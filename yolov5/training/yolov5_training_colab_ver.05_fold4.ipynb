{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5_training_colab_ver.05_fold4.ipynb의 사본","provenance":[{"file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","timestamp":1594723912497}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","authorship_tag":"ABX9TyMOGTednlAWNg5PmWz2YdDJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AiQPodddRTaD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594665300461,"user_tz":-540,"elapsed":1109,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"e17bff00-fc0c-40c2-d4da-22998e35043d"},"source":["\"\"\"\n","function ClickConnect(){\n","    console.log(\"Clicked on connect button\"); \n","    document.querySelector(\"#ok\").click()\n","}\n","setInterval(ClickConnect,60000)\n","\"\"\""],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'\\nfunction ClickConnect(){\\n    console.log(\"Clicked on connect button\"); \\n    document.querySelector(\"#ok\").click()\\n}\\nsetInterval(ClickConnect,60000)\\n'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Yf22UTuLusak","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1594665303033,"user_tz":-540,"elapsed":3659,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"fe400741-f15b-49eb-9b6e-cf2d42681401"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Jul 13 18:35:01 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OoBHduIadAI7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665303034,"user_tz":-540,"elapsed":3642,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import numpy as np\n","import pandas as pd\n","import os"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlvKV6g3Kcdn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"executionInfo":{"status":"ok","timestamp":1594665309184,"user_tz":-540,"elapsed":9776,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"517ba01c-7a0a-46a6-f2d9-a55e3d838da8"},"source":["!pip install -U PyYAML"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting PyYAML\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\r\u001b[K     |█▏                              | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 7.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: PyYAML\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=e4a25dc72caa43813cf5d222b4463432ab55cdf84520d710476e3b497e3e626c\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built PyYAML\n","Installing collected packages: PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDekTiLTg1WA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594665309185,"user_tz":-540,"elapsed":9758,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"247e6d36-ff1c-4af7-eab4-50bc62cb7336"},"source":["%%writefile setup.sh\n","\n","export CUDA_HOME=/usr/local/cuda-10.1\n","git clone https://github.com/NVIDIA/apex\n","pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Writing setup.sh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wPuaO9L9g2GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594665750543,"user_tz":-540,"elapsed":451097,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"8ed90380-1d4b-4722-cc84-4d6a1b403bdf"},"source":["!sh setup.sh"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 80, done.\u001b[K\n","remote: Counting objects: 100% (80/80), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 7335 (delta 40), reused 42 (delta 19), pack-reused 7255\u001b[K\n","Receiving objects: 100% (7335/7335), 13.88 MiB | 13.64 MiB/s, done.\n","Resolving deltas: 100% (4941/4941), done.\n","/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n","  cmdoptions.check_install_build_global(options)\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-8fqvo3oe\n","Created temporary directory: /tmp/pip-req-tracker-a9dzy6jo\n","Created requirements tracker '/tmp/pip-req-tracker-a9dzy6jo'\n","Created temporary directory: /tmp/pip-install-9oed_jfs\n","Processing ./apex\n","  Created temporary directory: /tmp/pip-req-build-6ro9aax_\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-a9dzy6jo'\n","    Running setup.py (path:/tmp/pip-req-build-6ro9aax_/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    writing manifest file '/tmp/pip-req-build-6ro9aax_/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-6ro9aax_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-6ro9aax_ has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-a9dzy6jo'\n","Skipping wheel build for apex, due to binaries being disabled for it.\n","Installing collected packages: apex\n","  Created temporary directory: /tmp/pip-record-5sk6z496\n","    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-6ro9aax_/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-6ro9aax_/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-5sk6z496/install-record.txt --single-version-externally-managed --compile\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    /tmp/pip-req-build-6ro9aax_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","\n","    Compiling cuda extensions with\n","    nvcc: NVIDIA (R) Cuda compiler driver\n","    Copyright (c) 2005-2019 NVIDIA Corporation\n","    Built on Sun_Jul_28_19:07:16_PDT_2019\n","    Cuda compilation tools, release 10.1, V10.1.243\n","    from /usr/local/cuda-10.1/bin\n","\n","    running install\n","    running build\n","    running build_py\n","    creating build\n","    creating build/lib.linux-x86_64-3.6\n","    creating build/lib.linux-x86_64-3.6/apex\n","    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n","    creating build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    creating build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    creating build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    creating build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    creating build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    creating build/lib.linux-x86_64-3.6/apex/contrib\n","    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof\n","    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n","    creating build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    running build_ext\n","    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","      warnings.warn(msg.format('we could not find ninja.'))\n","    building 'apex_C' extension\n","    creating build/temp.linux-x86_64-3.6\n","    creating build/temp.linux-x86_64-3.6/csrc\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from csrc/flatten_unflatten.cpp:2:0:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         return tensors[0].type();\n","                                ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/flatten_unflatten.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'amp_C' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'syncbn' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n","    building 'fused_layer_norm_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n","    building 'mlp_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","                                                                                 ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                        ^\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < inputs.size(); i++) {\n","                       ~~^~~~~~~~~~~~~~~\n","    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n","    running install_lib\n","    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    creating /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n","    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n","    running install_egg_info\n","    running egg_info\n","    creating apex.egg-info\n","    writing apex.egg-info/PKG-INFO\n","    writing dependency_links to apex.egg-info/dependency_links.txt\n","    writing top-level names to apex.egg-info/top_level.txt\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n","    running install_scripts\n","    writing list of installed files to '/tmp/pip-record-5sk6z496/install-record.txt'\n","    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n","  Removing source in /tmp/pip-req-build-6ro9aax_\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-a9dzy6jo'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"665tCOfRpIIx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665750896,"user_tz":-540,"elapsed":451433,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import torch.random\n","import random\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqnYi7N2Kfjy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665771801,"user_tz":-540,"elapsed":472317,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["zip_name = 'split-fold4.zip'\n","zip_path = '/content/drive/My Drive/Colab Notebooks/gwdsplit/' + zip_name\n","!cp \"{zip_path}\" .\n","!unzip -q '{zip_name}'\n","!rm '{zip_name}'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"978lsjD2vQAF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665780965,"user_tz":-540,"elapsed":481470,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["yolov5_name = 'yolov5.zip'\n","yolov5_path = '/content/drive/My Drive/Colab Notebooks/' + yolov5_name\n","!cp '{yolov5_path}' .\n","!unzip -q '{yolov5_name}'\n","!rm '{yolov5_name}'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROkeoZzd_ljI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665785325,"user_tz":-540,"elapsed":485814,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["weight_name = 'yolov5x_coco.pt'\n","weight_path = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + weight_name\n","!cp '{weight_path}' ."],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1l1XG4zejqR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594665785327,"user_tz":-540,"elapsed":485806,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["train_input = '/content/drive/My Drive/Colab Notebooks/yolov5/train.py'\n","data_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/wheat_colab.yaml'\n","cfg_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/yolov5x.yaml'\n","weights_input = '/content/' + weight_name\n","name_input = 'x-b2-e50-fold4'"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-Sb84dpxl6U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594665785328,"user_tz":-540,"elapsed":485795,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"ecc127cb-5c48-4ee4-a4c5-706a9aa399c6"},"source":["%cd /content/yolov5/"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/yolov5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYOIA2YaeNgC","colab_type":"text"},"source":["# **train.py**"]},{"cell_type":"code","metadata":{"id":"9UCW99OCx4QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1594665788028,"user_tz":-540,"elapsed":488480,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"a168db10-0321-4a05-8360-ea98dd21eeaf"},"source":["import argparse\n","\n","import torch.distributed as dist\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","import torch.utils.data\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import test  # import test.py to get mAP after each epoch\n","from models.yolo import Model\n","from utils import google_utils\n","from utils.datasets import *\n","from utils.utils import *\n","\n","mixed_precision = True\n","try:  # Mixed precision training https://github.com/NVIDIA/apex\n","    from apex import amp\n","except:\n","    print('Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex')\n","    mixed_precision = False  # not installed\n","\n","wdir = 'weights' + os.sep  # weights dir\n","os.makedirs(wdir, exist_ok=True)\n","last = wdir + 'last.pt'\n","best = wdir + 'best.pt'\n","results_file = 'results.txt'\n","\n","# Hyperparameters\n","hyp = {'lr0': 0.01,  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","       'momentum': 0.937,  # SGD momentum\n","       'weight_decay': 5e-4,  # optimizer weight decay\n","       'giou': 0.05,  # giou loss gain\n","       'cls': 0.58,  # cls loss gain\n","       'cls_pw': 1.0,  # cls BCELoss positive_weight\n","       'obj': 1.0,  # obj loss gain (*=img_size/320 if img_size != 320)\n","       'obj_pw': 1.0,  # obj BCELoss positive_weight\n","       'iou_t': 0.20,  # iou training threshold\n","       'anchor_t': 4.0,  # anchor-multiple threshold\n","       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n","       'hsv_h': 0.014,  # image HSV-Hue augmentation (fraction)\n","       'hsv_s': 0.68,  # image HSV-Saturation augmentation (fraction)\n","       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n","       'degrees': 0.0,  # image rotation (+/- deg)\n","       'translate': 0.0,  # image translation (+/- fraction)\n","       'scale': 0.5,  # image scale (+/- gain)\n","       'shear': 0.0}  # image shear (+/- deg)\n","print(hyp)\n","\n","# Overwrite hyp with hyp*.txt (optional)\n","f = glob.glob('hyp*.txt')\n","if f:\n","    print('Using %s' % f[0])\n","    for k, v in zip(hyp.keys(), np.loadtxt(f[0])):\n","        hyp[k] = v\n","\n","# Print focal loss if gamma > 0\n","if hyp['fl_gamma']:\n","    print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])\n","\n","\n","def train(hyp):\n","    epochs = opt.epochs  # 300\n","    batch_size = opt.batch_size  # 64\n","    weights = opt.weights  # initial training weights\n","\n","    # Configure\n","    init_seeds(1)\n","    with open(opt.data) as f:\n","        data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n","    train_path = data_dict['train']\n","    test_path = data_dict['val']\n","    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes\n","\n","    # Remove previous results\n","    for f in glob.glob('*_batch*.jpg') + glob.glob(results_file):\n","        os.remove(f)\n","\n","    # Create model\n","    model = Model(opt.cfg, nc=data_dict['nc']).to(device)\n","\n","    # Image sizes\n","    gs = int(max(model.stride))  # grid size (max stride)\n","    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n","\n","    # Optimizer\n","    nbs = 64  # nominal batch size\n","    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n","    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n","    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n","    for k, v in model.named_parameters():\n","        if v.requires_grad:\n","            if '.bias' in k:\n","                pg2.append(v)  # biases\n","            elif '.weight' in k and '.bn' not in k:\n","                pg1.append(v)  # apply weight decay\n","            else:\n","                pg0.append(v)  # all else\n","\n","    optimizer = optim.Adam(pg0, lr=hyp['lr0']) if opt.adam else \\\n","        optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n","    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n","    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n","    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n","    lf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.9 + 0.1  # cosine\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n","    print('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n","    del pg0, pg1, pg2\n","\n","    # Load Model\n","    google_utils.attempt_download(weights)\n","    start_epoch, best_fitness = 0, 0.0\n","    if weights.endswith('.pt'):  # pytorch format\n","        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n","\n","        # load model\n","        try:\n","            ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n","                             if model.state_dict()[k].shape == v.shape}  # to FP32, filter\n","            model.load_state_dict(ckpt['model'], strict=False)\n","        except KeyError as e:\n","            s = \"%s is not compatible with %s. This may be due to model differences or %s may be out of date. \" \\\n","                \"Please delete or update %s and try again, or use --weights '' to train from scratch.\" \\\n","                % (opt.weights, opt.cfg, opt.weights, opt.weights)\n","            raise KeyError(s) from e\n","\n","        # load optimizer\n","        if ckpt['optimizer'] is not None:\n","            optimizer.load_state_dict(ckpt['optimizer'])\n","            best_fitness = ckpt['best_fitness']\n","\n","        # load results\n","        if ckpt.get('training_results') is not None:\n","            with open(results_file, 'w') as file:\n","                file.write(ckpt['training_results'])  # write results.txt\n","\n","        # epochs\n","        start_epoch = ckpt['epoch'] + 1\n","        if epochs < start_epoch:\n","            print('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n","                  (opt.weights, ckpt['epoch'], epochs))\n","            epochs += ckpt['epoch']  # finetune additional epochs\n","\n","        del ckpt\n","\n","    # Mixed precision training https://github.com/NVIDIA/apex\n","    if mixed_precision:\n","        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n","\n","\n","    scheduler.last_epoch = start_epoch - 1  # do not move\n","    # https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822\n","    # plot_lr_scheduler(optimizer, scheduler, epochs)\n","\n","    # Initialize distributed training\n","    if device.type != 'cpu' and torch.cuda.device_count() > 1 and torch.distributed.is_available():\n","        dist.init_process_group(backend='nccl',  # distributed backend\n","                                init_method='tcp://127.0.0.1:9999',  # init method\n","                                world_size=1,  # number of nodes\n","                                rank=0)  # node rank\n","        model = torch.nn.parallel.DistributedDataParallel(model)\n","        # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","    # Trainloader\n","    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n","                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect)\n","    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n","    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Correct your labels or your model.' % (mlc, nc, opt.cfg)\n","\n","    # Testloader\n","    testloader = create_dataloader(test_path, imgsz_test, batch_size, gs, opt,\n","                                   hyp=hyp, augment=False, cache=opt.cache_images, rect=True)[0]\n","\n","    # Model parameters\n","    hyp['cls'] *= nc / 80.  # scale coco-tuned hyp['cls'] to current dataset\n","    model.nc = nc  # attach number of classes to model\n","    model.hyp = hyp  # attach hyperparameters to model\n","    model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n","    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights\n","    model.names = data_dict['names']\n","\n","    # Class frequency\n","    labels = np.concatenate(dataset.labels, 0)\n","    c = torch.tensor(labels[:, 0])  # classes\n","    # cf = torch.bincount(c.long(), minlength=nc) + 1.\n","    # model._initialize_biases(cf.to(device))\n","    if tb_writer:\n","        plot_labels(labels)\n","        tb_writer.add_histogram('classes', c, 0)\n","\n","    # Check anchors\n","    if not opt.noautoanchor:\n","        check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n","\n","    # Exponential moving average\n","    ema = torch_utils.ModelEMA(model)\n","\n","    # Start training\n","    t0 = time.time()\n","    nb = len(dataloader)  # number of batches\n","    n_burn = max(3 * nb, 1e3)  # burn-in iterations, max(3 epochs, 1k iterations)\n","    maps = np.zeros(nc)  # mAP per class\n","    results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n","    print('Image sizes %g train, %g test' % (imgsz, imgsz_test))\n","    print('Using %g dataloader workers' % dataloader.num_workers)\n","    print('Starting training for %g epochs...' % epochs)\n","    # torch.autograd.set_detect_anomaly(True)\n","    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n","        model.train()\n","\n","        # Update image weights (optional)\n","        if dataset.image_weights:\n","            w = model.class_weights.cpu().numpy() * (1 - maps) ** 2  # class weights\n","            image_weights = labels_to_image_weights(dataset.labels, nc=nc, class_weights=w)\n","            dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # rand weighted idx\n","\n","        # Update mosaic border\n","        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n","        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n","\n","        mloss = torch.zeros(4, device=device)  # mean losses\n","        print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n","        pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n","        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n","            ni = i + nb * epoch  # number integrated batches (since train start)\n","            imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n","\n","            # Burn-in\n","            if ni <= n_burn:\n","                xi = [0, n_burn]  # x interp\n","                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # giou loss ratio (obj_loss = 1.0 or giou)\n","                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n","                for j, x in enumerate(optimizer.param_groups):\n","                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n","                    x['lr'] = np.interp(ni, xi, [0.1 if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n","                    if 'momentum' in x:\n","                        x['momentum'] = np.interp(ni, xi, [0.9, hyp['momentum']])\n","\n","            # Multi-scale\n","            if opt.multi_scale:\n","                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n","                sf = sz / max(imgs.shape[2:])  # scale factor\n","                if sf != 1:\n","                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n","                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n","\n","            # Forward\n","            pred = model(imgs)\n","\n","            # Loss\n","            loss, loss_items = compute_loss(pred, targets.to(device), model)\n","            if not torch.isfinite(loss):\n","                print('WARNING: non-finite loss, ending training ', loss_items)\n","                return results\n","\n","            # Backward\n","            if mixed_precision:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            # Optimize\n","            if ni % accumulate == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                ema.update(model)\n","\n","            # Print\n","            mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n","            mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n","            s = ('%10s' * 2 + '%10.4g' * 6) % (\n","                '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n","            pbar.set_description(s)\n","\n","            # Plot\n","            if ni < 3:\n","                f = 'train_batch%g.jpg' % ni  # filename\n","                result = plot_images(images=imgs, targets=targets, paths=paths, fname=f)\n","                if tb_writer and result is not None:\n","                    tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n","                    # tb_writer.add_graph(model, imgs)  # add model to tensorboard\n","\n","            # end batch ------------------------------------------------------------------------------------------------\n","\n","        # Scheduler\n","        scheduler.step()\n","\n","        # mAP\n","        ema.update_attr(model)\n","        final_epoch = epoch + 1 == epochs\n","        if not opt.notest or final_epoch:  # Calculate mAP\n","            results, maps, times = test.test(opt.data,\n","                                             batch_size=batch_size,\n","                                             imgsz=imgsz_test,\n","                                             save_json=final_epoch and opt.data.endswith(os.sep + 'coco.yaml'),\n","                                             model=ema.ema,\n","                                             single_cls=opt.single_cls,\n","                                             dataloader=testloader)\n","\n","        # Write\n","        with open(results_file, 'a') as f:\n","            f.write(s + '%10.4g' * 7 % results + '\\n')  # P, R, mAP, F1, test_losses=(GIoU, obj, cls)\n","        if len(opt.name) and opt.bucket:\n","            os.system('gsutil cp results.txt gs://%s/results/results%s.txt' % (opt.bucket, opt.name))\n","\n","        # Tensorboard\n","        if tb_writer:\n","            tags = ['train/giou_loss', 'train/obj_loss', 'train/cls_loss',\n","                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/F1',\n","                    'val/giou_loss', 'val/obj_loss', 'val/cls_loss']\n","            for x, tag in zip(list(mloss[:-1]) + list(results), tags):\n","                tb_writer.add_scalar(tag, x, epoch)\n","\n","        # Update best mAP\n","        fi = fitness(np.array(results).reshape(1, -1))  # fitness_i = weighted combination of [P, R, mAP, F1]\n","        if fi > best_fitness:\n","            best_fitness = fi\n","\n","        # Save model\n","        save = (not opt.nosave) or (final_epoch and not opt.evolve)\n","        if save:\n","            with open(results_file, 'r') as f:  # create checkpoint\n","                ckpt = {'epoch': epoch,\n","                        'best_fitness': best_fitness,\n","                        'training_results': f.read(),\n","                        'model': ema.ema,\n","                        'optimizer': None if final_epoch else optimizer.state_dict()}\n","\n","            # Save last, best and delete\n","            torch.save(ckpt, last)\n","            if (best_fitness == fi) and not final_epoch:\n","                torch.save(ckpt, best)\n","            del ckpt\n","\n","        # end epoch ----------------------------------------------------------------------------------------------------\n","    # end training\n","\n","    # Strip optimizers\n","    n = ('_' if len(opt.name) and not opt.name.isnumeric() else '') + opt.name\n","    fresults, flast, fbest = 'results%s.txt' % n, wdir + 'last%s.pt' % n, wdir + 'best%s.pt' % n\n","    for f1, f2 in zip([wdir + 'last.pt', wdir + 'best.pt', 'results.txt'], [flast, fbest, fresults]):\n","        if os.path.exists(f1):\n","            os.rename(f1, f2)  # rename\n","            ispt = f2.endswith('.pt')  # is *.pt\n","            strip_optimizer(f2) if ispt else None  # strip optimizer\n","            os.system('gsutil cp %s gs://%s/weights' % (f2, opt.bucket)) if opt.bucket and ispt else None  # upload\n","\n","    # Finish\n","    if not opt.evolve:\n","        plot_results()  # save as results.png\n","    print('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n","    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None\n","    torch.cuda.empty_cache()\n","    return results"],"execution_count":14,"outputs":[{"output_type":"stream","text":["{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9csFml3nfP7H","colab_type":"text"},"source":["# **Train Option**"]},{"cell_type":"code","metadata":{"id":"h0uu9IpAyJC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594708574872,"user_tz":-540,"elapsed":43275307,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"034ee55f-8561-4f44-a876-375bb78c7418"},"source":["check_git_status()\n","class opt:\n","    epochs=50                #parser.add_argument('--epochs', type=int, default=300)\n","    batch_size=2            #parser.add_argument('--batch-size', type=int, default=16)\n","    cfg=cfg_input           #parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='*.cfg path')\n","    data=data_input         #parser.add_argument('--data', type=str, default='data/coco128.yaml', help='*.data path')\n","    img_size=[1024, 1024]   #parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='train,test sizes')\n","    rect=False              #parser.add_argument('--rect', action='store_true', help='rectangular training')\n","    resume=False            #parser.add_argument('--resume', action='store_true', help='resume training from last.pt')\n","    nosave=False            #parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n","    notest=False            #parser.add_argument('--notest', action='store_true', help='only test final epoch')\n","    noautoanchor=False      #parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n","    evolve=False            #parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n","    bucket=''               #parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n","    cache_images=False      #parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n","    weights=weights_input   #parser.add_argument('--weights', type=str, default='', help='initial weights path')\n","    name=name_input         #parser.add_argument('--name', default='', help='renames results.txt to results_name.txt if supplied')\n","    device=''               #parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n","    adam=False              #parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n","    multi_scale=False       #parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%')\n","    single_cls=False        #parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n","\n","#parser = argparse.ArgumentParser()\n","#opt = parser.parse_args()\n","\n","opt.weights = last if opt.resume and not opt.weights else opt.weights\n","opt.cfg = check_file(opt.cfg)  # check file\n","opt.data = check_file(opt.data)  # check file\n","print(opt)\n","opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n","device = torch_utils.select_device(opt.device, apex=mixed_precision, batch_size=opt.batch_size)\n","if device.type == 'cpu':\n","    mixed_precision = False\n","\n","# Train\n","if not opt.evolve:\n","    tb_writer = SummaryWriter(comment=opt.name)\n","    print('Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/')\n","    train(hyp)\n","\n","# Evolve hyperparameters (optional)\n","else:\n","    tb_writer = None\n","    opt.notest, opt.nosave = True, True  # only test/save final epoch\n","    if opt.bucket:\n","        os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n","\n","    for _ in range(10):  # generations to evolve\n","        if os.path.exists('evolve.txt'):  # if evolve.txt exists: select best hyps and mutate\n","            # Select parent(s)\n","            parent = 'single'  # parent selection method: 'single' or 'weighted'\n","            x = np.loadtxt('evolve.txt', ndmin=2)\n","            n = min(5, len(x))  # number of previous results to consider\n","            x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n","            w = fitness(x) - fitness(x).min()  # weights\n","            if parent == 'single' or len(x) == 1:\n","                # x = x[random.randint(0, n - 1)]  # random selection\n","                x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n","            elif parent == 'weighted':\n","                x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n","\n","            # Mutate\n","            mp, s = 0.9, 0.2  # mutation probability, sigma\n","            npr = np.random\n","            npr.seed(int(time.time()))\n","            g = np.array([1, 1, 1, 1, 1, 1, 1, 0, .1, 1, 0, 1, 1, 1, 1, 1, 1, 1])  # gains\n","            ng = len(g)\n","            v = np.ones(ng)\n","            while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n","                v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n","            for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n","                hyp[k] = x[i + 7] * v[i]  # mutate\n","\n","        # Clip to limits\n","        keys = ['lr0', 'iou_t', 'momentum', 'weight_decay', 'hsv_s', 'hsv_v', 'translate', 'scale', 'fl_gamma']\n","        limits = [(1e-5, 1e-2), (0.00, 0.70), (0.60, 0.98), (0, 0.001), (0, .9), (0, .9), (0, .9), (0, .9), (0, 3)]\n","        for k, v in zip(keys, limits):\n","            hyp[k] = np.clip(hyp[k], v[0], v[1])\n","\n","        # Train mutation\n","        results = train(hyp.copy())\n","\n","        # Write mutation results\n","        print_mutation(hyp, results, opt.bucket)\n","\n","        # Plot results\n","        # plot_evolution_results(hyp)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["<class '__main__.opt'>\n","Using CUDA Apex device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n","  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  2                -1  1    315680  models.common.BottleneckCSP             [160, 160, 4]                 \n","  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n","  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n","  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n","  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n","  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n","  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n","  9                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1   5435520  models.common.BottleneckCSP             [1280, 640, 4, False]         \n"," 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1   1360960  models.common.BottleneckCSP             [640, 320, 4, False]          \n"," 18                -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n"," 19                -2  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 21                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n"," 22                -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n"," 23                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 25                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 26                -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n"," 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [1, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n","Model Summary: 407 layers, 8.84337e+07 parameters, 8.84337e+07 gradients\n","\n","Optimizer groups: 134 .bias, 142 conv.weight, 131 other\n"],"name":"stdout"},{"output_type":"stream","text":["Reading image shapes: 100%|██████████| 2701/2701 [00:00<00:00, 12079.60it/s]\n","Caching labels /content/labels/train (2701 found, 0 missing, 0 empty, 0 duplicate, for 2701 images): 100%|██████████| 2701/2701 [00:00<00:00, 4436.13it/s]\n","Reading image shapes: 100%|██████████| 672/672 [00:00<00:00, 13858.24it/s]\n","Caching labels /content/labels/valid (478 found, 0 missing, 0 empty, 0 duplicate, for 672 images):  71%|███████   | 478/672 [00:00<00:00, 4771.65it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving labels to /content/labels/train.npy for faster future loading\n"],"name":"stdout"},{"output_type":"stream","text":["\rCaching labels /content/labels/valid (672 found, 0 missing, 0 empty, 0 duplicate, for 672 images): 100%|██████████| 672/672 [00:00<00:00, 4614.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Analyzing anchors... Best Possible Recall (BPR) = 0.9991\n","Image sizes 1024 train, 1024 test\n","Using 2 dataloader workers\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      0/49     4.91G   0.07371    0.1847         0    0.2584       123      1024: 100%|██████████| 1351/1351 [12:50<00:00,  1.75it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [02:04<00:00,  2.69it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.341       0.941       0.692       0.224\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      1/49      5.3G   0.05604    0.1553         0    0.2113        34      1024: 100%|██████████| 1351/1351 [12:22<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:57<00:00,  2.85it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.518       0.944       0.917       0.442\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      2/49      5.3G    0.0533    0.1559         0    0.2092       108      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [02:03<00:00,  2.72it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04        0.43        0.94       0.831       0.357\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      3/49      5.3G   0.04725    0.1496         0    0.1968        48      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:54<00:00,  2.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.645        0.95       0.938       0.486\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      4/49      5.3G   0.04244     0.145         0    0.1874        24      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.712       0.949       0.941       0.498\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      5/49      5.3G   0.04014     0.144         0    0.1842       116      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:53<00:00,  2.96it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.709       0.947       0.941       0.508\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      6/49      5.3G   0.03933    0.1431         0    0.1825       126      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.736       0.947       0.945       0.518\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      7/49     5.31G   0.03824    0.1406         0    0.1788        74      1024: 100%|██████████| 1351/1351 [12:21<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  3.00it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.711       0.946        0.94        0.51\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      8/49     5.31G     0.038    0.1423         0    0.1803        39      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:53<00:00,  2.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.732       0.949       0.946       0.512\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      9/49     5.31G   0.03706    0.1385         0    0.1755        50      1024: 100%|██████████| 1351/1351 [12:23<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:55<00:00,  2.92it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.737        0.95       0.947       0.523\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     10/49     5.31G   0.03703    0.1393         0    0.1763        13      1024: 100%|██████████| 1351/1351 [12:23<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:53<00:00,  2.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.743        0.95       0.948       0.528\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     11/49     5.31G   0.03664    0.1386         0    0.1753       140      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.717       0.949       0.943       0.512\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     12/49     5.31G   0.03611    0.1355         0    0.1716        28      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.728       0.951       0.948       0.518\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     13/49     5.31G   0.03622    0.1363         0    0.1725        31      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:51<00:00,  3.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.732       0.954        0.95       0.527\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     14/49     5.31G    0.0356    0.1369         0    0.1725        90      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.747       0.952       0.949       0.533\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     15/49     5.31G   0.03544    0.1356         0     0.171        19      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:51<00:00,  3.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.745       0.951       0.948       0.521\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     16/49     5.31G   0.03516    0.1336         0    0.1688        71      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.754        0.95        0.95       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     17/49     5.31G   0.03494    0.1357         0    0.1706        58      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.761       0.948       0.947       0.529\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     18/49     5.31G   0.03442    0.1325         0    0.1669        52      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.741       0.952       0.949       0.534\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     19/49     5.31G   0.03458    0.1332         0    0.1678        69      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.745       0.952       0.949       0.529\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     20/49     5.31G   0.03416     0.134         0    0.1681        34      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.758       0.951        0.95       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     21/49     5.31G   0.03431    0.1329         0    0.1673       129      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.757       0.952        0.95       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     22/49     5.31G   0.03389    0.1325         0    0.1664        57      1024: 100%|██████████| 1351/1351 [12:21<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:51<00:00,  3.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.764       0.949       0.948       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     23/49     5.31G   0.03369    0.1329         0    0.1666        20      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.99it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.765        0.95       0.949       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     24/49     5.31G   0.03361    0.1326         0    0.1662        81      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.766       0.952        0.95       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     25/49     5.31G   0.03345    0.1325         0    0.1659       131      1024: 100%|██████████| 1351/1351 [12:22<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:52<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.768       0.949       0.949       0.533\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     26/49     5.31G   0.03349    0.1316         0     0.165        75      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.764        0.95       0.948       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     27/49     5.31G   0.03327    0.1307         0    0.1639        30      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:51<00:00,  3.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04        0.76        0.95       0.948       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     28/49     5.31G   0.03316    0.1302         0    0.1633        76      1024: 100%|██████████| 1351/1351 [12:21<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.773       0.949       0.948       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     29/49     5.31G   0.03289    0.1283         0    0.1612        22      1024: 100%|██████████| 1351/1351 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.766       0.949       0.948       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     30/49     5.31G   0.03275    0.1279         0    0.1607        36      1024: 100%|██████████| 1351/1351 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.775        0.95       0.949       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     31/49     5.31G   0.03267     0.128         0    0.1607        31      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.778       0.948       0.949       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     32/49     5.31G   0.03259    0.1289         0    0.1615        75      1024: 100%|██████████| 1351/1351 [12:18<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.776       0.949       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     33/49     5.31G   0.03269    0.1304         0    0.1631        58      1024: 100%|██████████| 1351/1351 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.781        0.95       0.949        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     34/49     5.31G   0.03231    0.1274         0    0.1597        58      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04        0.78       0.948       0.949       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     35/49     5.31G   0.03219    0.1256         0    0.1578       173      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.783       0.948       0.948        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     36/49     5.31G    0.0321    0.1274         0    0.1595        41      1024: 100%|██████████| 1351/1351 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.785       0.948       0.949        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     37/49     5.31G   0.03204    0.1278         0    0.1599        94      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.782       0.948       0.948        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     38/49     5.31G   0.03205    0.1259         0     0.158        92      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:49<00:00,  3.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.784       0.947       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     39/49     5.31G   0.03194    0.1265         0    0.1584        63      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.778       0.948       0.947       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     40/49     5.31G   0.03192    0.1248         0    0.1567        59      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04        0.78       0.948       0.948        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     41/49     5.31G   0.03176    0.1242         0    0.1559        42      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.787       0.947       0.948        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     42/49     5.31G   0.03171    0.1256         0    0.1573        91      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.784       0.947       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     43/49     5.31G   0.03159    0.1259         0    0.1574       121      1024: 100%|██████████| 1351/1351 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.784       0.947       0.947        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     44/49     5.31G   0.03183    0.1248         0    0.1567        55      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.789       0.946       0.948       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     45/49     5.31G   0.03141    0.1244         0    0.1558       100      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:47<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.784       0.947       0.947       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     46/49     5.31G   0.03148    0.1239         0    0.1554        27      1024: 100%|██████████| 1351/1351 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:47<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.791       0.947       0.949       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     47/49     5.31G   0.03143    0.1243         0    0.1557        22      1024: 100%|██████████| 1351/1351 [12:19<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.785       0.948       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     48/49     5.31G   0.03137    0.1257         0    0.1571        62      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:51<00:00,  3.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.788       0.947       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     49/49     5.31G   0.03146    0.1229         0    0.1543       121      1024: 100%|██████████| 1351/1351 [12:20<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 336/336 [01:50<00:00,  3.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         672    2.96e+04       0.785       0.946       0.947       0.538\n","Optimizer stripped from weights/last_x-b2-e50-fold4.pt\n","Optimizer stripped from weights/best_x-b2-e50-fold4.pt\n","50 epochs completed in 11.875 hours.\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 10 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"HXFQcoG0kWE7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594708584874,"user_tz":-540,"elapsed":43285279,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import shutil\n","new_weight = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + name_input\n","if os.path.exists(new_weight):\n","  shutil.rmtree(new_weight)\n","os.mkdir(new_weight)\n","\n","weight_last = '/content/yolov5/weights/last_' + name_input + '.pt'\n","weight_best = '/content/yolov5/weights/best_' + name_input + '.pt'\n","\n","!cp '{weight_last}' '{new_weight}'\n","!cp '{weight_best}' '{new_weight}'\n","!cp 'results.png' '{new_weight}'\n","!cp 'labels.png' '{new_weight}'\n","!cp 'test_batch0_gt.jpg' '{new_weight}'\n","!cp 'test_batch0_pred.jpg' '{new_weight}'"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtigXSkIl15i","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594708584875,"user_tz":-540,"elapsed":43285258,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":[""],"execution_count":16,"outputs":[]}]}