{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5_training_colab_ver.05_fold1.ipynb의 사본","provenance":[{"file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","timestamp":1594569049878}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","authorship_tag":"ABX9TyP+ZWli2sW4e4OlWFJ1Rlsy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AiQPodddRTaD","colab_type":"code","colab":{}},"source":["\"\"\"\n","function ClickConnect(){\n","    console.log(\"Clicked on connect button\"); \n","    document.querySelector(\"#ok\").click()\n","}\n","setInterval(ClickConnect,60000)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yf22UTuLusak","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1594525567964,"user_tz":-540,"elapsed":4201,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"f11bf581-635e-4b33-e1e0-166680273841"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Jul 12 03:46:04 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OoBHduIadAI7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594525614589,"user_tz":-540,"elapsed":2249,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import numpy as np\n","import pandas as pd\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlvKV6g3Kcdn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"executionInfo":{"status":"ok","timestamp":1594525620756,"user_tz":-540,"elapsed":8209,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"d5807a1c-1b4e-4119-8e29-9bb828dfe424"},"source":["!pip install -U PyYAML"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting PyYAML\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\r\u001b[K     |█▏                              | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 6.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: PyYAML\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=e6b619c9878da3920407f955cdb7c8828cbbd19807810ba46fa4f3249a3371e1\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built PyYAML\n","Installing collected packages: PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDekTiLTg1WA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594525620759,"user_tz":-540,"elapsed":7978,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"1bb5d4c6-92be-41c4-8cac-2955ba2e1366"},"source":["%%writefile setup.sh\n","\n","export CUDA_HOME=/usr/local/cuda-10.1\n","git clone https://github.com/NVIDIA/apex\n","pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Writing setup.sh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wPuaO9L9g2GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594526038495,"user_tz":-540,"elapsed":425517,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"a0a42a2e-ae5d-47ed-dd55-6a213a5a1c46"},"source":["!sh setup.sh"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 80, done.\u001b[K\n","remote: Counting objects: 100% (80/80), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 7335 (delta 40), reused 42 (delta 19), pack-reused 7255\u001b[K\n","Receiving objects: 100% (7335/7335), 13.88 MiB | 12.81 MiB/s, done.\n","Resolving deltas: 100% (4939/4939), done.\n","/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n","  cmdoptions.check_install_build_global(options)\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-y6c8tly5\n","Created temporary directory: /tmp/pip-req-tracker-2ki3rb6q\n","Created requirements tracker '/tmp/pip-req-tracker-2ki3rb6q'\n","Created temporary directory: /tmp/pip-install-06m5gvtl\n","Processing ./apex\n","  Created temporary directory: /tmp/pip-req-build-6vt5vouz\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-2ki3rb6q'\n","    Running setup.py (path:/tmp/pip-req-build-6vt5vouz/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    writing manifest file '/tmp/pip-req-build-6vt5vouz/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-6vt5vouz/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-6vt5vouz has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-2ki3rb6q'\n","Skipping wheel build for apex, due to binaries being disabled for it.\n","Installing collected packages: apex\n","  Created temporary directory: /tmp/pip-record-u1beufol\n","    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-6vt5vouz/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-6vt5vouz/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-u1beufol/install-record.txt --single-version-externally-managed --compile\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    /tmp/pip-req-build-6vt5vouz/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","\n","    Compiling cuda extensions with\n","    nvcc: NVIDIA (R) Cuda compiler driver\n","    Copyright (c) 2005-2019 NVIDIA Corporation\n","    Built on Sun_Jul_28_19:07:16_PDT_2019\n","    Cuda compilation tools, release 10.1, V10.1.243\n","    from /usr/local/cuda-10.1/bin\n","\n","    running install\n","    running build\n","    running build_py\n","    creating build\n","    creating build/lib.linux-x86_64-3.6\n","    creating build/lib.linux-x86_64-3.6/apex\n","    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n","    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    creating build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    creating build/lib.linux-x86_64-3.6/apex/contrib\n","    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n","    creating build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    creating build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    creating build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof\n","    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n","    creating build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    creating build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    running build_ext\n","    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","      warnings.warn(msg.format('we could not find ninja.'))\n","    building 'apex_C' extension\n","    creating build/temp.linux-x86_64-3.6\n","    creating build/temp.linux-x86_64-3.6/csrc\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from csrc/flatten_unflatten.cpp:2:0:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         return tensors[0].type();\n","                                ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/flatten_unflatten.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'amp_C' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'syncbn' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n","    building 'fused_layer_norm_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n","    building 'mlp_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","                                                                                 ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                        ^\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < inputs.size(); i++) {\n","                       ~~^~~~~~~~~~~~~~~\n","    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n","    running install_lib\n","    creating /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    running install_egg_info\n","    running egg_info\n","    creating apex.egg-info\n","    writing apex.egg-info/PKG-INFO\n","    writing dependency_links to apex.egg-info/dependency_links.txt\n","    writing top-level names to apex.egg-info/top_level.txt\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n","    running install_scripts\n","    writing list of installed files to '/tmp/pip-record-u1beufol/install-record.txt'\n","    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n","  Removing source in /tmp/pip-req-build-6vt5vouz\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-2ki3rb6q'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"665tCOfRpIIx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594526038890,"user_tz":-540,"elapsed":425664,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import torch.random\n","import random\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqnYi7N2Kfjy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594526060579,"user_tz":-540,"elapsed":447093,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["zip_name = 'split-fold1.zip'\n","zip_path = '/content/drive/My Drive/Colab Notebooks/gwdsplit/' + zip_name\n","!cp \"{zip_path}\" .\n","!unzip -q '{zip_name}'\n","!rm '{zip_name}'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"978lsjD2vQAF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594526066780,"user_tz":-540,"elapsed":453138,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["yolov5_name = 'yolov5.zip'\n","yolov5_path = '/content/drive/My Drive/Colab Notebooks/' + yolov5_name\n","!cp '{yolov5_path}' .\n","!unzip -q '{yolov5_name}'\n","!rm '{yolov5_name}'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROkeoZzd_ljI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594526071752,"user_tz":-540,"elapsed":457822,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["weight_name = 'yolov5x_coco.pt'\n","weight_path = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + weight_name\n","!cp '{weight_path}' ."],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1l1XG4zejqR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594526071754,"user_tz":-540,"elapsed":457680,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["train_input = '/content/drive/My Drive/Colab Notebooks/yolov5/train.py'\n","data_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/wheat_colab.yaml'\n","cfg_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/yolov5x.yaml'\n","weights_input = '/content/' + weight_name\n","name_input = 'x-b2-e50-fold1'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-Sb84dpxl6U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594526071755,"user_tz":-540,"elapsed":457423,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"6fd5eb3f-9993-40b5-c888-07aa804c567f"},"source":["%cd /content/yolov5/"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/yolov5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYOIA2YaeNgC","colab_type":"text"},"source":["# **train.py**"]},{"cell_type":"code","metadata":{"id":"9UCW99OCx4QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1594526074784,"user_tz":-540,"elapsed":460079,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"f9ec3c7f-1c46-4328-b0cc-5a877c9456a7"},"source":["import argparse\n","\n","import torch.distributed as dist\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","import torch.utils.data\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import test  # import test.py to get mAP after each epoch\n","from models.yolo import Model\n","from utils import google_utils\n","from utils.datasets import *\n","from utils.utils import *\n","\n","mixed_precision = True\n","try:  # Mixed precision training https://github.com/NVIDIA/apex\n","    from apex import amp\n","except:\n","    print('Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex')\n","    mixed_precision = False  # not installed\n","\n","wdir = 'weights' + os.sep  # weights dir\n","os.makedirs(wdir, exist_ok=True)\n","last = wdir + 'last.pt'\n","best = wdir + 'best.pt'\n","results_file = 'results.txt'\n","\n","# Hyperparameters\n","hyp = {'lr0': 0.01,  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","       'momentum': 0.937,  # SGD momentum\n","       'weight_decay': 5e-4,  # optimizer weight decay\n","       'giou': 0.05,  # giou loss gain\n","       'cls': 0.58,  # cls loss gain\n","       'cls_pw': 1.0,  # cls BCELoss positive_weight\n","       'obj': 1.0,  # obj loss gain (*=img_size/320 if img_size != 320)\n","       'obj_pw': 1.0,  # obj BCELoss positive_weight\n","       'iou_t': 0.20,  # iou training threshold\n","       'anchor_t': 4.0,  # anchor-multiple threshold\n","       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n","       'hsv_h': 0.014,  # image HSV-Hue augmentation (fraction)\n","       'hsv_s': 0.68,  # image HSV-Saturation augmentation (fraction)\n","       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n","       'degrees': 0.0,  # image rotation (+/- deg)\n","       'translate': 0.0,  # image translation (+/- fraction)\n","       'scale': 0.5,  # image scale (+/- gain)\n","       'shear': 0.0}  # image shear (+/- deg)\n","print(hyp)\n","\n","# Overwrite hyp with hyp*.txt (optional)\n","f = glob.glob('hyp*.txt')\n","if f:\n","    print('Using %s' % f[0])\n","    for k, v in zip(hyp.keys(), np.loadtxt(f[0])):\n","        hyp[k] = v\n","\n","# Print focal loss if gamma > 0\n","if hyp['fl_gamma']:\n","    print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])\n","\n","\n","def train(hyp):\n","    epochs = opt.epochs  # 300\n","    batch_size = opt.batch_size  # 64\n","    weights = opt.weights  # initial training weights\n","\n","    # Configure\n","    init_seeds(1)\n","    with open(opt.data) as f:\n","        data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n","    train_path = data_dict['train']\n","    test_path = data_dict['val']\n","    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes\n","\n","    # Remove previous results\n","    for f in glob.glob('*_batch*.jpg') + glob.glob(results_file):\n","        os.remove(f)\n","\n","    # Create model\n","    model = Model(opt.cfg, nc=data_dict['nc']).to(device)\n","\n","    # Image sizes\n","    gs = int(max(model.stride))  # grid size (max stride)\n","    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n","\n","    # Optimizer\n","    nbs = 64  # nominal batch size\n","    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n","    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n","    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n","    for k, v in model.named_parameters():\n","        if v.requires_grad:\n","            if '.bias' in k:\n","                pg2.append(v)  # biases\n","            elif '.weight' in k and '.bn' not in k:\n","                pg1.append(v)  # apply weight decay\n","            else:\n","                pg0.append(v)  # all else\n","\n","    optimizer = optim.Adam(pg0, lr=hyp['lr0']) if opt.adam else \\\n","        optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n","    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n","    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n","    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n","    lf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.9 + 0.1  # cosine\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n","    print('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n","    del pg0, pg1, pg2\n","\n","    # Load Model\n","    google_utils.attempt_download(weights)\n","    start_epoch, best_fitness = 0, 0.0\n","    if weights.endswith('.pt'):  # pytorch format\n","        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n","\n","        # load model\n","        try:\n","            ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n","                             if model.state_dict()[k].shape == v.shape}  # to FP32, filter\n","            model.load_state_dict(ckpt['model'], strict=False)\n","        except KeyError as e:\n","            s = \"%s is not compatible with %s. This may be due to model differences or %s may be out of date. \" \\\n","                \"Please delete or update %s and try again, or use --weights '' to train from scratch.\" \\\n","                % (opt.weights, opt.cfg, opt.weights, opt.weights)\n","            raise KeyError(s) from e\n","\n","        # load optimizer\n","        if ckpt['optimizer'] is not None:\n","            optimizer.load_state_dict(ckpt['optimizer'])\n","            best_fitness = ckpt['best_fitness']\n","\n","        # load results\n","        if ckpt.get('training_results') is not None:\n","            with open(results_file, 'w') as file:\n","                file.write(ckpt['training_results'])  # write results.txt\n","\n","        # epochs\n","        start_epoch = ckpt['epoch'] + 1\n","        if epochs < start_epoch:\n","            print('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n","                  (opt.weights, ckpt['epoch'], epochs))\n","            epochs += ckpt['epoch']  # finetune additional epochs\n","\n","        del ckpt\n","\n","    # Mixed precision training https://github.com/NVIDIA/apex\n","    if mixed_precision:\n","        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n","\n","\n","    scheduler.last_epoch = start_epoch - 1  # do not move\n","    # https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822\n","    # plot_lr_scheduler(optimizer, scheduler, epochs)\n","\n","    # Initialize distributed training\n","    if device.type != 'cpu' and torch.cuda.device_count() > 1 and torch.distributed.is_available():\n","        dist.init_process_group(backend='nccl',  # distributed backend\n","                                init_method='tcp://127.0.0.1:9999',  # init method\n","                                world_size=1,  # number of nodes\n","                                rank=0)  # node rank\n","        model = torch.nn.parallel.DistributedDataParallel(model)\n","        # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","    # Trainloader\n","    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n","                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect)\n","    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n","    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Correct your labels or your model.' % (mlc, nc, opt.cfg)\n","\n","    # Testloader\n","    testloader = create_dataloader(test_path, imgsz_test, batch_size, gs, opt,\n","                                   hyp=hyp, augment=False, cache=opt.cache_images, rect=True)[0]\n","\n","    # Model parameters\n","    hyp['cls'] *= nc / 80.  # scale coco-tuned hyp['cls'] to current dataset\n","    model.nc = nc  # attach number of classes to model\n","    model.hyp = hyp  # attach hyperparameters to model\n","    model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n","    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights\n","    model.names = data_dict['names']\n","\n","    # Class frequency\n","    labels = np.concatenate(dataset.labels, 0)\n","    c = torch.tensor(labels[:, 0])  # classes\n","    # cf = torch.bincount(c.long(), minlength=nc) + 1.\n","    # model._initialize_biases(cf.to(device))\n","    if tb_writer:\n","        plot_labels(labels)\n","        tb_writer.add_histogram('classes', c, 0)\n","\n","    # Check anchors\n","    if not opt.noautoanchor:\n","        check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n","\n","    # Exponential moving average\n","    ema = torch_utils.ModelEMA(model)\n","\n","    # Start training\n","    t0 = time.time()\n","    nb = len(dataloader)  # number of batches\n","    n_burn = max(3 * nb, 1e3)  # burn-in iterations, max(3 epochs, 1k iterations)\n","    maps = np.zeros(nc)  # mAP per class\n","    results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n","    print('Image sizes %g train, %g test' % (imgsz, imgsz_test))\n","    print('Using %g dataloader workers' % dataloader.num_workers)\n","    print('Starting training for %g epochs...' % epochs)\n","    # torch.autograd.set_detect_anomaly(True)\n","    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n","        model.train()\n","\n","        # Update image weights (optional)\n","        if dataset.image_weights:\n","            w = model.class_weights.cpu().numpy() * (1 - maps) ** 2  # class weights\n","            image_weights = labels_to_image_weights(dataset.labels, nc=nc, class_weights=w)\n","            dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # rand weighted idx\n","\n","        # Update mosaic border\n","        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n","        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n","\n","        mloss = torch.zeros(4, device=device)  # mean losses\n","        print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n","        pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n","        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n","            ni = i + nb * epoch  # number integrated batches (since train start)\n","            imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n","\n","            # Burn-in\n","            if ni <= n_burn:\n","                xi = [0, n_burn]  # x interp\n","                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # giou loss ratio (obj_loss = 1.0 or giou)\n","                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n","                for j, x in enumerate(optimizer.param_groups):\n","                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n","                    x['lr'] = np.interp(ni, xi, [0.1 if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n","                    if 'momentum' in x:\n","                        x['momentum'] = np.interp(ni, xi, [0.9, hyp['momentum']])\n","\n","            # Multi-scale\n","            if opt.multi_scale:\n","                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n","                sf = sz / max(imgs.shape[2:])  # scale factor\n","                if sf != 1:\n","                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n","                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n","\n","            # Forward\n","            pred = model(imgs)\n","\n","            # Loss\n","            loss, loss_items = compute_loss(pred, targets.to(device), model)\n","            if not torch.isfinite(loss):\n","                print('WARNING: non-finite loss, ending training ', loss_items)\n","                return results\n","\n","            # Backward\n","            if mixed_precision:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            # Optimize\n","            if ni % accumulate == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                ema.update(model)\n","\n","            # Print\n","            mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n","            mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n","            s = ('%10s' * 2 + '%10.4g' * 6) % (\n","                '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n","            pbar.set_description(s)\n","\n","            # Plot\n","            if ni < 3:\n","                f = 'train_batch%g.jpg' % ni  # filename\n","                result = plot_images(images=imgs, targets=targets, paths=paths, fname=f)\n","                if tb_writer and result is not None:\n","                    tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n","                    # tb_writer.add_graph(model, imgs)  # add model to tensorboard\n","\n","            # end batch ------------------------------------------------------------------------------------------------\n","\n","        # Scheduler\n","        scheduler.step()\n","\n","        # mAP\n","        ema.update_attr(model)\n","        final_epoch = epoch + 1 == epochs\n","        if not opt.notest or final_epoch:  # Calculate mAP\n","            results, maps, times = test.test(opt.data,\n","                                             batch_size=batch_size,\n","                                             imgsz=imgsz_test,\n","                                             save_json=final_epoch and opt.data.endswith(os.sep + 'coco.yaml'),\n","                                             model=ema.ema,\n","                                             single_cls=opt.single_cls,\n","                                             dataloader=testloader)\n","\n","        # Write\n","        with open(results_file, 'a') as f:\n","            f.write(s + '%10.4g' * 7 % results + '\\n')  # P, R, mAP, F1, test_losses=(GIoU, obj, cls)\n","        if len(opt.name) and opt.bucket:\n","            os.system('gsutil cp results.txt gs://%s/results/results%s.txt' % (opt.bucket, opt.name))\n","\n","        # Tensorboard\n","        if tb_writer:\n","            tags = ['train/giou_loss', 'train/obj_loss', 'train/cls_loss',\n","                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/F1',\n","                    'val/giou_loss', 'val/obj_loss', 'val/cls_loss']\n","            for x, tag in zip(list(mloss[:-1]) + list(results), tags):\n","                tb_writer.add_scalar(tag, x, epoch)\n","\n","        # Update best mAP\n","        fi = fitness(np.array(results).reshape(1, -1))  # fitness_i = weighted combination of [P, R, mAP, F1]\n","        if fi > best_fitness:\n","            best_fitness = fi\n","\n","        # Save model\n","        save = (not opt.nosave) or (final_epoch and not opt.evolve)\n","        if save:\n","            with open(results_file, 'r') as f:  # create checkpoint\n","                ckpt = {'epoch': epoch,\n","                        'best_fitness': best_fitness,\n","                        'training_results': f.read(),\n","                        'model': ema.ema,\n","                        'optimizer': None if final_epoch else optimizer.state_dict()}\n","\n","            # Save last, best and delete\n","            torch.save(ckpt, last)\n","            if (best_fitness == fi) and not final_epoch:\n","                torch.save(ckpt, best)\n","            del ckpt\n","\n","        # end epoch ----------------------------------------------------------------------------------------------------\n","    # end training\n","\n","    # Strip optimizers\n","    n = ('_' if len(opt.name) and not opt.name.isnumeric() else '') + opt.name\n","    fresults, flast, fbest = 'results%s.txt' % n, wdir + 'last%s.pt' % n, wdir + 'best%s.pt' % n\n","    for f1, f2 in zip([wdir + 'last.pt', wdir + 'best.pt', 'results.txt'], [flast, fbest, fresults]):\n","        if os.path.exists(f1):\n","            os.rename(f1, f2)  # rename\n","            ispt = f2.endswith('.pt')  # is *.pt\n","            strip_optimizer(f2) if ispt else None  # strip optimizer\n","            os.system('gsutil cp %s gs://%s/weights' % (f2, opt.bucket)) if opt.bucket and ispt else None  # upload\n","\n","    # Finish\n","    if not opt.evolve:\n","        plot_results()  # save as results.png\n","    print('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n","    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None\n","    torch.cuda.empty_cache()\n","    return results"],"execution_count":12,"outputs":[{"output_type":"stream","text":["{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9csFml3nfP7H","colab_type":"text"},"source":["# **Train Option**"]},{"cell_type":"code","metadata":{"id":"h0uu9IpAyJC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594568562692,"user_tz":-540,"elapsed":42947485,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"382f2174-a762-477d-c5d8-d329a75e5657"},"source":["check_git_status()\n","class opt:\n","    epochs=50                #parser.add_argument('--epochs', type=int, default=300)\n","    batch_size=2            #parser.add_argument('--batch-size', type=int, default=16)\n","    cfg=cfg_input           #parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='*.cfg path')\n","    data=data_input         #parser.add_argument('--data', type=str, default='data/coco128.yaml', help='*.data path')\n","    img_size=[1024, 1024]   #parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='train,test sizes')\n","    rect=False              #parser.add_argument('--rect', action='store_true', help='rectangular training')\n","    resume=False            #parser.add_argument('--resume', action='store_true', help='resume training from last.pt')\n","    nosave=False            #parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n","    notest=False            #parser.add_argument('--notest', action='store_true', help='only test final epoch')\n","    noautoanchor=False      #parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n","    evolve=False            #parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n","    bucket=''               #parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n","    cache_images=False      #parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n","    weights=weights_input   #parser.add_argument('--weights', type=str, default='', help='initial weights path')\n","    name=name_input         #parser.add_argument('--name', default='', help='renames results.txt to results_name.txt if supplied')\n","    device=''               #parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n","    adam=False              #parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n","    multi_scale=False       #parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%')\n","    single_cls=False        #parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n","\n","#parser = argparse.ArgumentParser()\n","#opt = parser.parse_args()\n","\n","opt.weights = last if opt.resume and not opt.weights else opt.weights\n","opt.cfg = check_file(opt.cfg)  # check file\n","opt.data = check_file(opt.data)  # check file\n","print(opt)\n","opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n","device = torch_utils.select_device(opt.device, apex=mixed_precision, batch_size=opt.batch_size)\n","if device.type == 'cpu':\n","    mixed_precision = False\n","\n","# Train\n","if not opt.evolve:\n","    tb_writer = SummaryWriter(comment=opt.name)\n","    print('Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/')\n","    train(hyp)\n","\n","# Evolve hyperparameters (optional)\n","else:\n","    tb_writer = None\n","    opt.notest, opt.nosave = True, True  # only test/save final epoch\n","    if opt.bucket:\n","        os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n","\n","    for _ in range(10):  # generations to evolve\n","        if os.path.exists('evolve.txt'):  # if evolve.txt exists: select best hyps and mutate\n","            # Select parent(s)\n","            parent = 'single'  # parent selection method: 'single' or 'weighted'\n","            x = np.loadtxt('evolve.txt', ndmin=2)\n","            n = min(5, len(x))  # number of previous results to consider\n","            x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n","            w = fitness(x) - fitness(x).min()  # weights\n","            if parent == 'single' or len(x) == 1:\n","                # x = x[random.randint(0, n - 1)]  # random selection\n","                x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n","            elif parent == 'weighted':\n","                x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n","\n","            # Mutate\n","            mp, s = 0.9, 0.2  # mutation probability, sigma\n","            npr = np.random\n","            npr.seed(int(time.time()))\n","            g = np.array([1, 1, 1, 1, 1, 1, 1, 0, .1, 1, 0, 1, 1, 1, 1, 1, 1, 1])  # gains\n","            ng = len(g)\n","            v = np.ones(ng)\n","            while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n","                v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n","            for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n","                hyp[k] = x[i + 7] * v[i]  # mutate\n","\n","        # Clip to limits\n","        keys = ['lr0', 'iou_t', 'momentum', 'weight_decay', 'hsv_s', 'hsv_v', 'translate', 'scale', 'fl_gamma']\n","        limits = [(1e-5, 1e-2), (0.00, 0.70), (0.60, 0.98), (0, 0.001), (0, .9), (0, .9), (0, .9), (0, .9), (0, 3)]\n","        for k, v in zip(keys, limits):\n","            hyp[k] = np.clip(hyp[k], v[0], v[1])\n","\n","        # Train mutation\n","        results = train(hyp.copy())\n","\n","        # Write mutation results\n","        print_mutation(hyp, results, opt.bucket)\n","\n","        # Plot results\n","        # plot_evolution_results(hyp)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["<class '__main__.opt'>\n","Using CUDA Apex device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n","  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  2                -1  1    315680  models.common.BottleneckCSP             [160, 160, 4]                 \n","  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n","  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n","  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n","  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n","  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n","  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n","  9                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1   5435520  models.common.BottleneckCSP             [1280, 640, 4, False]         \n"," 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1   1360960  models.common.BottleneckCSP             [640, 320, 4, False]          \n"," 18                -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n"," 19                -2  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 21                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n"," 22                -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n"," 23                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 25                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 26                -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n"," 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [1, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n","Model Summary: 407 layers, 8.84337e+07 parameters, 8.84337e+07 gradients\n","\n","Optimizer groups: 134 .bias, 142 conv.weight, 131 other\n"],"name":"stdout"},{"output_type":"stream","text":["Reading image shapes: 100%|██████████| 2697/2697 [00:00<00:00, 12498.88it/s]\n","Caching labels /content/labels/train (2697 found, 0 missing, 0 empty, 0 duplicate, for 2697 images): 100%|██████████| 2697/2697 [00:00<00:00, 4915.73it/s]\n","Reading image shapes: 100%|██████████| 676/676 [00:00<00:00, 11970.93it/s]\n","Caching labels /content/labels/valid (490 found, 0 missing, 0 empty, 0 duplicate, for 676 images):  72%|███████▏  | 490/676 [00:00<00:00, 4896.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving labels to /content/labels/train.npy for faster future loading\n"],"name":"stdout"},{"output_type":"stream","text":["\rCaching labels /content/labels/valid (676 found, 0 missing, 0 empty, 0 duplicate, for 676 images): 100%|██████████| 676/676 [00:00<00:00, 4779.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Analyzing anchors... Best Possible Recall (BPR) = 0.9992\n","Image sizes 1024 train, 1024 test\n","Using 2 dataloader workers\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      0/49     4.95G   0.07327    0.1843         0    0.2576        68      1024: 100%|██████████| 1349/1349 [12:45<00:00,  1.76it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [02:07<00:00,  2.64it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.211       0.941       0.682       0.217\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      1/49     5.34G   0.05708    0.1599         0     0.217        33      1024: 100%|██████████| 1349/1349 [12:18<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:56<00:00,  2.90it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.482       0.946       0.899       0.394\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      2/49     5.34G   0.05392    0.1536         0    0.2075        88      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:55<00:00,  2.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.551       0.944       0.897       0.421\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      3/49     5.34G   0.04651    0.1501         0    0.1966        30      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.693       0.941       0.933        0.47\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      4/49     5.34G   0.04151    0.1466         0    0.1881        44      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.661       0.949       0.938       0.491\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      5/49     5.34G    0.0405    0.1443         0    0.1848        32      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.72       0.947       0.941       0.508\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      6/49     5.34G    0.0394    0.1436         0     0.183        76      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.69       0.947       0.939       0.489\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      7/49     5.34G   0.03795    0.1423         0    0.1803       102      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.698       0.948       0.939       0.498\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      8/49     5.34G   0.03798    0.1417         0    0.1797        24      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.717       0.949       0.944        0.52\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      9/49     5.34G   0.03749    0.1393         0    0.1768        41      1024: 100%|██████████| 1349/1349 [12:13<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.728       0.948       0.943       0.511\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     10/49     5.34G   0.03686    0.1383         0    0.1751        41      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.753       0.948       0.946       0.523\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     11/49     5.34G   0.03663     0.138         0    0.1746       123      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.758       0.949       0.946       0.526\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     12/49     5.34G   0.03609    0.1374         0    0.1735        60      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.74        0.95       0.945       0.523\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     13/49     5.34G   0.03569    0.1378         0    0.1735       119      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:46<00:00,  3.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.721       0.953       0.947       0.525\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     14/49     5.34G    0.0359    0.1387         0    0.1746        35      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.743       0.949       0.946        0.53\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     15/49     5.34G   0.03512    0.1354         0    0.1705        24      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.746       0.947       0.944       0.527\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     16/49     5.34G   0.03487    0.1352         0    0.1701       152      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:46<00:00,  3.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.73       0.952       0.947        0.53\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     17/49     5.34G   0.03498    0.1358         0    0.1707        62      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:46<00:00,  3.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.751       0.948       0.946       0.528\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     18/49     5.34G   0.03441    0.1326         0     0.167        42      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.759       0.949       0.947       0.534\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     19/49     5.34G   0.03451    0.1348         0    0.1693        27      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.754       0.949       0.946       0.533\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     20/49     5.34G   0.03421    0.1346         0    0.1688        25      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:50<00:00,  3.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.768       0.948       0.947       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     21/49     5.34G   0.03417    0.1343         0    0.1685        41      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.758       0.949       0.947       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     22/49     5.34G   0.03383    0.1334         0    0.1672        62      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.764       0.946       0.945       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     23/49     5.34G   0.03366    0.1327         0    0.1663        36      1024: 100%|██████████| 1349/1349 [12:16<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.762       0.949       0.948       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     24/49     5.34G   0.03364     0.133         0    0.1666       165      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.763        0.95       0.948       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     25/49     5.34G   0.03344    0.1326         0     0.166        55      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.769       0.949       0.947       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     26/49     5.34G   0.03329    0.1326         0    0.1659        96      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.77       0.948       0.946       0.536\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     27/49     5.34G   0.03317    0.1309         0    0.1641        34      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.765        0.95       0.948        0.54\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     28/49     5.34G   0.03306    0.1307         0    0.1638         7      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.776       0.945       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     29/49     5.34G   0.03284    0.1292         0     0.162        78      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.779       0.947       0.947       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     30/49     5.34G   0.03262    0.1283         0    0.1609        34      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.11it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.782       0.949       0.948       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     31/49     5.34G    0.0326    0.1288         0    0.1614       121      1024: 100%|██████████| 1349/1349 [12:13<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.774       0.947       0.947       0.541\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     32/49     5.34G   0.03262    0.1295         0    0.1622        41      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.778       0.946       0.946       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     33/49     5.34G   0.03241    0.1298         0    0.1622       110      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.781       0.947       0.946       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     34/49     5.34G    0.0324    0.1294         0    0.1618        55      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.776       0.948       0.947       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     35/49     5.34G   0.03203     0.127         0     0.159        45      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.78       0.947       0.947       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     36/49     5.34G   0.03213    0.1271         0    0.1593        25      1024: 100%|██████████| 1349/1349 [12:13<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.786       0.945       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     37/49     5.34G   0.03205    0.1285         0    0.1605        61      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.783       0.944       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     38/49     5.34G   0.03201    0.1265         0    0.1585        27      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.778       0.947       0.946       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     39/49     5.34G   0.03196    0.1257         0    0.1577        38      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.788       0.946       0.946       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     40/49     5.34G   0.03181     0.125         0    0.1568        24      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:48<00:00,  3.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.782       0.946       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     41/49     5.34G   0.03173    0.1255         0    0.1573        29      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.787       0.944       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     42/49     5.34G   0.03168    0.1255         0    0.1572        29      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.784       0.945       0.945       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     43/49     5.34G    0.0317    0.1266         0    0.1583        48      1024: 100%|██████████| 1349/1349 [12:14<00:00,  1.84it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:47<00:00,  3.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.784       0.945       0.946       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     44/49     5.34G   0.03156    0.1242         0    0.1557        30      1024: 100%|██████████| 1349/1349 [12:15<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.787       0.945       0.944       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     45/49     5.34G   0.03143    0.1249         0    0.1563        48      1024: 100%|██████████| 1349/1349 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:49<00:00,  3.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.788       0.945       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     46/49     5.34G   0.03143    0.1244         0    0.1559        44      1024: 100%|██████████| 1349/1349 [12:17<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:51<00:00,  3.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.789       0.945       0.946       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     47/49     5.34G   0.03151    0.1255         0     0.157       134      1024: 100%|██████████| 1349/1349 [12:18<00:00,  1.83it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:51<00:00,  3.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.789       0.945       0.944       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     48/49     5.34G   0.03127    0.1238         0    0.1551        38      1024: 100%|██████████| 1349/1349 [12:19<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:52<00:00,  3.00it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04       0.793       0.944       0.945       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     49/49     5.34G   0.03137    0.1244         0    0.1557        27      1024: 100%|██████████| 1349/1349 [12:21<00:00,  1.82it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 338/338 [01:51<00:00,  3.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         676    2.95e+04        0.79       0.944       0.945       0.538\n","Optimizer stripped from weights/last_x-b2-e50-fold1.pt\n","Optimizer stripped from weights/best_x-b2-e50-fold1.pt\n","50 epochs completed in 11.793 hours.\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1YAAAGmCAYAAAB/URVbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxcZfX/32eyp0m3NG1pS1q6idBNuiCKVJayCqLIJkuBQkFZflpEWVxAEVGgKlKEQoGyi8gXUIvYL1D8srdIWwqU7k0XQtN0TdKsc35/3OfO3Ewm6WRPJuf9euWVO/c+995nkmfuPOc553yOqCqGYRiGYRiGYRhG8wl1dAcMwzAMwzAMwzC6OmZYGYZhGIZhGIZhtBAzrAzDMAzDMAzDMFqIGVaGYRiGYRiGYRgtxAwrwzAMwzAMwzCMFmKGlWEYhmEYhmEYRgsxw8owkhgR+bqINFpTQUReEpEb26tPRvdFRG4WkUXtcJ+PROS8wOuJIrJURPaKyCMicp6IfNSefTCM5iAiBSJSKiIFCbS9UUReao9+GUZrEfu9ICKLROTmjutRyzDDqp0QkfEi8hcRKRKRMhEpFJEFIvItd7xJE46GBp6bNDzSah03OjVuwviiiOwQkXIR+cR9uaYleg1VPUlVb2ul/lwkIhta41pG10RExonIM+5ZVyoi60TkUREZ0159UNVDVfWJwK7fAItUNVdVL1LVJ1T10Na4l4gMExEVkWH76YORJLjv3yo3vveIyAoRmdEW91LVQlXNUdXCBNrepqontUU/jOQmzpj+SEQu6+h+dUXMsGoHRORY4B1gC/BlIBf4AvAn4Nsd2DWjCyMixwBvAB8DhwC9gcuBi4DnRcQ+30a7IiJfB97Fe9YdjvesmwS8CXyz43rGcGBpB97fSD5uU9UcoA9wO/CgG/91aMoil2F0MP6Y7g3cAtwvIkd1cJ+6HDbxah/uA55S1VmqukFVw6q6T1VfUtUL4p0gIn1F5CER2Soi20TkbyIypJ37bXRu/gz8TVWvV9UiVa1S1f/gTWCPB87yG4rId0VkvYjsEpHnRCQ/cKyO91NEBovIkyKyxY29p2LaZ4vIb0RkjQutWi0iZ4jI1/DGuh+6UioipwdW9M8XkeXunLdE5ODANVNE5FrncdstIu+7BQn/+HgRed31f6c7/gV37GgRWeLOKxGRN0WkT5v8xY39cT/wjKr+UFU3qscOVb1fVX8d21hErnQro3vdeJsjItmB42e543tEZLuI/G/g2FUistad+3nQUy8iG5z3NEVESvEMq/vcmDwj1rMqIqkicp0bf3tFZKOIXOmOHSAi/3SfhT0istgtavj4IYUfuevfFexD4B5HunG/y312rheRlMBxFZHvuzal7rPyleb+I4z2QVVrVfVxoASY6P6P/09E3hWRcuAEEckUkdvceN0pIv8RkS8FryMiF4vIMvcc+0xEbnX763hE9/MsjA2panQeIV6EyxMico97dhZJFw7BMloHN0d9BtgBTAEQkcPFmyuUuOfjr0Qk1T9HvJDVp9xzfLf7TvbH5Zki8l+3/3M35vp1zLtre8ywamNEZDQwEniyiac+DgwGxgEjgHLgxeAXsdF9ceNqNPBI7DFV/QR4D/hGYPfZwGHAQUAm8GgD180AXgE2uesPB2qoO37nAUcDJ6tqLnAMsFpV/w+4AvBDV3JU9fnAeRcA04B8oAiYEzj2M+A8PKOwD3Ar8IKIjHDH73X96ufOnwHscsced9fqDRwA/Aioivf+jLZDREbhjZnHmnDaZ3j/857AsXgLAje562Xj/W+vVtWewBDgtsC9fgd8043BEcBDsRd3k94coBC4wo3Jv8Xpx6+Ay4DzXV8mAYvdsRTgQbzPTj/gBeB/AhMDP6TwUHf9a2MvLiJDgX/jfe7y8SIVvg/8v5iml+J9TnoDr9O0v6XRATij/AKgL9ExczkwHeiB99y6D5gIHIX3//8L8LKI9HbXuBzP6/VDd52DgX81cMvGnoWxJDKPOANvrPV32zeJt0hmdFPcmP4ukAd86gyk/8X7nh2AN45PBX7i2mcDrwJleGOtD9643OsuuRfv89AX73MwHPhje72f9sYMq7bHX+nf4u9wK5e7nPVe4b50CRw/ADgJ+KGqblfVvcBVwHhgcnt13OjU1BtXMWzG+6L0uV5Vd6rqTuBa4EQ3zmI5Bch27ctUtRTPUDlORIaI57k6B2+SugpAVTep6vIE+nyLqn6uqhV4k+ApgWM/BK5T1VVutex/gP8DznXHq4ACYKiq1qjqUlX9PHBsBDDIee3eVtWyBPpjtC7+eGtoTNZDVZ9T1TXOs7USb9J4XKBJNfBFEemnqhWq+qrbXwMIcKiI9FTVUuetbTIiInjP1x+r6vuuL8Wq+p7r42ZV/R/3eahS1VsBpWnP4u8CK1T1PlWtdp+X3wEzY9rdqaprVbUGz/s3XETymvO+jDbnehHZhbdI9APgosAYvEtVV6qq4j1PpwPfV9Ut7vk1B8/D5S9+XQP8RlVfdYsBu1X1jQbu29izMEIT5hH/UdW/uvu+CSyj7rPZ6D74Y7oCb1HnRlX9O3Al8LwbJzWquhEvb/Vid94peAtS31PVEvcdvkxVtwKo6r9U9UM3xjbjPfuOi715smCGVdtT7H4P9neo6huq2hvvAZeBN0EIcqD7vS5wzm53LV8ZqBqIF7ud5o4ZyU29cRXDEGBb4PX6ONsHUp9RwCBgpzP+dwGfApV4Y2+Ya/dpM/q8NbBdCuQAiMgAvIfy//j3dPc9iuj7uwhvMvuqiGwSkd+LSA937DS8FbD3xQtL/IV5djsEf7w1NCbrISLfEZF3xAvz2w38GmegqWo5cCLeF/CnLjTuKndsPZ6BfzFQ6MKuzop/l/3SD28sxh3TgXCqDeKFAu7CG6/947VvgAMJPM8da4g+z31iPyPg5akZnY/bVbW3qvZT1YmqGowCCD5vR7rf78c834biPafBe64m+ky9iIafhUESmUdA3TEH3rizMdc9ud3NTfsAD+MtqKbizQvOjBm/DwAD3XnDgPWqGnfuKV64/iIXBrgHz2hryvOzS2GGVRvjVvXX4q1YJsom9/sgf4eI9MSbAPjKQOvxBnsso9z9jCTGjas1wIWxx5zbfgrwz8DuYXG2N8e5dBGwzk0Ygj+ZqvoWsMG1G91A18IJv4ko/grZiTH37KGq3wNQL1/nMlUdiheGeDzwY3fsQ1X9rqoOBM7EC7Gq93cx2hZVXQ2swgvp3C8u1+MvwJ3AYFXthRcGGFloUtX/U9Vv4T37rgHuFJGj3bEXVPVEd+wu4KlA6GhT2I43mWxoTN+O9yz+KtALb9KxJ9DPRMb8JgLPc8cIos9zI7kIjoki9/uQmOdbtqre7o5toOHxV4fGnoUxJDKPMIx6OO/mlXhj50q8MfxozPjtqV6YNXjj9yCJI9QiIunA34HngeHqhXXH1RZIFsywah++D3xXRO4SkaEiEnK5LEfGa6yqn+HFV88WkX4ikoOnIPgR0Rju+cA3xUvETheRLPGSrQ/Fm6wYyc/3gbPES4oeICJpInIkXg7IK8Azgba/EZE+4ok63AH823fTx/AckCleEnQvABHpLyJnA6hqMfAUcK/Lc8GFCI5z5xcB+dIE8QhVrcTLQbhDRL4oHlkicpTLJfNl3Ie4sK09eKFgtW7sXyxRcY3dQK37Mdqfy4GzReQO8ZKZRUR6i8gMqV8rLRfvO2i7qla6MXSlf1BEBoqX9NzbhVTtwluprxWRL4jIySKS48LmduMZOk3+v7tr/wn4rYh8yfU5X0T8cKlewD5gJ15+4q04b6ujGG8i/YVGbvMUMFZEZrrP6Ri8yfCDTe2v0bVwYVPP4z0zhwKISK6InCTRcOw/AjeIyFTxBFd6uWd5PRp6Fsa5byLzCMOIi/te/iXwU7xc7rMC880UERkpIie65v/AG4v3OA9/SLyyG4OAdLzn5i5VLROR4cD17f+O2g8zrNoBVf038BU89/t7eIl8q/FWdk8HNsY57Xzgc+BDPO9ULnCqqta6a74JfAe4Dm8yW4iXEH2cC5MxkhxVXQh8DRgLrMR7sM3DS1g+zR8rjr8C/8VbWaqhgRUjt1J1BN5K1YfObf8WXliez2V48tkvi6e49hrRcJdX8Txla1zIwGkJvp0f4RmCf8WbQG8AbiAa7no03menFC8H4G08AxG8z8FHIlKGl4T9iPsbGO2Mqi7CGz9DgSV4z7oP8Mbp8zFtP8H70v6LG2d3UldURfDEUNa5cfYsXsz/f/C+rG8Ctrhz7wIuUNUNzez6z/HGzdOuz0vwBCzAE1bphWdAfYr3XI54e1V1H3AjMN+N+d/FXtz160S80MXteIsfc4HfN7O/Rtfiu3hy/wtFZC/eOLoM5/VU1bl4n4V78J5/K4ETGrhWY8/CWBqdRxjGfngMTxnwOLzxeDleDm0J3vN4KESegcfiefM/xluEegjIUS9P+3Lgl+45/oT7SVrEW6wzDKO7IiL/B7ykrVQk2DAMwzAMoztiHivD6Ma4mPuReB5UwzAMwzAMo5mYYWUY3RQROQIvwfk/xIRpGYZhGIZhGE3DDCvD6KaoV++pl6qe3ZBMqmEYhmF0RURktIi8LSKr3O96SspOJOcF8co5fCIi5weO3Swi20RkqfuZE+f8r4tIrbhSEIZhhpVhGIZhGIaRbNwHzFHV0cAcvKLbscwGlqjqODyRpttEJFjj8VFVneB+rgyeKCK5wG+Bl9qm+0ZXxAwrwzAMwzAMI2kQkf7AYXilDnC/DwuU5vAZjydL75cTWQokWmx8Np4i4/YWd9hIGlI7ugPNoV+/fjps2LCO7obRCrz//vvbVTX2QZdU2HhNHmy8Gl0JG69GV6KVx+uBwJZAiZpaEdnq9hcHbwucIyJLgGF4pXE2BI6fIyLH45W1+YWqvg0gIicBvVT1WRH5RmMdEZGZwEyAHj16TDz44INb4e0ZHUljY7VLGlbDhg1jyZIlHd0NoxUQkXg1vJIKG6/Jg41Xoyth49XoSnTQeL0Wr57cUrx6oK/g1XoEL5Tw16paLSLTgBdE5It4BZlvB6YlcgNXp2wuwKRJk9TGa9ensbHaJQ0rwzAMwzC6BiIyGpgP5OEVF71QVVfHtOkPPIznUUjDKzx+jarWYBhNZxMwWERSnLcqBRjk9kdw4X9BwYoFeEVuUdWiQLuFIrIJGINnWB0AvCciAP2AU0Wkr6r+sm3fltHZsRwrwzAMwzDakkREBG4EPnEiAuOAicC326+LRjKhqtvwvFDnul3nAh84QyqCiOSJSKrbPgYYCzzpXg8OtJuAFyr4qaq+oar9VXWYqg4DnsULEzSjyjCPlWEYhmEYbUNARMAPm3oKuEdE8mMmuQrkikgIyADSgS3t2lkj2bgCmC8iPwd2AhdCxCv1c1VdAkwB7haRWjwRilNVtdydf5uITMTzUFUBFwS9WIYRj6QwrApLypkxfzHrissYnt+DedMnU5CX3dHdMox6BMfq2EE53Hb8ICRsJaS6CgsXLhy7bNmyDR3dj1YkDKyoqam5dOLEids6ujNGUpKoiMCvgL8BnwE9gHtU9c14FwyKARQUFLRh143WoKPmaKq6Ejg8zv6TA9svAfXqW7lj0xO8z0XN7GK7YnPl9iEpDKuz577NZ7srAFhbXMqM+YtZOGtqB/fKMOozY/5i1mwrRYFvjEinOiWDcaNH4OK0jU5ObW1tzZgxY5JGWjccDktxcfEhRUVFDwKndXR/jG7NmcBy4FggF3hJRL6jqs/GNowVA2jXXnYTmjMJ989Zu62UlBShplZJTRGqa6P/otXbSjnqjtcY1T/HJvbtzAUPvcvGEs8ZZ3PltiMpDKvP91REtsMK64rLOrA3htEw64rL8L9iCnqnIRm5ZlQZHUYoFNL8/PzdRUVFYzq6L0bSkpCIAHA1cImqhoHdIvICcDRe/orRRjRkQAUXAdcWl3LhQ++SEhLWby9jSJ8sQiIUlpRHDKiUkFATjhpQYWdMBY2qIGu22cS+vSncUR7Ztrly25EUhtXAXpls3eUZVyGB4fk9OrhHhhGf4fk9Il9WIYTMtJSO7pLRzQmFQt5wNIw2QFW3iYgvIvA4DYgIAOuBE/GU1tKB44Dn2rWzXZzCknIuevg9NpaU1zGS4hlP4EVQrN5WGjk/6E1aU1waWQQMK2woiU7KC3fsi2z7BlTQqEoExSb27U1ej3S2l1YBNlduS5LCsPrxCQfzg78sBWBEfk7koWEYnY150ydzxp/fpLi0ChEY2s/CIAzDSHoSERH4AXCfiHwIpODJrT/QQf3tEgRD70IxHqM1zsuUlhKKazylxrQPEmzfVtjEvv35xrhBPPLWBsDmym1JUhhWw/p5H87xQ3rxwlVHdnBvDKNhCvKymXX8F7jhuQ/JSk8hI9U8VoZhJDcJigisJcGCq4bHxY+8x1rn9QnHGEka42WKpakepqaSFsixqg0rI/Jz+NU3x/CzF1bU85wZ7UNqyEs7OPygvvzl8iM6uDfJS1IYVplpXhRLRXW4g3tiGPvHH6/ajVKuN2zYwKRJk9i+3dN9uPnmm7nxxhtJT09v0/sOGzaMf/zjH4wZUzeFKBwOc+aZZ7JixQoyMzPp378/9913HyNGjGjyPURk4qhRo/aFQt7/9dFHH10/ZcqUfQBPPvlkr5tuumlIbW2tjB07tvzpp5/ekJubG/dBdc011wz6+9//3qdv374177///qcN3W/WrFmDSktLQ3Pnzt0ce+zuu+/OW7BgQa9//etf69avX592zjnnHPTxxx9nDx06tHLFihWfNPnNGYbRJiQqDhErCOEbKfOmT263ULqQeOGAPsNcP4M5VqkxfWtIlMJyqjqOsiqv1nZFdW0H9yS5SQ7Dyq3677PBYnQB/PGqzbCs2ksutaamhtTUtns83HLLLfzoRz9qc8OqMaZPn843vvENQqEQ99xzDzNnzuSVV15p1rUWL168slevXnUMpt27d4euueaaYa+99trKsWPHVp599tlDb7nllgF33nnnZ/GuMXfu3IHr1q1bPmjQoJpmdSKGnj17hm+55Zatu3btSrn11lsHtcY1DcNoHS6Z/x5rt5VFxCEaEnIIikj4+Uyrt5Vy9F2LaMnanACpKUI47IXk+d6kYBhgSKCgbzZpKSGT6E4CSiu9ObLNlduWpDCsstK9iapZ4UZXwBesCH4pDrv+n02+jh8rnwgbbj9lv21EhF/84hf885//5MQTT+S6665j1qxZLF++nIqKCo4++mhmz55NSkoKt9xyC0899RSZmZmICK+99hq7du2q45WK9VL5XHnllQB85StfIRQKsWjRIp555hl+//vfk5GRQTgc5plnnuHggw+O289bb72V//73vzz33HOUl5dz+OGH89vf/paTTz45bvvHH3+chQsXsnv3bn7wgx9w1VVXEQqFOO20qLr4EUccwR/+8IcG/zbvvvsu119/PUVFRZmhUOiLP/vZz7aec845uxv7e/7tb3/rNXbs2LKxY8dWuvddfMkllxwUz7CaOHHiFyorK+XrX//66KOPPnrP/fffv/mmm24a+Mwzz+QBjB8/vmzevHmFscZbRUWFXHLJJQVvvvlmbp8+fWrGjBkTif3Jy8urPfHEE0v/8Y9/5DbWT8Mw2h/fqALPG7R2WylH/vZVtuzcR6rvBQoJ1Q2E7NXG7E8LeIyqa8MU7iiv42Ua1T9+KF7QSFo4a6rVOkpiyiu9NTszrNqWpDCszGNlJIqIjAbmA3lACXChqq6OaXM8cBswFviTqv4ocKw/8DBeccs0vATra1Q1YS9DRicOBczKymLx4sUAXHrppUydOpUHH3yQcDjMeeedx0MPPcQZZ5zB73//ez777DOysrLYu3cvWVlZ7Nq1K6F7zJkzh3vvvZe33nqLnJwcAK677jpWrlzJAQccQGVlJbW1DX+Wb7zxRk488UT+9Kc/8cEHH3DSSSc1aFQBbNu2jffff5/PP/+cL33pSxx11FGMGzeuTpt77rmnjqEVZNeuXVxxxRUsWLCAkpKSitzc3DVTpkz54nHHHfdRv379agG++tWvfqGmpkaOPfbY3XfeeefWrKws3bhxY/qQIUOq/OuMGDGiqqioKK6L7v333/9URCb6nq9nnnmm5zPPPJP37rvvftK7d+/wGWecMez6668/4M9//vOW4Hl33XVX/saNG9NXrVr1UVVVlRxxxBFfGDJkSGWDfwzDMJpNc42O2PNuPX1MPW9TGNi801Pb8yXKGzKqYkkRYfWvo8/Axvq5v1C8grxsC9dLUkor/VBAS5tpS1psWCU4UU0B7saTUlXgdlV90B17FAjOcsYBp6vqi4n2ITPdm6hW2mAx9s99wBxVfVxEzgfuB46JabMOuBT4DpAZc+xG4BNVPUVE0oA3gG8DzyTagXgeq0Q8SgDTZr/O2uJSwuqFaYzIz2nVL8Hp06OF5l988UXee+897rrrLgDKy8sZMmQIvXr1YuTIkVx44YUcf/zxfOMb3yA3t2VOkWOOOYbp06dz6qmncsoppzB8+PAG24ZCIR5//HEmTJhAQUEBb7zxRqPXnjFjBgADBgzglFNOYdGiRXUMq9/97nd88sknvPrqq3HPf+utt1i/fj0nnXQS+/btyxSRUSLCxx9/nHHUUUeVr169evnIkSOrd+zYETrzzDMP+slPfnLA3XffvbUZf4YICxcu7Pmtb31rR9++fcMAV1xxxfZZs2YdCNQxrF5//fXc888/vyQjI0MzMjL0rLPOKnnrrbdyWnJvwzCiBI0UkajoQ1MKrAZlzVdvK+Wcue8AXjheU9bXfK9USsjzaCnx1fXMODLiEcmxqjInRFvSGrVL/InqaGAO3kQ1lvOAkcAo4AjgZhEZBqCqF6rqBFWdAEzHk2J9uSkdSE8JIQJVteF67nHD8HHepsOAp9yup4DDRCQ/2E5V16jqUiCeF0qBXBEJARlAOjGT3f3RkhyredMnMyI/hxSRNpFL9T1I4PXv+eefZ+nSpSxdupRVq1Zxxx13kJKSwjvvvMNVV13F5s2bmThxIsuXLyc1NZVwOLq4UVFREe8WcXnuuee49dZbKSsr4+ijj+all15qtP369esJhULs2rWLffu8Vd6XX36ZCRMmMGHCBO64446E7vunP/2JJ598kgULFpCd7a3oPvzww5HrPPHEE6gq48aNY+nSpfztb3+rWLly5cdFRUXLjzrqqHKAkSNHVgP07ds3PGPGjO3vvvtuDsDQoUOrNm/eHPFQrV27Nn3gwIFVABdccEHBwQcffMjBBx98yLJlyzIS/kMZhtGuzJi/mDXFpdSq1i2Am0CB1cKScqbNfr2efHnkKgnWhg+JF8q3+tcns+43p/DKrK8zsn/bfQ8YyUm55Vi1Cy3yWAUmqr5E6lPAPSKSH1P872zgAVdRvVhEngfOBGJnPzOAJ1S1SaEsIkJmagr7qmupqK6lR0ZSRDgarc+BwBZVrQVQ1VoR2er2xxarbIhfAX8DPgN6APeo6ptN6URLVAHbcyXytNNO4/bbb+fPf/4zKSkpbN++nb1799KvXz9KS0uZOnUqU6dO5e2332bFihWcddZZVFdXs2bNGkaOHMmTTz7Z4LVzc3PZvXs3OTk51NTUsHHjRqZMmcKUKVNYu3ZtJMQvHjt37uS8887j6aefZuHChVx22WU8/fTTnHDCCZxwwgn12j/yyCN89atfpbi4mAULFnDNNdcAcP/99zN37lxeffVV+vbtG2l/8cUXc/HFF9e53+rVq3nttdfIz/ds8Ndffz37a1/7WnlJSUlKVlZWOCcnR6urq3n22Wf7jBkzZh/At771rd3XXXddwYcffpgxduzYyjlz5uR/85vf3AHw2GOPFTb2t582bdqen/70p0NuuOGGz3v16hWeO3duv6lTp+6Jbff1r399z5NPPpl36aWX7qisrJS//vWveYMHD7ZQQMNoJdYVl8V9VkscT1FsCF51bZiNjUie+9eNVd2LJ1UeNJ7MI2U0Bz8UsCasVNeGSUuxuvBtQUstkEQnqgXAxsDrQtcmgqu0/l28autNJivdDCujXTgTWA4cC+QCL4nId1T12WAjEZkJzAQoKCioc4F4oYCdkT/84Q/8+Mc/Zvz48YgIGRkZ/OEPfyAtLY0zzjiDffv2EQ6HOeyww/j2t79Namoqf/zjH5k2bRr5+fmcckrD4Y3XXnstxxxzDFlZWbz88stcdNFF7Nq1i1AoxIEHHsjtt9/e4LmXXHIJl1xyCUceeSRHHHEExx57LPfddx9XXHFF3Pb9+vVj4sSJ7N69mxtuuIGxY8eyd+9evve97zF06FCmTfPWhTIyMnj33Xfrnd+nTx9efPFFrrvuOrZu3ZpZU1NzaEFBQeUrr7yyZtmyZZnf//73h4oINTU1MmnSpNLZs2dvceeF//jHP2489dRTR4XDYQ499NDyX/ziF58n8rc/66yz9ixbtmzHlClTvggwbty4st/85jf1RC9mzZq1/cMPP8weOXLkmD59+tRMmDChrLi4OBU8ZcfBgwePq6qqktLS0pQBAwaMO++887bPnj27RWGKhtGdGNYvO1IrCqJGUFZaSsTYKSwpr1NTCoiEbMeSluIV5lU11T2jfSmrjAbhVFTXmmHVRkhzwpEiJ4tMBB5V1UMD+z4GzlfV/wb2fQhcoqqL3esfA0NU9ZpAm7OA61X1sAbuFZyoTty4cWOd41/5zSts3V3BGz85miF97KHUVRCR91V1Ujvdqz+wCshziwApeHmBo2I8rH77m4GcGPGKFXhj+T33+idAgape2dB9J02apEuWLIm83lFWxWG/WshD3zyAY46IO9yNTsqKFSvKx4wZ0271oJYvX55x4YUXHrRr167U3r171zz22GPrfZVBn5qaGi6++OKCRYsW9RQRfvCDHxTNmjWrjhTjsmXLMr785S8fcsEFFxTHq3+1bNmyfuPHjx8G9cer0XVpz+drR9HW4/WxtzfysxdWAF443uyzxnPm/W9TUR2O5LlW1YTZuKNhzxREc2LnTZ9sqnsNYOO17QiHleE3Loi8fu+mY+mfG5tCbiRKY2O1pebqJmCwm6D6IhWD3P4ghcDQwOuCOG0uAR5q6KZ6T4IAACAASURBVEaqOldVJ6nqJD8cJ0hmRHLdBCyM+KjqNmApcK7bdS7wQTyjqhHW44mw+F7W44AVTelHJBSwKScZ3ZKZM2cOnTlz5rYNGzasmDlz5rbLLrtsaGyb++67L2/9+vUZGzZsWPHOO++s/O1vfzvo008/jeR21dTUcNlllw077rjjEpNtNAwjwvsbdwDwkxMPZuGsqYwd0juSJxtWzzPVkFGVnuIlUUnAqPLD+Nb+5mQWzppqRlUbIiKjReRtEVnlfo+K02agiLwgIstF5BMnauUfu1lEtonIUvczJ3BsjoisFJFlIvKmiHRqgzA2r6qiyubKbUWLDKsmTFT/ClwmIiEnFHA6EAmdEpEhwNeAJ5rbF/9BZ7WsjP1wBXC1iKwCrnavEZEF/oNRRI4Ukc3ALOByEdksIn7yzg+Arzkv7FI8D9gDTelA8Eu5JR7jZGfSpEkREQn/p6Fwv2Rky5YtqR999FH2zJkzdwDMnDlzx0cffZS9devWOrHOzz77bJ8ZM2ZsT0lJYdCgQTUnnHDCrscff7yPf/ymm24aeOKJJ+4aNWqU5V4ZRhOorKnllU+2AXDSmIGR/XsqqiPbjellVdUqIvCv//c1M6I6hkTE1WYDS1R1HHAUcJuIBFNVHvUF1mIiU14CxqrqeOA3wF/a5i20DsEwQICKGpsrtxWtkYx0BTBfRH6Op+h3IXgTVeDnqroEeAw4HPBl2H+pqusD15gO/F1Vdza3E74XwAwrozFUdSXeWIzdf3Jg+w1gSAPnryUq1tIsQiEhPSUqYCEJKkN1N7p7ONq6devSBwwYUJ2a6j2mU1NT6d+/f/W6devSBw0aFPmW3Lp1a/rw4cMjRlNBQUHlpk2b0gHefvvtrFdeeaXXO++88+mPf/zjQQ3d68knn8yZMGHCEnd+m70nw+gqFJaUc87ct9lbWUN6SohQ4EE9Ij+nntKfACERhuf3YGdZFdvLvBJ2qnDVkx+Y2EQ70wRxtfHA7wFUtVhElgJnAXc1dn1V/Ufg5dvAEBEJOZG2TkdpjGG1zyTX24wWZ66p6kpVPVxVR7vfn7r9JzujClWtVdXvqeoI9zM35hq/VtVzWtKPLAsFNLoQGWkhFKU2bOPVaBsqKyvl8ssvH3r//fdv9I2zeITDYfnud7+7p7FQa8PobsyYv5itu72SEdW1YWbMXxw5Nm/6ZA7sk1Wn/anjB0XC+3aWV9c5tj9ZdqNNqCeuBvjiakHeB84Rj4OAr1A3deUcFyb4bxE5ooF7XQX8s7MaVQDlMYZUMDTQLwsw4oYFTJv9OoWNKFka+ydpJEH88CrT5ze6AplpKWzcVU1JyQ4LBzTiMnz48KrPP/88rabGSeTW1LBt27a04cOHVwXbDRo0qGrdunWRWliFhYUZBx54YFVhYWHapk2bMk477bRRgwcPHvvAAw/0f+qpp/qde+65kUlDOByW4uLiXjQxT9Awujr7m0yuLY56pJS6xlFBXjb/95NjGDOoZ2Tfko07ItcYnt8jEokQr4Cv0am4FhiAF9p/N/AK0RqW9wEHuTDBO4AXRCQveLKInIOnaP29hm4gIjNFZImILCkubkpKd+sR67EKRnf5BaxrVSOFr43mkzS65FHxCjOsjM5PZlqIP727k6+O2M3OHdv3f4LRKSgqKkqtra3t1173Gz58eM2vfvWrod/+9rfLnnvuuR4jRoyoLi4u7h38cj7yyCNr7r333kETJkxI2bFjR+ill17qO2/evKLy8vKeixYtihSv/uMf/9i7vLxcrr/++rJly5b57yEMrKipqbm0vd6TYXQGLnrkvYix5E8mF86aSmFJOefPe7dO7lRDxlFJWXSNo2h3ReQa8ZT/jHYnIq4WUAGuJ67mwgKDghULgI/dsaJAu4UisgkYA7zu2n4L+DVwrKo2WErDRWnNBU8VsHXeXtOol2MVmCsHFw0SKXxtNE7yGFbmsTK6EJmpKWyqDJPSawBfGJjb0d0xEuSQQw75sD3lgJcvX37w8uXL5//yl7/sA3wOXDh+/PhPgzmsEyZMSAHuOeyww44HaoHvn3baaXNjr/Xwww/fDOQ8/fTTP4o9ZhjdjQ3b408mZ8xfTGGMyl9sgV6fbXuiejDBa1gB345HVbe5fKlzgcdpQFzNeaB2q2qNiBwDjAW+444NVtUtbnsCMAz41L3+Bp7wxTRV3dAub6oF1MuxCsyVg7XazMPacpLHsHLiFZVmWBldAL9IsHlYjcZIUGyllkbCUALtbm7VzhlGF6Zvj3S2l3oeJwlMJoMhgAApIg0aScPze0QKAduEtFOSiLjaFOBuEakFtgOnqqpvWd/m6rXWAlXABQEv1sNu37MSFTY5VlVL2uF9NZl6OVYBufU7zxzPt+59C/AKVpuHtWUkjWGVlWbiFUbXwVQsDcPoLojIaGA+kIdXlP1CVV0d0+ZRYFxg1zjgdFV9sS36dOTIfjy/dCsAfbLTIpPJzLSUyCR0f8aShfx1bhJcmHoJqFffyh2b3si1u5TKT2OhgHk9Iim6PGgFq1tM0hhWvgfAQgGNrkDEY1VjCwGGYSQ9fj2hx10B1vuBY4INVPVCf1tExgOvAi+3VYd2BJT7Cvr2oCAvm1Wf76W8qhahblHfhrCQP6Or0FgoYJ1tk2FvMUljWGWZeIXRhciwgtaGYXQDmlBPKMgM4AlVbbOi1htLojlWyzfv4sPNuzjvwXcB6JmVxt+vOtJW7o2kwffCZqd7HtmKBgyr8qqaeucaTSNp5NYzUr23Yh4roytgoYCGYXQTEq0nBICIpOPJVz/U0AWbI19dWFLOsXctYsQNCzhu9iI27ShHBCYO7UNY4ZwH3mFPhTep3FNRbZLTRlLhe6z65XhhfxUNeKnKbU7SYpLGsLICwUZXwg8FrLTxahiGEeR0oFBVlzbUQFXnNrWg9dlz32ZtcZmr1VNGWGFQrywmD+sDQFlldEKpJjltJBllEcMqHajrhGjIyDKaR9IYVpkWWmV0ISIeqxobr4ZhJDWRekIADdUTCnAJjXirmkvR7orItl+TvaBvNgs+LKrX1hT+jGTDN6zynMcqqApYNxTQ5iQtJXkMK5OvNroQthBgGEZ3QFW3AX49IWignhCAiAwBvgY80dr96JmVFr2P+z2sXzZbdu6r13Z/ohWG0dXwPbK+x6ohL5Wl07ScpDGsstItZ8XoOmRaeQDDMLoPVwBXi8gq4Gr3GhFZICLBgtvTgb+r6s7W7sAUF/IH0ZzsoXk9GJ7fg5CztEICo/rnsHDWVBOuMJKKsqpGcqzqGFkmXtFSkkYV0PcAmLVtdAVMvMIwjO5CIvWE3Otft1Ufwhrd9stcDHXFUK0WlZHs+OIVeT0az7GyUMCWkzyGlYlXGF0I81gZhmG0H3sr6q/ED83rYbWojG5BuQsFjORYNRQKaIZVi0maUEDLWTG6EhmRAsE2Xg3DMNqaPRXV9fYNtXA/o5tQFiO33lBelXmsWk7yGFYWWmUkgIiMFpG3RWSV+z0qTpvjXY2UShG5M+bYoyKyNPATFpHTmtqPzFQbr4ZhGO2FHwqV7aJbAE6f8yaFJeUd1SXDaBdUNZBj5YUCVtZEo2WCkTNmWLWcpDGsrI6VkSD3AXNUdTQwB7g/Tpt1wKXAHbEHVPVCVZ2gqhPwEq13Ai83tRNWx8owDKP98EMBQyKRfWuLS60QsJH07KuuJayeaEuPDC8DqCGP1b5qE69oKUljWJl4hbE/RKQ/cBjwlNv1FHCYiNSpMKmqa1xxyv09YWYAT6hqZVP7YuUBDMMw2gdVjXisygOqZ2ErBGx0A3yp9ZyMVLLS6s+VTbyidUkawyrqsbJBYTTIgcAWVa0FcL+3uv1NQkTSge/SzEKWViDYMAyjfSivqqU2rGSmhRiRn4ME5NWtELCR7Pj5VT0yUuPOlU28onVJGsPKr0tRWRMmHNRVNYy24XSg0Hm26iEiM12e1pLi4np1ME0V0DAMo53wwwBzM9OYN30yI/NzSBGxQsBGtyCYXxhvrryvgZpWRvNIGrl1ESEjNURlTZjKmnDEKjeMAJuAwSKSoqq1IpICDHL7m8olNOKtUtW5wFyASZMm1bP0TcXSMAyjfdjrFAFzM1NNXr0bISKjgflAHlACXKiqq2PaDMTLtT4ISAN+raqPu2M3A9/Hi2wBeFNVr3THsoGHgYl4aQM/UtV/tPV7ag5+eF9ORioiQmZaiIrqMBU1tWSnp5oqYCuTNB4riIYDmsVtxENVtwFLgXPdrnOBD1S1vkupEURkCPA14Inm9sVULA3DMNqHvZVRj5XRrUhErGo2sERVxwFHAbeJSDA94FFfsMo3qhw/Avao6kjgVOBBEclpm7fRMoKhgEA0z8oZUQ2FBRrNI6kMK/MCGAlwBXC1iKwCrnavEZEFIjLJbR8pIpuBWcDlIrJZRE4IXGM68HdV3dncTlgooGEYRvsQCQXMSJogHWM/JCpWBYwH/gXgFlmXAmclcIuzcYaa84ItAU5qec9bn9KIYeXNO7IidTS9+UfQmAqKuzSFwpJypv7uNYbf8E+mzX69W5cxSKqnjAlYGPtDVVcCh8fZf3Jg+w1gSCPX+HVL+5GR5sc521g1DMNoS4KhgEa3oZ5YlYj4YlXBKJX3gXNEZAkwDPgKsCFw/BwROR4oAn6hqm+7/QXAxkC7QpohhNUeRDxW6d74z4zxWLVGKOAl8xezcYdnTPllDBbOmkphSTkz5i9mbXFpJKexIMkLcyeVx8pPyrNQQKOzYx4rwzCM9iEqXmGGlVGPa4EBeJ6qu4FXiJZauQ84yIUJ3gG8ICJ5Tb3B/sSs2pLCknLu/PenAPz7488pLCmvV+4l6IyorAlT2wwBuHXFpZHtYBmDGfMXs2ZbKWGFNdu6R924pDKsbLJqdBUsbNVIBBEZLSJvi8gq93tUnDYpIjJHRNaKyBoRuTRw7Gci8pGILBeR92NCWg2jWxD1WFmOVTciIlYF3nOSOGJVqlqsquer6nhVPRXIBT52x4pUtdptL3TnjnGnFgJDA5cqiL124B5zVXWSqk7Kz4+NRGxbZsxfTElpFQB79lUzY/7ietFdsXlVzXFO9M/NrPPaL2OwrrgM30xTukfduKQyrLKs6KrRRUhLEUICNWGlptYWAowGSST5+jxgJDAKOAK4WUSGuWPvAZPdiuslwF9EJKutO20YnQnzWHU/EhWrEpE8EUl128cAY4En3evBgXYT8EIFP3W7/gpc7o6NAibjcrU6E/EMm2CRYFWNGFK9s72Fh+bkWR1/6IDIdkZqKFLGIFgnTugedeNabFi1dEXVHT9LRD4UkRXu94DYaySCKa0ZXQVP8rRuAqlhBGlC8vXZwAOqGnaThueBMwFU9WVV9bOIl+N9tzU5lMUwujLBOlZGt2K/YlXAFOATEVkJ/BI4NfDMvM3NS5cBDwAXqGqRO3YH0FtE1gD/AGaq6t72eVuJM6xfNJ9JXEFsf668r6qWqtowYYX0lBA5Ttyloqrpc5LPdldEtqtqw/TM8q41b/pk0lO8+/XOTusWdeNaY/nGX1F9XETOx1tRPSamTXBFNQ/4QET+V1U3uMF9M3CMqhaJSC+gsjkdMbl1oyuRmZZCeVUtFdW1kQeaYQRINPk60STqC4G1qro59oCIzARmAhQUFLRO7w2jk2CqgN2TBMWqXsKbm8Y7f3oj1y7DLWC1FYUl5Vz0yHts2F7GQf168PBFU+oJPxSWlPPdB99h6659ccUhZhw5nBv/50MARrrjv3t5JeDNlX0jKjMtRLabQ5dXN91jtbJoDwD9czPYtreSd9fv4IRDB1KQl03PrFS2l1Zx+pcGJ71wBbTQY9UaK6rAD4E7/VUAVd2tqhU0g2jeinkAjM5PZqp5WI32QUSmAr8iGhZTh47MATCMtsZUAY2uyIz5i1lfXBYRg4gn/HDJ/PfYvHMfYY2q8QX5cMsuAK6dNpqFs6ZSkJcdCQWsrA5HHBFZ6SlkOdXApioDllbWsGnHPtJTQpw1yVvTe3ttCQDhsLKjzMvx6i5znZaGAtZbUcWrUB27WtrYiuohwHAR+Y+I/FdEfioi0pzOZJrcutGFMLEVYz8klHzNfpKoReQI4HHgdFX9FMNoZxJJGXDtWiUtIBYLBTS6IokIPwT3BdX4wDNqXvlkGwDHfLF/ZH9mIMfKny9npqWQHSPDniifFnkRkCP75zB6gFcj+ZG3NjBt9uus2LobX2SwuVLuXY3OIF6RAowDpgFT8QqsXRDbKBG5SlNaM7oSGSa2YjRCosnXeEnUl4lIyEULnA48CyAik4G/AN9R1f+2T88Nox77FWEJpAVMU9UxwJHA7ta4+d5K81gZXY9YoYd4wg8De0XV+PwcKnAFe+94jW17K0kJSZ10g2DaTMRjlZYSDQVsogHkhwEefEAud7+6OrJ/bXEpVz/5QeR1Uw22rkpLDavWWFEtBJ5V1UqX+PcCXjJhHRIJVTHxCqMrkWlFgo39k0jy9WPAOmA18A7wS1Vd747dC2QB94vIUvcztl3fgdGtaULKQKulBcRSaqqARhdk3vTJ9HRjNicjNa7ww7lTojmxg3plRdrMmL+YzTv3AVAbVi6dvyTSLljHal/AY5UVMayalmPle6wOHpjL+uLyyP6wwqad0dfdRf+gRYZVa6yo4slaHi8eacCxwLLm9CcoIWkYnR3LCTT2h6quVNXDVXW0+/2p23+yqi5x27Wq+j1VHeF+5gbOn6yq+ao6IfDzYUe9H6NbkmjKQMJpAU0tuGqhgEZXpCAvmxPHDARg8rA+cYUfyiqj893rTzo40iYYRui/9gnOlSuqoh6rrGaGAq78zDesetaTVw/WtzKPVeK0dEX1aWAbXkG2pcBHwLzmdMRyVoyuhHlYDcMwIiSUFgBNF1uxOlZGV6Wm1jOP/DEcS9AjtL00Kqhdx8CRuq8jc4+q2jriFc0JBdxYUsaSjTsA+MWLH/Grb46J1MPq2yOdsydH10+6i9OjxYZVK6yohlV1lqp+UVUPddvNsoxMvMLoSthCgGEY3YCmpAzsNy2gqVRUe7V60lKEjNTOkFZuGIlT7ZQf9jhly1g274hvWM2bPpmQ8/celNejThhh0GMVzLHyVQGbYgBd9PDiiDjFxpIyfvbCCv7fsZ42zUljB9bxmpnHqgviy1d3F6vY6NpkmniFYRhJThNSBlotLSBIMAywmYLDhtFhVNd4C68Neaz8PCqA7XurItt5Oele4d/UEK9cO7VOGGFWenRR1zd2MgPiFU0xgDaW1FclHNw7C4AtO/dREjD2YufmhSXlHHvXIkbcsIBps1+nsKScZCCp/OKZAW1+w+jsRNzxJl5hGEZycwUwX0R+DuzEK1aNiCwAfu6iW54GJuGlBYSBl2lmWkAQq2FldGVqwg0bVmWVNZSURY2poMdq6y7P4BrcO6vegoJ/rReXbeXtdV69qaz0UEKhgIUl5cyYv5h1xWUMz+/BgJ6ZfLbb05gJuZDDQc6w2rqrggyXSx7vuhc9/B7rtnuGmV+Da+GsqQ3eu6uQVE8aE68wuhIZJl5hGEY3QFVXAofH2X9yYDsMzHI/rUZppeVXGV2XapdjVVpZQ21YSQlFjaSgtwpge8DI2hIwrGK5d9Ga6Dl7PWMsK6AKWLy3gmmzX2fttlJSUoTasDIiP4d50ydz4UPvssF5ltYWl5Kfkx65lt+mZ5b3Wdu6a19kG+rPzTfE8XYlA0kVCrhnn7cy9erKbUnlVjSSEwsFNAzDaFsioYAZpghodD18jxVEywb4bHbCFcNcmJ9vJEHUsBrUO5NYinZHqxj4OVDBOlaLPi1mzbZSwniGXVhhjfMobdxRV069uNQz5k48dCALZ3khh72y0shOT2FvZQ3rt0eNpaqaMLXhaNZVv5yMyHZI4tfp6ooklWE1+39XRbZ9t6JhBBGR0SLytoiscr9HxWlzvJPyrRSRO+McP0tEPhSRFe73gOb0JVLHygwrwzCMNsFCAY2uTHVN1BCJFbDY5IycLxX0AbxQQFWvfTQUsL5E+7C8upLo4Im/+VFfeytr6ohOAKjzKGWnRUP7QhI1jnICny8RiXjKtpdW1blO0Gs17ZDo1GlYjMBGVyapDCt/IEFyuRWNVuU+YI6qjgbmAPfHabMOuBS4I/aAKyFwMzBNVccARwK7m9ORiMeqxkIBDcMw2oI9bpU/xwwrowtSHfBYxeZZbXKhgKMH5JKVlkJlTTgS+rplZ8Meq4cvnhwxqPzPRVAV0F/0jWV4fg9SU6LHRuTncNYkT049J6Pu52tQIAQxJNDHSbAHhTHKKqPvZ855h8Wt09UVSSrDakR+TmQ7VrffMESkP3AY8JTb9RRwmCtaHUFV16jqUiCeDM8PgTtVtci13a2qFXHa7Zdy91B54D/rLHTVMAyjDfAnoz2tOLDRBfHrWEHU++rjhwIO6ZNFv1wv18n3EEVyrPrUz7EamteD0QNyASjo6xkzQVVADbir0lI8E0yAm075Irtdys2wvGwWzppKmjO0Yj3Cwfv27ZFBD2d4BQ2rLQFnSNGeZk2jOiVJZVjNmz45Ymkf0DMzadyKRqtxILBFVWvBq68GbHX7E+UQYLiI/EdE/isiP5U4Gr4iMtOFEy4pLo5VFfZ4erFXxkWx0FXDMIy2wEIBja5MdW3UY7Un1mO1wzNMDuybHQnJ85UBt+7yDJV44hXgGWPgzT3Aeax8ZW0XRXP6hEGs/vXJfGFALgq89GFRvb409PkK3jevR3pccTm/jwCf7zbDqlNSkJfNuVMKADjvy0OTxq1odCpSgHHANGAqcBJwQWwjVZ2rqpNUdVJ+fn7sYaCuNKqFrhqGYbQuhSXlPPLmBgCeeq/QogK6GQnmVA8UkRdEZLmIfCIi58dp8wURKQ/mXLtrLxKRpe68m9viPQQNq6DHqrCknJVFewCY9ZelEcNl+95KamrDFO2pQAQG9qofCgieMQZRVeKgx8pnzOBeABwxIg+A5z7YHDm2Z181qhoJPcyJEYepY1jlpEcUB33Dyu+jj3msOjGHDvIGwsdb93RwT4xOyCZgsIikALjfg9z+RCkEnlXVSlXdC7wATGlOZ/wHGySXIo5hGEZnYMb8xexyoUslpVUWFdD9SCSnejawRFXHAUcBt4lIJIrFzRPuB56POe93eHOBCcBk4GIRadZcoDFqwsFQwKjH6qJH3sM/tKGkjBVbvFTv7WVVfL63ktqwkp+TUaeOVJAhMSGCWekpZKfX9TqNjTGsqgNhiTVhZV91LXsr4+cwDqpjWGVEDL/yKq+930efz/dUkiwknWF1yAE9Afj4MzOsjLqo6jZgKXCu23Uu8IGqxo/Vi8+TwPHikQYcCyxrTn+CoarD85NHEccwDKMzEIwCUCwqoDuRaE41MB74F4CbCywFzgocvx74B7Aq5jwFerntbPd6W2v136ehHKsN2+vWgPKNru17KyPCFfHyq3yG9Kkb0RWsY+VzqDOsvnxQHn7CQ2pI6OmMqL0VNdFyBo3kWOX1iHqs/PIyW2JqcH1uHqvOy8j+OaSlCOu3l0VclIYR4ArgahFZBVztXiMiC5ziHyJypIhsxitUebmIbBaRE9z5T+M9PD/GewB/BMxrTkdG9s+JrBrdf8EkC101DMNoRYJRACZo1e1INKf6feAct1h6EPAVYCiAiIwHTgB+H+f6PwDOFpEtwAbgDlXdEK8jieRcN0RDOVb9c+vWgArmWG2N1LBq2LA6sG+MxyomFHB4vx4Rpb9e2WmMdOJwvqcKvHDAUj/HKkYVcEBuRqSYcV6P9Mi1y514hd/HoW7eU2Q5Vp2X9NQQo/p7aicrzWtlxKCqK1X1cFUd7X5/6vafrKpL3PYbqjpEVXuqaq7bftkdC6vqLFX9oqoe6rabrZfuP1Qs9t8wDKN1eeDCSZHt4f0sKsCIy7XAALyF0ruBV4AaF5EyF7jCN85iuBx4TFUHAyOAa0Tk8Hg3SCTnuiEayrE6acwBgKfWNyI/h6uOGQl4hpWvtjekEcOqnscqPURaSohUZwz5+VU+xYGccD8kcE9FdTTHKsZjtXVXRUTS/bF3NkbC/nxVQL+Ph7kaXOax6uQcMsjCAY2uQUFfbwW1cIcZVoZhGK2JL/HcOzuNV679ukUFdC8SyqlW1WJVPV9Vx6vqqUAuXkTKAXgG0wIR2YDnobpMROa6U68B5rtrfAa8ipej1aoEQwGDHqsd5Z6s+u++M46Fs6byhYGeQ2HLzn3c//paAJ7775YGF217ZaVFQvrAE68oLCkn7LTW31q7vc65e/dV17vGnkAoYGwdqxnzF0fyw4r3VvLO2hIgKl7hG1bjhvQiJSSUlFVRWVPXfi0sKWfa7NcZccOCLlWSJikNq0FOBeUXL3zUpf4ZRvfD91httDFqGIbRqkRq+TSycm8kJ4nmVItInoikuu1jgLHAk6paqKr9VHWYqg4D/gA8oKoz3anrgRPdebnA14AVrf0+GioQvN7lWPnhrX4o4MqivREDbHtpZaOCLUEBray0FGbMXxwRxIgVexmen0MoprCMFwro51jVVQWMzW/0+xTxWLkcqwP7ZEfCGrfFCFjMmL+YNdtKqVVlTRcqSZOUhtVz/90CWH0go/Mz1D3YCndYUrVhGEZr4k/eGss1MZKa/eZU46n6fiIiK4FfAqeqaiIrnRcBV4jIMuBd4BlVfam130Adj5XzGqkq653hclA/L/ep0pcxDyjt7U+w5cBAOGBWekqjYi/zpk9mRH4OKRIVr9i9r5rSqvgeq+H5PSKGWEigT7ZnePkeq2Ae2ICenjMkNhxwXXEZ/rvRLlSSJikr5m3dHVUbsfpARmfGXzEyj5VhGEbrstU8Vt0aVV0J1Mt7UtWTA9svAfXqW8U55+aY1+/jCV20GaoaI7fuGVbbS6vYW1lDr6y0iMHyg78srXf+/sq4BCXXM1NTGJ7fg7XFpYS1/rkFedksnDUVgNtfWsl9r6+laHcFfIikrgAAIABJREFUqpCdnhIRqvCZN30yM+YvZl1xGcPze3DMwf25/z/r2FdVi6pGvcl9shjQ0/NYxdayGtYvm7WB+XtXEZ9JSo/VCKdeAlYfyOjcRMQrdpQTDjxADcMwjJYRSeJvRHbaMDorwbpREA0FXFdcCsBB/XogTgc9ngNhRH5Oo4It/sJuRmqIUEjqeKUaO9eXVvcXLmK9VRA1xNb+5mQWzprKAS5FZ191Lbv3VVNeVUtORio9M1MZ6DxWscqA151wcGQ7My3UZcRnktKwmjd9MilusA3NMyUgo/OSm5lG3x7pVNaE66juGIZhGC1js4UCGl2YmnBdwWHfsIrkV/WLOg2G5/eI1JoKCYzqn8PCWVMbFWzJSPNMgMqaMNNmvw5Qxxhq6NyeWZ6XbOsuzxCKrWEVj6yA3PqSjTsBKK2s4fjf/yfSj9hQwOCcKDUUqicR31lJSsOqIC+bEf29AXfveYeZEpDRqSmwcEAjDiIyWkTeFpFV7ne9cBURSRGROSKyVkTWiMiliRwzjPYkwbF8s4hsE5Gl7mdOS+9roYBGV6a6xvNY5WakEhLP21NdG44YVgcFDKt50yczMgFvU5A/v7Y2st0UPQI/x8r3COfECFfEIyvdO2dfdS0/ez6q8bG2uJQXlm4F4PMY8YoVm3dHtksrayILJZ2dpMyxAujbIx2AHWVVHdwTw2icoXnZLN20i40lZUw5qG9Hd8foPNwHzFHVx0XkfOB+4JiYNucBI/FyBPKAD0Tkf12hysaOGUZ7kshYBnhUVX/UWjcN5nEYRlfDVwRMSw2RG0pj975q9lbUsM43rBrIgUqUoKHSFD0C32Ple5hiiwPHIyvN81hVVNXWyaUKa1QN8MVlW/nksz3Mmz6ZgrxsVmz1DKuemansqahhZdHeOkqGnZWk9FiBGVZG16G3e0j9+NnlVh7AAEBE+gOHAU+5XU8Bh4lIbHXJs/EkgMNORvh54MwEjhlGu9CEsdyqlFbWsHtfNRmpIfLcfMAwuhK+ImBaikTC7fZWVMf1WDWHWOW+RPUIfI+VL6wRL8cqluxAKGCfrKiHKyREihJD1HNWWVPLqs/3IgLfGD8IgJVdpDatGVaG0cH866MiwMoDGHU4ENiiqrUA7vdWtz9IAbAx8Low0KaxY3UQkZkiskRElhQXF8drYhjNJdGxDHCOiCwXkX+LyBEtuWkwDNBP8DeMrkR1reexSg2FInWidpVXs7GkdQyrRMUqYukZE/qXSI5VpvNY7auu5YgR/QAQ8QQ2ajUq0uF7zj4t2kt1rTK8Xw8OK+gDwMrP9ybUv44miQ0rT76xxAwro5NTvDcaV2zlAYyOQFXnquokVZ2Un9+mjgTDaIj7gINUdRxwB/CCiOTFa5jIQoBfw8rCAI2uim9YpaVEa0e9sWZ7RC3wm/e82aIIl1jlvkT1CHpm1TWschIwrHyP1b6qWspd7au5F0xi4aypdZS8xXnOPtzihQGOHdyLgwfmAuax6nD6Om3/nWZYGZ2coPvdygMYjk3AYBFJAU+IAhjk9gcpBIYGXhcE2jR2zDDai4TGsqoWqWq1217ojo+Jd8FEFgI2+wVIe5lhZXRN/FC71JSox+reRWsixzsqwqWex6oJOVb7qmsjIhV+/ap50yfTI8M73j83g199cwy/fWkl4BmSGakhUkLC+u1lVLgCwz6FJeV8/Y7XGHHDgk6TSpG8hlWO9w+zUECjs/PQ9ClkObnRAT0zrTyAgapuA5YC57pd5wIfuFypIH8FLhORkMtZOR14NoFjhtEuJDqWRWRwYHsCMAz4tDn3LCwpZ/a/vVMXfvJ5p5hsGUZTiXqsQhGPVVll1LDoqAiXzLRQnbyoRDxWvtz6vupatrkonf65Xv2qgrxsLvvacABOnzCYn72wgj1OWr6ktIrLHl1CSLz3O+33dY2n6Q+/x4aScmpVO00qRfIaVtmWY2V0DQrysrl86ggATjh0oJUHMHyuAK4WkVXA1e41IrJARCa5No8B64DVwDvAL1V1fQLHDKM9SWQs3yYiK0RkGfAAcIGqFjXnZjPmL2ZneTXgRa10hsmWYTSVeOIVQToqwkVE6oQD5iYkt+4ZVqUVNZSUVSIC/XKiojIHD+wJwMqivXWMRQU2lJRHwh8379hX5/Ps55tB50mlaLHcuoiMBubjyfmWABeq6uqYNinA3cCJeH+n21X1QXfsZuD7eMmsAG+q6pUt7ZeJVxhdCV9m/b31Ozq4J0ZnQVVXAofH2X9yYLsW+F4D5zd4zDDakwTH8vTWul/sxKwzTLYMo6lExSsEDez3nUVNEZxobXpmpkbm14moAgZDAQH65WSQmhL17UTyqIr20L9nBp/t9iTZfU+VT+zneUDPzEhboXOkUrSGx8qvTzEamINXnyKWYD2VI4CbRWRY4PijqjrB/bTYqIKoYWXiFUZX4LCC/8/em8fJVZX5/+9PdzprJwSSDms6IRsqIAoJioNsigvqiDPKokBAJIAzzCjKfEVHZHRUHAQdBxwWQeKg6KCOzE8CyiDBDSEBIossWQjNFtIJ2TqdpZfn98c5t+p2dVV39VpLP+/X676q7r3n3ntu1VO3znOebU9G19bw1LqtbIkzrY7jOE7fSQ+u5HGrToWSWGlG1daw5PFXMtuNoFT1JeHEYJO2UhXjClhXW0NdbdZ9cNrEMV32N+41nnF1tby6dReH7r8HEBSl2Q31zJwynnRez/Tv+cy3ZsOI9xhXVxahFANSrAap1sqQsOeEmLyidTdm1ktrZ6QgaZ6kByQ9G1/n5mnzrphxapekb+bsu1zSekkr4nLtYPRrbF0th03fAzNYttatVo7jOP3lpoULGDMqDG8O2HNcWQy2HKevtMcCwaNra7p4X1kZuLxNGpdVpopJXgHZlOuQTVyRUFMjDopWq/ueWQ/Aj857K/dcfCw/+Phb2GePEI81fnRtl99zbSrWa9/J48oilGKgFqvBqLUCRdSu6GudlTGjaqkfM4qOTmPrjvY+3JJT5RRjYV0DfIKQ8jcfg25hBTIPlfN+sLxssts4juNUGo1TxjN9rzDAunnhgrIYbDlOX2nPWKxCnSn1o5jvUJHODFhMjBVk3QEhm7giTeIO2NZhjBlVw5sbJwPh93zjWSEUs3Gv8V1+z5t3ZD18nnpla1mE/5RD8oqialf0p85KJs6qtfQftFN6irWwmtkqM1sBDKtG/punwyyNFwp2HMcZGLvb42z/qHIY5jhO39mdKhB808IFzOlHMd+hYlIfXQEhW8sKulusIKtYARwxY88cC1dQxF7durPLMZtzxvcPrtlYVF+GkoE+cQZca6UvtSv6SjaBxa5eWjojhGItrL0x6BZWgFe3eKFgx3GcwWBXewiSHzOqtpeWTrVSpOv/PpLuiP/pT0k6I0+bgyS15gkNuEjS05Iel7RisPufzgrY32K+Q0U6S2ExySugqytgw6TuFqs9J2SzBD6zblsXr50pE0YzqkZsam3rUstqc4xJP3BKsOB98oePlNzjZ0CK1WDUWhnM2hW5ZBJYtLjFyhk0hszC2iXgmtKb+h3HcSqVXdFiNcYtViOZYlz/rwaWx//0Ywhp/zOTrdFgcD0hNwCp7X9DyBWwwMwOBd492J1PYqzqastPhtPp1otVrLpYrCZ2t1j9+/9lE4q/1tq1TEJNjTIJL9ZvzU5CJ4rVlp1hnF8OHj+D8W0NtNbKoNWuyCVRrDa5K6ATKNbCWpChtLDetHABe44PD6vJ48sju43jOE4lsqstKlZ15TcodYaePiRXOwy4GyAaBVYAp6T2fw74JfBsznGfAS43s23x2FcH9QZIZwVULy2Hn6Rg8YTRtV0SSPTEuJRiNS2Pxer5lJUpX4KOvWMCi3Upd8AkxmpzKptyqT1+BvzEMbOnzewtZjYvvj4Tt59kZsvj+w4zu9DMZsflhtTxC83sEDM7zMwWmNmSgfYpwVOuO2n6YGEtyFBaWBunjOeqUw4DYFZDfclN/Y7jOJVK4go4ugxn+51hoVjX/4cJ7v2SdCDwNmLoiqTDCJaob+U5/xuAt0r6Y3T7P69QR/oTGgDZOlZ1NeUnw4nFqtj4KshNXtHdYjWrYUKmRle+BB37TMqjWEXDSeNehVOyDzfl920NIhmLlStWTpZeLaySjpb0InAxcL6kFyUlZv4hs7ACHDFjLyR47MXN7Njd0fsBjuM4ThfaOzrptJCKeZQrVk7PfAbYmzDp+h3gXqBdUh1wA3BBopzlUEtQ0o4GTgL+SdIx+S7QW2hA08ZWjrvyPmZdemeX+KD2JHlFGVqsdkaL8KtbdxUd0zRudFYJa8ijWN20cAGze0jQkSSwWN9FsQqWqv884whmTs0qU1/+4MF9uJvBpXhVswLZa7xbrJyumNnTwFvybD8p9f73wAEFjl84dL0LBe7esO8knnx5K482beJtc6YO5eUcx3GqDo+vcki5/ptZRyHX/+ixkklYIWkJ8BdgX2A2sEQhz/nksFuTzGwRISnbbWbWCayXdA9wJPDbvnb03MXLWBsVkyQ+6J6Lj824ApZjjNV3l67KvE/3uSfGRbfcKRNG572nJEFHIZJaVuu2BMVqZ1sHO9o6GFUjXrfPRO777HFceOvD3PXEOj5644PMmRaUs+H2/im/b2sQcYuVU4m85cCQC+NPz3mhYMdxnL7iipVTrOu/pCmSRsX3JwCHAj8ysyYzm2pmM81sJvBt4MaoVAH8CHhPPG4C8Hbgz/3pazoeKB0flE1eUX4Wq1c2Z61GxcY0jY8Wq3zxVcWQ6wq4NcZXTR5fR1R+efLlrUBpk1hU9VNnz0y6dVesnMoh8Q3+zr0rS5421HEcp9LwVOtOpJjkakcCT0l6Gvgy8AEzK+ZP91vAdElPAg8Bt8aEVn2mUEbgbPKK8huq9xYPlY+kttxTr2zt19gmt5bVptZEscqmaX9p047M+94UvqaNrZx49f3MvnTJoI61yu/bGkSmePIKpwK5+ffPZd6XOm2o4zhOpZFkBPTiwCObIpOr3WVmc83sdWZ2tJnlrUdlZpeb2WdT6zvM7EwzOzgu3+hvP68784jM+70njc3EFmWTV5Sfxaq3eKh83P1kNhy9P2ObfXKyAiaJKyanUr/3pWzNObc8xMr1LXSYDepYq6pjrFp3twPw4qYdnHj1/SXxtXScvpJOOVrqtKGO4ziVxu4OdwV0Kod0hrxFx8zKjFPbyzjGqrd4qHxsTpU+6s/YZu9J4XN6desuzCyTan3y+KxiddPCBXzgmt+zZUcbU+pH96jwrdmQ3wVzoJTftzWI/OOPsxMPPvPvVAqzGiaUTdpQx3GcSsNrWDmVRJJhD2BDS7b4bVsmK2B1yPHshnrUR/fBNONHj2Li2FHsbu9kU2tb1mKVcgVsnDKef3zHXADeffA+GSW1aWMr77hqKbMuvZN3Rre/CakshepHfwpRHd9WAQoFBDpOOXPTwgVdfuClTBvqOI5TaXiMlVNJ7GzLZnPvqlglFqvycwXsDzctXMCcProP5pJJYLFlZybVetoVEGBGoky9lvX+OXfxMtY0b6fTYPX6YGhJuwpPmdCzdasvVLUr4KyGCaxc3wL07mvpOOVC45Tx3PuZ4zj/B8v51V9eLWnaUMdxnErDswI6lUQyEQCwoSXrLpdkBRxVhjFW/aE/7oO57LPHWFaub+HVrTvzugJCVrFKh1Wsad6OxfdJxsBOyx7zun0mAXDi1fezpnk7sxom9HvMVdVPnZsWLmBirArdMHHMoGmjjjMcPPHyFqC0aUMdx3EGiqR5kh6Q9Gx8ndtD24MktUr6Zn+vlwxUPXmFUwmkXQE35rNYuRxnmDAmjOk/vngZP/zT8wDskXIFBDhgz/FI8NLmHRl3ygP2GtelTX08z9vnTqVG8OBzGznr5gcHJZlFVX9bjVPGs/ComQCcfmSjz/Y7FcW6LdkHbKfByvUtnn7dcZxK5DrgWjObB1wLXJ+vUSziej3wi4FcbLdbrJwKoqsrYNZilc0K6HKc8OCajQCYwdadIUHdnjkWq7F1tewzaSwdncbLm0P69fcdum+XNsmx7z1kXw7Zbw/aOixTpBkGFj5U9d/WfpODlvrS5h29tHSc8mJWw4RMoGfCKrdcOY5TQUiaBhwO3BY33QYcLqkhT/PPAb8Enh3INbOugB5j5ZQ/aYtVc0vIeAfQnkleUR2ugINB4v6XZvK40d225boDPtK0CYBzjz6wS7ujZk/Jqx8MJJlF1StW++8ZFKuXXbFyKowk0DONeRIWx3Eqi+nAS2bWARBfX47bM0g6DHg3ofDqgMhkBXSLlVMB7EhZrHa3d7JtV7CmtHWWb4HgUjFjr+6eZ7kxVqFdUIqef62VLTvaWLZ2E7U14h9OmMv+k8dm2i36wXI2tXavdbtvqp5YX6n6byv5AN1i5VQaSaDn3Gn1XSxXHWbuEljlSBov6SeSVkl6WtL7e2h7Xmy3WtI1kmri9g9KeljSE5KelPSZ4bsDxykeSXXADcAFiQLWS/tFkpZLWt7c3NxtfyYroKdbdyqAtCsgwIZtIQwgsViNdotVhsUfP7JbMo98ilUS+vP4i5t597d+S0enMbpWbNnR1kWRXd3cQm2NunkHpeuJ9ZWqf+okroCvbN5JZzoFiONUCPksV+4SWPV8FthqZnOADwDfk1Sf20jSgcCXgKOAuXE5I+5eB3zAzA4B3gZcKOntw9F5x0nxArB/jJ9K4qj2i9sT9gVmA0skrQU+BZwn6YZ8JzSzG8xsvpnNb2jo7lGYuAKOrnVXQKf86aZYxTirJHnFKI+xyjBjygQ++Kb9u2ybPL6wK+Cdj73Cuq07geByee7iZWxpbc+06zTo6LBMGvgpE8K5XtjUf2NM1X9b40ePYs/xdezu6OxSH8BxKoXEclWbmlKxmMxi9qVL3HpVnZxKDPA3s5XAcuC9edp9GPiFmTWbWSdwYzwWM3vQzF6O77cATwEzhqHvjpPBzNYDK4DT46bTgUfNrDnVpsnMpprZTDObCXwbuNHMFvXnmpkYK7dYORXAzvbOLuvJWLXNY6zyctTsKZn3o2rEhNHdJ1ASV8Dtu7NKq0EmlXpNqlDx7Gn13HPxsaz++kn8S6wb+uKm/o+pRsRTJ4mzcndAp5JJPwwSBpoW1ClbGoHnU+tN5MSk9KWdpNcBbwV+k+9ivblWOc4AuQC4SNKzwEVxHUlLJM0f7It5HSunktiVY7FKUq63ZwoEuxynSStWk8ePRrl+fEA+I19NTEhx08IFzC5QqPiAPYOl64XX+q8vVHWB4IT99hjHEy9t5aXNO3hz456l7o7j9IubFi7IVA/vsKxb60DSgjqlQdIjBKUoH3sP8rX2Be4APplYsHIxsxsIMS7Mnz/ffaadQcXMngbekmf7SQXaXz6Q62VirDwroFMB5LoCNkdXwGorEDxY7D95HDOmjOf5ja1546sAPvXjFd22JUpUT4WKp0dDzAtuseoZzwzoJBRTqFLSu+Ls/a5CRSoHo4hlX0keBqu/fhJzpmXTgA4kLahTGszs8Oj6lG/pIFie0m57jXSNSUnosV1Mdf1/wL+Z2e2DfyeOU354VkCnkkjSrU+bOAbIugLu9gLBBTl0vz0AWFWgvmfuZHOtxD0XH9trQoq9Joxm/Ohatu1sZ0ue1O7FMCK+rf2TWlYDCEZzqoZiClWuAT4BXJnvBINVxHIg3LzwSCaNDQbnyePq+p0W1ClbbgfOB4jK/wLg7jztfgacLKkhZgM8D/jveNwU4B7gGjO7aVh67ThlQCZ5hQ9InQogyVJ3QDQC5GYF9ALB3Vn+/KbM+3zhELlxVMVOPkvKfA/LnnuNv7riN8y69M4+xbKPiG8ro1ht3lninjilpNhClWa2ysxWAO3kZ1CKWA6ExinjuensoEyNravNPAicquFKYLKkVQRZW2Rm2wAkfVnSBQBmtgb4CvAnYCVhUuDWeI7PAfOA8yWtiMs5w3wfjjPs7PYYK4eiPVT2kXSHpMckPSXpjDxtCnqoSDpOUoekv+9vP3dmFKtgTdmQE2PlySu607wtm4wuXzhET3FUvTE9fg9fvOMJXtq8g04LlrFiY9lHRozVZE9e4QB5ClVKSgpVFhWxnypieTzwxR7aLQIWATQ2FgqlGRhHNO7J3hPH8MqWncz5wpIu/sNOZWNm24GPFNh3Wc769eSxvJrZJcAlQ9JBxyljsnWsPMZqhJN4qNwaFabrgRNy2lwNLDezD8ZJ1ocl3W9mL0DPHiqSJgLfAO4aSCcTV8CMxSpJtx5jrOpcserGrIYJrG5uodPyW6R6iqPqjemxCPG6LVljTJJRsBhGxHSOx1g5g0Ffilj2VmdlMKipEbujq0Cn5TeHJzRtbOXEq+/39OyO41Q9nhXQKdZDBTiM6GYdSwCsAE5J7e/JQ+VqgnfBhoH0dWd7fotVkm7dswJ2ZyAWqd7I5wHUF3fCEfFtbd/VjoAtO9p4x1VLfVA5cimmUGVP9KmI5XCQDq7sjLWt8ilO5y5exqr1LZ6e3XGcqsdjrBzyeKgAiYdKmoeB0xQ4kFBMfQZ08VD5Vu7JJb0X2MPMftpbR3orZ5GkW7eY7bd1dwfvuGppxkVwlCtW3Ugn8yomKUVfSBTcJD1ujeiT8jYiXAE/sXh55gNa07ydcxcv67eJ0KlczGy9pKRQ5a3kKVTZy/FNwNRkXdLlQL2ZfXYIulsUsxvqWdXcQir7OivXt3DMlfcxd1o9X/ngIXzxjidYub4ls9/TszuOU80kA1W3WDlF8BmC4rSCkGX1XqA95aFyTgwbyBwgaTJwBXBiMRforZxF4gp47dJVmW1rNmynhnDNOk+3PqykLVZ7TRjNg59/R5+shiNCsUoPIvviJ+lUJRcAiyVdBmwCzoJQqBK4zMyWSzoa+DEwKezSacC5ZvarUnW6EEltq7TilLByfQun3finvMd5enbHcaqVxEXa61iNaDIeKlExyuuhEidWMwkr4ljgL3T1UAGYHHZrEvCDuP+huG8q8AFJe5nZl/va0cQy1SWmx6CDJHmFTxAMJ+l6wx2dxiubd/bJIjYivq102kWADjOPMxmhmNnTZvYWM5sXX5+J208ys+Xx/e/N7AAzm2RmE+P7bkqVmV1eSmsVZM3hc6fVk6f4eF5qa8T3Fs4f2o45juOUCK9j5ZjZeoIV6vS4Ka+HiqQpkkbF9ycAhwI/MrOmWFdwppnNBL4N3Ghmi+IYYVpq30+BL/VHqYJsuvUkgzWA4gKevGK4SRcX3rqzrc+hEwN+6hSZzrJW0rWSVktaJekTedoMWcHVJMgtzSqPM3GqiJsWLmBOjoznUqOwdHQabR3dvBEcx3GqgiQr4Ng6V6xGOBcAF0l6FrgoriNpiaRkdvFI4ClJTwNfBj5gZsM6655YrL568iHUjwlW1r0njc2kWffkFcNLFy+3foRODMa3VUzB1Y8Bc4C5wFHA5ZJmJjuHuuBqMqtfm5rS78+H5TjlSiLjv73keOZOy69gzW6o59h5ISHSA6sHlMTIcRynbMkkr6h1V8CRTJEeKneZ2Vwze52ZHR1rWOY7V0EPFTM728yu6W8/kxirAxvqed+h+wHwj++cS0dndAX0GKthpb/FhRMGpFj1IZ3lqQQTamc0w/6CrjVahqXg6qyGCV3cpQ7Yy4uqOtVFroJVKzF3Wj2/veR47rn4WN518D4A/GHVxswxnordcZxqIpNu3S1WTgWQrbtWw8SxIfXB5tY2ol5FrStWw8pAU7kPNHlFsQVXG4HnU+tNsc2wFlzNDfR/Pg4ovaiqU20UKo43M8r53U+uy8j+2d9/iOc2bMfI1sLyrJmO41Qqu72OlVNBJBarsXW1TBxbB8Cm1lAkeHRtDSo2gNoZFAZSXBhKnLxiuAuuJh/WgVOzZj2PtXJGEpfd8WTm/cr1LZxw1VLWRKUKPBW74ziVT8YC4FkBnQogibEaV1fLpHHB3vHa9qBYjfLEFRXHQC1WRaWzJFioZgCJBpNYsAqmszSzRQPsW0HSrk4ea+WMJHJlvb2zaxKLGsH0vcZx4tX3s3p9C7W1oqPTMuZwt+w6jlPOmJkXCHYqhraOTto7jdoaUVdbk7FYZRQrdwOsOAb01Ck2nSVwO3CepJoYf3Uy8NOe0lkOpF+9kRtrNcMHi84IIbf0QC777TGOTgvWrE6grcMy68dceZ/HYDmOU9a0dRhmYUDqsSlOuZNYq8bGSYAkxmpjVKw8I2DlMRjfWDHpLP8LWAOsBP4EfNnMnhuEa/eL3NTU73zDtFJ1xXGGlXRQZl2tutW++tDh+/PCpsKKk7vOOo5TzmTdAH1A6pQ/6fgqyCpWm1yxqlgG6gqImT0NvCXP9pNS7zuAC4s41+UD7U8xJLFW9z2znnO+v4ybf7+W7/32OXd7cqqedFBm08ZWzl28jDXN29l70hhe3rKT363cwJhRNZmHfS4WrVee9MVxnGKRNA9YDEwBNgJnmdnKnDbnAJ8GOoFagvfKd/p6rUziijqPr3LKn4zFKsrrpCR5hcdYVSwjWhU+dm4Do2pEe6d1cXta7bPyzgggUbJWf/0k7rn4WOpqxZ9f3MzOtk6k8HAoVPE9+Y14qnbHcYqgmHqXPwMOM7M3AW8DPiPpjX290C7PCOhUEOlU65BVrLbtagfcYlWJDNhiVcnU1IgOs27bO31W3hlhTBgzitfvO4nHXtwCwMQxo/jlRW+nccr4jGUrKVMA2d/ICVctzSTASOKw6tzy6zhOJFXv8sS46TbgGkkN6XhsM9uaOmw8UAd0/4PuBVesnEoi4wo4qqsrYIInr6g8RvyTZ3ZDPYXE1i1XzkjixU07Mu+37WrPyH5i2Zo7rb5bTFZuVkFwy6/jOF3oVu8SSOpddkHSX0t6kpA1+EozezzfCSUtkrRc0vLm5q65shILgGcEdCqBTKr10UGxqs9RrNxiVXmM+G/s5oULmDOtPq/bU9py5S5OTrWzORYkhPwx3OdNAAAgAElEQVRlCHKTvvSG18RyHKcvmNn/mtnBwDzgTEkHFWhXsK7lrrbEYuUxVk75k01eEYbjdbU1jEvFBxZyx3fKlxGvWCWz8WuueB8rv3pS3ll5TzXtjARmN2Rlv0YhNXuatOUq8U4QhR/8ovs5HMcZcWTqXQL0UO8yg5k1AQ8B7+/rxXZ3uCugUznsyKRbzypTSZFggFFusao4/BvLoadZeU817VQziezXSpn4qELtkpTtc6bVc+/Fx/HbS44PChdZn3AJvn3am4bxDhzHKTeKrXcp6fWp91OB44G8roA9kbFY1fnwxil/crMCApkiweAxVpXIiE5ekY9kVv7Eq+9nVXML6dwWnmq68iky7e+7gK8BhwL/YWafTe0blJTA5Ug6FXt/2qW3fejaP/DoC5t533d+78ksHMe5AFgs6TJgE3AWhHqXwGVmthxYFJ+9bQSD9zVm9uu+XigTY+Uz/U4FkChW6YmAdAILjxWsPFyxKsBNCxd0y4SW4NnPKpok7e+tks4gpP09IafNGuATwIeBsTn7fgbcYmYmaSLwhKSlZvbYUHe8kmhu2ZV539YRZieSZBbFKG8jHUnjge8DRwDtwGfN7JcF2p4H/D/CYPQu4B/MrDO1fyzwMLDDzObnO4fjDCVF1rv89GBcK5sV0GOsnPJnZ3vXAsHgFqtKx1XhAiSz8omLUz6S7Gcr17uLYCWQSvt7W9x0G3C4pC7Rz2a2ysxWEAa05OzbapaxY/Y7JXC188rmnd229ZbMwmtideGzwFYzmwN8APiepG4PIkkHAl8CjgLmxuWMnGZfBf40tN11nPIgty6QM3KRNE/SA5Keja9z87TZR9Idkh6T9FSccM1tc5CkVknfTG27VtLTkv4s6Q+S+jVptStPjFXaYuUxVpWHf2O9kC9gPx8r17f4gLD8KTrtb08UmxJ4JDOrYULe38uMPFbdpo2tvPPqpRxz5X2sXN9Ch5knjIFTiUVUo6vqcuC9edp9GPiFmTVHK9WN8VgAJL2doGz915D32HHKgN1ex8rJUkxh6quB5Wb2RuAY4GuSMmOCmGzleuAXOcfdBRxqZocBXwd+0p8OZtOtZ+V1Uspi5VkBKw9/8hRJErDfE+kB4dwvLGHWpXeO5IFh1VJMSuCe6qyMBJLfS24Zg+c2bO/2mzjl+gdYtT6/JWsE18JqJCjuCU3knwAo2E7SBODbwIW9XWyky6tTPbgroAPFe6gAhwF3A8SEKiuAU1L7Pwf8Eng2fZCZ/dLM2uLqA8ABkvo8ps4tEAwwKWWx8jpWlYfHWBVJYrlq2tjKuYuXsXp9C7UxxipPjVSPKylPMml/zayjmLS/PWFmTZKSlMDP5Oy7AbgBYP78+SPOVTA3wcWx/3Yfz7/WigGr1rdw1s0PUldbw6r1LT36UVZrLSxJjxCUonzsPUiXuZIwW/tSPheYNCNdXp3qIckK6EH/I55uHiqSEg+V9OzRw8BpkpYDM4G3AWsBJB0GvJuQofKLPVzr74E707GtaSQtAhYBNDZ2fezvyJsVMOUKWONyXGm4YtVH8mVEe8dVS1nTvD3vADGJwZrz+SV0mie6KCVmtl5Skvb3Vgqk/e0JSa83s6fi+yQl8M+Hor/VxIubdmTeG7C2SCtuuhZW08ZWzrr5QZpea63435GZHd7TfklNwAyyA4BG4L48TZN2pNolEwVHAyfFTGxjgT0lPRZdXhynKsnEWLli5RTHZ4BvESxVTcC9QLukOsJk0zlRKct7sKTTgI8S3Ajz0tPEVTbdejoroLsCVjL+5BkEvn/2kcwpkOAiob0zm+jimCvvY87n3VWwRFwAXCTpWeCiuI6kJUnwqaSjJb0IXAycL+lFSe+Oxy+S9GRU0O6lnymBRxqFYq7S1ErMnVbPj897K1PrRwMwfkxtpp7WObc8xNqNrXRasHpVuYvg7cD5ANHatIDorpLDz4CTJTVEN5TzgP8GMLM3mtlMM5sJnAY87kqVU+24K6ATKaowdYxPPcPMDjOzDwATgb8A+wKzgSWS1gKfAs6TdENyrKQPEZIDvdvMXu1PJ3dm6q4VKhDsilWl4RarQaCQm2DiDpiP9ug/mInJmlbZM/CVQpFpf38PHFDg+EFJCTzS6Kl8QY1gdkN9F0vwLy96O0ddcS9tHcYe48PsXdol0KhOF8EUVwK3SFoFdACLzGwbgKQvAy+b2XVmtkbSV8hm/fs1wRrrOCOSTPIKzwo4oinWQ0XSFGCLmbVLOoFQv/LDZtYKTE21uxyoT+paSno/IfHFiWa2tr/93NmexxVwTNpi5XJcabhiNYjkugmeePX9rG5uyRuDlcvK9S0cf9VSOjuN2poQuzXK62Q5VUK68HbubyKR7zT77DGWN0+fzCNNmznsX35NXY26udoesNe4oe94iTCz7cBHCuy7LGf9evJnu0q3WQp4DSun6tnlWQGdLMUUpj4S+I6kDmAD8IGoVPXG94HdwE9TboLvMLONfelgkm59XIEYK1esKg9XrIaQZJa+GAsWQEccbSbWrKS9FyR2qoXkN7GmeTuzGib0KMfpuKy2PLMT82fs2ev1EityMddzHKfySWKsPHmFU6SHyl2EkhS9nevynPXc7IL9IpMVsECMlRcIrjxcsRpCci1YfXEVzEeuouXug06lkS/5SyE2tuzOu10EV8CfPfISK17YzPfPPrLgb+DcxcsymQc9Q6fjVD9JVkCPsXIqgZ29ZQV0i1XF4YrVMFJI0VrTvJ2ammCpsj7oWomCNX3PcdTWiKaNrdTWivYOdyN0Kp9ZDRNY1dzS5TdRI6itUaqcwXbOueUh7v3McXnPsao5m869WlO3O46TxV0BnUoik249XcdqXNZiNdqTV1QcrliVkLSilWvNSpSjYqxaL6Rcpjo73I3QqQ5yXWkT+V3d3DUBxurm7ZzwzaXccs6RAJljamrURSlLp25PcFdBx6kuXLFyKol86dbrx7jFqpJxxapMKOQiNVD3wYTkuFXN2eKsuQNWH1Q65USh30S+BBhrNmznhKuWZuITATpz4rJG1YrvLeyavyHtKpikcHdXQcepXDJ1rOrcFdApf7IxVll5ra0R9WNG0bKr3WOsKhBXrMqcQu6D+dJWF4NZ1+KsnSnLlmcldCqBQqnb23tJv9nWYTy7roUzb3qQFzbtYNbUCTy3IVvYewSkcHecqiexWI32mX6nAshOBHSV14ljg2LlWQErD1esKozcmllrmrczPaadzo2x6qt1q7eshKOiwtWb4uXuVc5Q0lPq9nzUCCaMHsW2Xe2c91/LM9tX51Gipk4cTdPGVk694QFe3brTJxUcp8LY5XWsnAoisViNy7GwThpbxytbdrpiVYG4YlWhFJNdbbDcCBPae1G8ptaPBmBDKpubx3g5Q0U6dXtNDbR3WJdaV2mZa9nVzrZd7b2ec2PLbo658r7MumcSdJzKoWljK0+9vBWAT/34UW49963+X+OULU0bW2mJ/0sf+u4fuHlhyHDbtLGV518LE3/f/r9nOXrOVJfjCsJV4SomUb7WXPE+Vn71JOZOqyfXXbeuVtQovGqArrwbWnZ3UarStHUYnZYdqDrOQEnke/XXT+Lei49jzrR6aiXmTqvnt5ccz8qvnsSar7+Pey4+lvVbd/V4rlqJulp1cyf0TIKOUzmcu3gZuzuCBeCFTTv8v8Ypaz6++KHM+zXN2zPyeu7iZRlLVvO2XS7HFYZbrEYQPRVnHUhWwr7gA1VnKOjNgjurYUJBt8EaZfcX2uc4Tv+RNA9YDEwBNgJnmdnKnDZfBE4DOoA24PNm9qu+XCf932L+X+OUOc81p+LdU/LaRY5xOa40BqxYFfnArAW+A7yHICdXmNn34r5zgE8DnUAtcKOZfWeg/XK609Pgs9ishInC1V/FyweqTinInVT4ygcP4Yt3PNFlkuHcxcu61c1KXFcdxxkQ1wHXmtmtks4ArgdOyGnzEHCVmbVKOgy4X9K+ZrYj92SFSNe+8/8ap9w5sGE8q5u3d5PX9ESgy3HlMRgWq2IemB8D5gBzCQrYo5L+z8zWAj8DbjEzkzQReELSUjN7bBD65gyQ3iwB+ZJovPDaji6D13xp3R1nOMknx7nrPVl0HcfpH5KmAYcDJ8ZNtwHXSGows+akXY516jFC6bkpwIvFXivfb9hxypWbFx6ZV15djiubASlWxT4wgVMJlqhOoFnSL4CPAFea2dZUu/FAHTC4/mfOkNGb4uVB/06lUExCGMdx+sx04CUz6wAwsw5JL8ftzQWOOQtYbWZ5lSpJi4BFAI2NjZnt/ht2KolC8upyXNkMNHlFtwcmkDww0zQCz6fWm9JtJP21pCdjmyvN7PEB9stxHMdxnApD0rHAV4DTC7UxsxvMbL6ZzW9oaBi+zjmO4/RCWWQFNLP/NbODgXnAmZIOym0jaZGk5ZKWNzcXmuRyHMdxHKeMeAHYP8ZaJzHX+8XtXZB0FHArcLKZPTOsvXQcxxkEBqpYFfvAbAJmpNYb87TBzJoIAazvz7PPZ6gcx3Ecp4Iws/XACrIWqNOBR3PCBZC0APgJ8GEze2R4e+k4jjM4DEixKvaBCdwOnCepRlIDcDLwUwBJr08aSZoKHA+4K6DjOI7jVAcXABdJeha4KK4jaYmk+bHNd4FxwPWSVsTl0NJ013Ecp3/IbGB5IiS9jpBufU9gEyHd+jOSlgCXmdnyaMm6BnhXPOwbZnZDPP5bcXsbIQvQ98zsP3q5ZjNdY7YSpgIbBnRDw0Ol9BOGvq8zzKyqTZAF5NVlYGhweR0gVSCvxVBt9wP578nltfyplL4ORz9dXsufSulrycYCA1asyglJy81sfu8tS0ul9BMqq6+VRCV9rt5Xp9o+12q7H6jOe+ovlfRZVEpfK6WflUglfbaV0tdS9rMsklc4juM4juM4juNUMq5YOY7jOI7jOI7jDJBqU6xuKHUHiqRS+gmV1ddKopI+V++rU22fa7XdD1TnPfWXSvosKqWvldLPSqSSPttK6WvJ+llVMVaO4ziO4ziO4ziloNosVo7jOI7jOI7jOMNOVShWkuZJekDSs/F1bqn7BCBpSqzT8YykxyX9PNbxQtJbJf059vnXkqaVur8Akr4kySQdEtfLsp+VjMvr4OHyOnhIGi/pJ5JWSXpaUrdC7am258V2qyVdI6kmbj9OUmuqDtGDw3cHxf22JNVKujb2fZWkTxSzrxQMwv1cLml96vu4dnjvYHgp12cr+PPV6U65ymslyiqUkbyaWcUvwG+AM+L7M4DflLpPsS97Acel1q8EbiIotKuAo+P2fwZuLoP+Hg7cBawFDinXflb64vI6aP11eR3cz/My4Mb4fi6wDqjP0+5A4EWgIX7mvyLULwQ4Dlhewnvo9bcFnBX7XBPv4UVgZm/7KvR+Lge+WWrZKqfPq4R98+erL7mfcVnKa6XJauxL2chryT+MQfgwpwGbgdq4XhvXG0rdtzx9/Vvg/4AFwBOp7VOBlhL3bQzwADAzJZhl189KX1xeB61vLq+D/5k+CcxPrf8S+EiedpcA16TWPwzcGd8fR4kUq2J/W8CdwIdT69cAl/S2r0Lv53JGiGJVSc/W2D9/vo7gpZLktZxlNfajrOS1GlwBpwMvmVkHQHx9OW4vG6KrzIXA/wKNpCpvm9kGoEbSXiXqHsCXgVvNbG1qWzn2s9JxeR0cXF4Hny6fH9BEfrnsrd08SY9IelDSwsHvZkGK/W311P9iP4PhYDDuB+A0SY9FV5ijhrLDJaYinq3gz1cHqBB5rQBZhTKT12pQrCqF/wBaCLOJZUX8s50PfLfUfXHKBpfXKiMqOxsKLLWDdJlHgOlmdjhwGnCZpHcO0rmdvnMdcKCZvZHgznOHpCkl7pPjz1encihbWYXylNdqUKxeAPZPBgbxdb+4vSyQ9E1CzMKpZtZJmFGckdo/Feg0s9dK1MVjgdcDz0laCxxA8NmfQ3n1sxpweR04Lq/9wMwON7OpBZYOcr5nwoxfPrks2M7MtprZlvj+OeAXwF8Nxf3kodjfVk/3WexnMBwM+H7MbJ2ZtcX398Tthwxxv0tF2T9bwZ+vToayl9cKkFUoQ3mteMXKzNYDK4DT46bTgUfNrLl0vcoi6WvAEcDJZrYrbn4YGCfp6Lh+AXB7KfoHYGZXmNl+ZjbTzGYSgp/fTZjhLJt+VgMurwPH5XXIuB04HyBmp1oA3J2n3c+AkyU1RDeR84D/jsftK0nx/V7AuwjyPuT04bd1O3CepJqY6epk4KdF7BtWBuN+JO2fNJL0JkIMwjND3PWSUO7PVvDnq5Ol3OW1EmQVylRehyOQa6gX4HXAg8Cz8fWgUvcp9utgwAh/ZCvi8j9x39uAx4GVwD3A3qXub6rfa4FDyr2flbq4vA56v11eB+dznED441kVZeCDqX1fBi5IrZ8PrI7Lf5INwP57QhKMFcATDHPih0K/LWAJMTEHIUj8P1P9X5Q6vuC+En0nA72fxfF7+DOwDDip1HJWis+rHBZ/vvqS57MtS3mtVFmN/Su5vCpe3HEcx3Ecx3Ecx+knFe8K6DiO4ziO4ziOU2pcsXIcx3Ecx3Ecxxkgrlg5juM4juM4juMMEFesHMdxHMdxHMdxBogrVo7jOI7jOI7jOAPEFSvHcRzHcRzHcZwB4oqV4ziO4ziO4zjOAHHFynEcx3Ecx3EcZ4C4YuU4juM4juM4jjNAXLFyHMdxHMdxHMcZIK5YOY7jOI7jOI7jDBBXrBzHcRzHcRzHcQaIK1aO4ziO4ziO4zgDxBWrYUbSUkmXl7ofTvUxWLIl6ThJ1kubuyR9fqDXcqqXwZBHSZdLWjo4PerxOk9K+lhq/QhJKyRtk3SLpI9JenI4++A4juNUHq5YlSGSDpP0E0nrJG2X1CRpiaQPpdr0acBRaJATBw23DErHnbInDhj/V9JrklolPSXp85Lq+nIeM3uvmX1tkPp0tqS1g3Eup7KQ9EZJ/x2fdS2S1kj6gaRDhrMfZnawmf0wtenrwFIzm2hmZ5vZD83s4MG4lqSZkkzSzF764DiO41QYrliVGZLeAfwJeAl4KzAROAj4D+BvStg1p8KRdALwe+AvwBuAycD5wNnALyT588AZNiQdBzxIeNa9hfCsmw/8Afhg6XoGwCxgRYn74FQBkq6IivQZefYtlbQ7TipslfSEpHPztNsvnuexOCn2kqRfSvrbAtf8VJyQbZX0B0mH9dLHtZJ2xn4ky/v7f9dOKahWWZP0Zkl/jNdokvQPvbTfS9JNkl6OXgd3SDogtT+Z3Nqe0489ejpvsfhAqg9I+qSkp3O2TYxfyAlx/SuSVsVtz8f1vnzO1wG3mdnFZrbWzDrNbIeZ3WVmZ/bQt70k3RwFab2kn6UFySlvhkm2/hP4mZl9zszWmdluM/stYRD7LuCUnOt/VNJzkjZL+rmkhtS+LhZQSftL+lF8CK+XdFtO+/GSvh77v03SSkl/K+ntBJlvTD3cTk49+M6ID/ht8cH6utQ5ayV9RsHqtkXSwwoTE8n+wyTdH/u/Ke4/KO47XtLyeNzG+IewZx8+y6pmmOTxeuC/zezTZva8BV4zs+vN7KsF+vV3Ci5z26KsXStpfGr/KXH/VkkbJP1fat/fS1odj31VKUu9wp/92VGmWgiK1XXx3v5WOVZVSaMkXRJlb1u8/7+L+/aVdGf8HWyVtCz5zCKJS+GT8fxXpfuQusbRUeY3x8/5c5JqU/stfk9/jOd5TNLb+vD5O0OMpNHAx4GNwAUFmn3NzOqBPYErgO8pTDok53g/8EegFfgIsDcwG/g34EwFD4RxqfanAZcRnud7Ab8G7pY0sZfuXmBm9anll32+YadkVKusSZoE3A38Kl7jFOBySR/u4fyLgWmECeR94/38f3n+nw7O6ceWXvpdHGbmS5ELYYZ/B/BXqW2fAFYDiutnAAcAAhYAG4DzUu2XApcXOP88wIB3FtGXywmuKsn6EoLgTSXM/P4X8AhQ29N1gVuAW0r92Y70pdSyRbAS3BrfHxfb3kF4AO8Z5euufNcCxgBPA98AJgD1Uf7uSbW/jWCJnRfXpwNvjO/PBtbm9Gdm7MOvCA/3scDPgXtTbS6PMj6PMEn0IaAFmJ26p8uAUXF5E7B33PcScE78LEcDRwETSi0H5bIMgzzO7Ukec77jpan1vwHmxGu+DlgJfDXuGw/sBk6I62NT7+cS/lwPiev1wDGp864Fzu5hvYuMElwFnwWOiH1pAI6M+w6IsjghytY/A1uAqTmyPTPnXjPXBGbE/l4A1AFvBJqAi1PtLcr/7Cjf/wGsLrXsVOsS5fnfgZ8B24A1wInA8cDjwFbCM3NS6piPxt/R++L3dUiec16es20D8Jn4/rAo4wf20K+vAd/OOec3Uus1wCvAWT2co4u8++KyVi6yRnj2vgzUpLZ9A/hNgfYTgE5gfmrbnPiZvD2uzyTPM3iwFrdY9QEz20wQ9LT59FzgZovflpndamYvWmAZ8EPgnUVeIpnhfynZEGctN8eZ9Z2SZuQeJGlf4L3Ap81sg5ltA/6e8ENZ0MfbdEpAKWQrhxcJMzxpPmdmm8xsE/AZ4D1R1nJ5H2FQ+zkz225mLcBngXdKOiBark4jzFI9G+/lBTN7rIh+/4uZvWpmO4GbgSNT+z4NXGJmz1qw7P4P8Dvg9Lh/N9AIzDCzdjNbYWavpvbNBvazYLl7wMy2F9GfEcEwyGMia4XksVC/fm5mq+I1nwa+m3PNNuD1kqaa2U4z+03c3k5QgA6WNMnMWixYa/uMJBGer/9kZg/HvjSb2UOxjy+a2f/E38JuM/tXwp94X57FHwWeMLPrzKwt/lb+DViU0+6bZrbazNoJFsBZkqb0576cojgD+CZh4uHHhAmkTwLHAgcS3PY/nWp/IcFL4E6CC/aFhU4craBnEmbll8XNXwUuMrPnFOJjH4gW9rsV4qPPBL5IeDYn3/thwPLkvGbWSVDA39TLvf2bguvXE5L+SX2Mu3UGnREpawqeMptTbQ8DHo3nTljewzWU85p+/+actn+Ing1/VCqHwUBxxarvfA84RVK9pDcQ/iy/n+yUdKFCNqlNUTjOp/uAtRDN8XX/ZIOZ/d7MJhOEawxdhSVhenxdkzpuSzxfY9zURpj5zKUu7nNKz7DKVg4HAOtztj2X5/10ujMX2A/YFCcBNgPPALsI8jcztnumyL6meTn1voVgaUDS3sAk4H+Sa8brHkP2Hs8mDGh/I+kFSd+SNCHu+2uCu9fDCm6JX0q7WTnA0MpjImuF5DEvkj4s6U/xz3ALYTAwDcDMWoH3EBStZ6Jr3N/Hfc8RlPtzgCZJD0o6Jf9VemUqQQ7zyrOybtlroyvgZoKsFvvZQPidrcnZtors8zwh9/cBwWPBGRp+GidhOoBbCdb0qy24sG4kWPbnAygkYDma8Dsivp6RegYlfC7KyDrgU4TZ/N9KGkNwVbo7KvM/B75NkKPPA+8neKR0EKwY8+L5JgGbc66RyGAhFhImmqYRlPcLgH8t9kNxhoQRKWtm9qM45k3o0zXixO5vgH+RNEUhbuqrhLFA8mzcALyNoKBOB64BbpN0Ug/9LhpXrPrO/QRT56kEf9a7zexlgOjf/m3gH4CGKBzXk18Z6kaczV9NmK3sCy/E1wOTDdEvdSrBfQTCwHhunmPnxms6pWeoZWsVcFbuPoW4oyOBO3N2zczz/sU8p18HrDGzyTnLWDP7I8H0D9mHcS6dBbb3xGZgJ/CenGtOMLMLASzE7ZxnZjMILhTvAv4p7nvczD5qZvsQfMk/SZ7PZoQzlPK4kuBKV3R6cYWY0Z8QZnH3N7M9gC+kr2lmvzOzDxGeff8AfFPS8XHfHWb2nrjvKsIf6exir59iA0GJKSTPVxCexX8F7EFwpd2a6mcx8v4Cqed5ZDbZ57lTGl5JvW8tsC0ZvF0IrDSzpXH9B4TJ0VyZvyI+u6aa2RFm9oO4fQrh2QpBZseb2U/MrMPMHiG4YSXMSLXdSpC7NJPj9ryY2f1mti1a9v9IcKEuGNPtDAsua/28BsHa9xrwGCGm9Q+EZ/aG2IeWqLTutpDD4EcE5bVb0o/+4IpVH4luMDcTZmfPJDtDAOHL7yBYBzoUAvP7Wpfkk8BHJV0laYakmjibcHQPfXqFENx3taSpkuoJ/vZPkjXzLgY+qBCIPVrSOIVg64MJgxWnxAyTbJ0i6WuS9pZUJ+logq/2vcB/57T/uqQ9FZI6XAn8OhlY5/BzYKxCCYA9ACRNk3RqvK9mQozVdyXNjfsPkPTGePw6oEF9SB5hZrsISS+ulPR6BcZJOkbSvHiNs+N1RHgItxM+u9GSzlE2ucYWwmfbUez1RwLDII/nA6dKulJSY/wOJ0s6V/lrpE0k/GdtMLNdUX7+LtkpaR9JH5E0OfZ9M2GWskPSQZJOklQf3ea2EBSdPn/n8dz/AXxDIVuVJDVISlz99iDEOmwixHn9K9HSGmkmKFcH9XCZ24BDJS2Kv9NDCJMC3+vhGKdMiP/BZwLTFUoJrCP8H9dSOLFALhuBfeL7DcB2SacqJFh5I8E6P17S54B10SoL8GeiJSP2pYbgAtWXLJedFDlJ4pSWESBrfwberK6JJ47o6RoWknOdYWb7m9kBBAvWRLoqiH3tR9G4YtU/FgOHE/6009lMfgXcRNCOXyPMmPapLomZ/ZpgomwEHiIELq4kDFpOBp4vcOgZwKsEM+1zBCH6QDTdYmZ/AD4MXEIYyDYRAsHfmfqROKVnKGXrHuDtwKGEZBNb4zlvBf46kZUUtxP8pdcSlJK8s0oWYvqOIsywPy5pKyGz0DGpZufFvv9KIevafYSAUggPvTuBVQoufX9d5C19lqAM3k4YRK8FLiXr8no84TfUQng4P0BQECH8Fp6UtJ1gmbklfg5OV4ZSHpcS5GYGwWd+G/AoQUZ/kaf9U4REED+JMvZNwsxsgggDiTVRxn4KfN5CLNVognXrpXjsVcU23SUAACAASURBVMCZZra2L31OcRlBZn4c+72c7ADjiwTlqpngLvgqKUuvme0guNcsjvL+b3nudS3BrfEcwkDnDuAG4Fv97K8zvHyMbMKc9PI+wiDxLb2dIE4erZb0jqjM/y0hpuZlglX0DrLJTU5NHXodcJ6kI+OkbGLV/Z9815E0N05IjY0TuUcCXyYo9075U+2y9vN4f1+QNCYecx4hy3Fe4kTa1DjpdTDBhf0mM3sm7n+7pDcoxJqNjpPAZ/bSj+KxMsiA4osvvlTWQkgS8flS98MXX3zxZTgWcrKqkSezGME6uZQwQfDdAuf5HfD9fOfM0/ZIgsvs9AL7RxXY/mmCO+kOwiTXYal9jYTJprenrvFnwgTBVuApguJfV+rPfKQuI1nWCIpiS8413kyYGN0Rr/UPOfvvAq5LrX+ckBiplTDhehkxQ3bcn2S43U6YGPwT8JHB+v6StLmO4zhFoRC/9wzh4XZ7qfvjOI5TrSgUZr2KYK38BWFguSdwEsGCe7IFa67jDAiXtcHBFSvHcYpG0lGEeL67gTPMzDNKOo7jDCEKZVYuJiTg2Y8w2/874N/N7MFS9s2pLlzWBo4rVo7jOI7jOI7jOAPEk1c4juM4juM4juMMEFesHMdxHMdxHMdxBsioUnegP0ydOtVmzpxZ6m44g8DDDz+8wcwaem9Zubi8Vg8ur04l4fLqVBIur06l0JOsVqRiNXPmTJYvX17qbjiDgKRCdbmqBpfX6sHl1akkXF6dSsLl1akUepJVdwV0HMdxHMdxHMcZIK5YOY7jOI4zICTNk/SApGfj69w8bfaRdIekxyQ9JemM1L7LJa2XtCIu1w7vHTiO4wwcV6wcx3Ecxxko1wHXmtk84Frg+jxtrgaWm9kbgWOAr0mantr/AzN7U1z+bui77DiOM7hUZIxVLk0bWzl38TLWNG9nVsMEblq4gMYp40vdLcfphsuq4zjVhqRpwOHAiXHTbcA1khrMrDnV9DDgWwBm1ixpBXAKcNVw9recSf4jVq9vobZWdHQasxvqu/xXFPof8f8XpxKpNrmtCsXq1Bse4JUtOwFY3dzCuYuXcc/Fx5a4V47TnXMXL2PV+hYMWLXeZdVxnKpgOvCSmXUAmFmHpJfj9rRi9TBwmqTlwEzgbcDa1P7TJL0LWAd8ycweyHcxSYuARQCNjY2Deyc5pAd90/caB8ALr+1gVsMELvvAG7jk9sd4detORqWUoK988BD++Y7HWb1+O6NqRXuHZfY37pVVjmpqwrZRNaLDwrG72jtoem0HAJ0dBsDK9S0cc+V9jKoRnWYIiLtY3dzCWTc/SKdB02utmX4nx9Slrt/eYdTGa02tH82omhrWb92VVznrSbHL99m4gufko2ljKx9f/BBrmrdn5AjoImNtiTCTldu508Lv6It3PNFFjpJjk21Jm1x5LbS9L3LcX2RmvbcqM+bPn2/prCqzLr2TztRt1Eqs/vpJJeiZ01ckPWxm80vdj6EkLa+zL11CR+o357JaWYw0eXUqm+GSV0lHENz4Dk5t+wtwhpk9ktrWQLBYHQo0Aa0EhexiSfsAG82sTdKJwA+B15vZxp6uPdjymjvIauvo5PnXWqnAoVKfGVUj2jsL32ii2O0/eRw1Es+nFLmE2qgs5pJR8KJid+DUCXz/7CO7DGD9+Vq55CrkiTKfVpqgsHwUy0CPB9h/8lgAXt68MzO5kUvyW6gVdBrMnDqBxedk5bUnWa0Ki9Xek8ZmLFY1glkNE0rcI8fJz6yGCRmLlXBZdRynKngB2F9SbbRW1QL7xe0ZoltgOmHFEuAvcd+6VLt7JL0AHALcPwz9z3Du4mWsam7BLMyejyR6UqrS+1/YtKNgm0KD3mSA3Rb3r2ne7h4bZUo+Cw7Axxc/xOr12zPKSG2N6OzsrkAlltZcpQoKy0exDPR4gJc27+z1fImsJ7ewdmPx8loVySs+9c5s8qG0qdFxyo2bFi5gSv1oACaNq3NZdRyn4jGz9cAK4PS46XTg0Zz4KiRNkTQqvj+BYLn6UVzfP9XuTQRXwWeGqs9NG1s54aqlzL50CSdefT9NG4P1ZXVUqsqBulrl3a4e9lUKRlCunPIjCVnoMMu45h33zftYtX47RlYZ6eg0jPwKVLVhVry8VoVitd/k4Pd89Jyp3HPxse7L65QtjVPGc/GJBwHwnoP3cVl1HKdauAC4SNKzwEVxHUlLJCUuM0cCT0l6Gvgy8AEzS/zJvibpCUl/Bm4EzkxbsQabj1z/R9Y0b+8yeJz7hSX0NCE+c8p4ZhZ4ZhdSdOpqlVGEapQ9R03OvjQ1grnT6ln51ZP47SXHM3dafaZ9jWDOtHruvfi4sD3nsnOn1fPj897a5Rj10I+eGErlzb2LSkfTxlZOvPr+zKTCn1Zv7LK+ujl41aQZBENRkEF135bIeyK3PdHTpEJft/eFvshrVbgC1tUG/XB3R2eJe+I4vTO2LsjrzvaOEvfEcRxncDCzp4G35Nl+Uur9XUC3+lZx38Kh612W5zdu52+++0c2bt/dbV+hmfcaBW+YxA1oKJI2FHK/apwyvqD70U0LFxS8XrEudr0lq8i3P0nAkSTxKDaBQDqJh3sXlY6zbn6QtSkL7Zk3P0h7R7A+DYb7a10P33Vvv497Lj6222+hmCQWvf0G8yWhadrYOiTyWhXJKx5+/jX+9j8f4PDGyfz8k39Vwp45fWUkBqsuefwVPvnDR3j3wXtz/ZlVfetVx0iUV6dycXnN0/5f72FDS3elKpcaYPa0es9sN4y4vA4ehRSM7bvaOfhLv+rz+QRByeiwLkpHPuVjJPxOqj55RWKx6i3w0nHKgYzFqs0trI7jOMPFEy9tKU6pyrFQOU6lkChUactTUtrlux87nJOv/UPR5/LJhf5RFYrVqJroCtjuA1Wn/Bk7qhaAnW3uCug4jjMcPLNuKx/6btdBZY2gca/x1NXW5HWFc5xKI8lqmSZx8TvxW78t+jw+udB/qkKxSgLT3GLlVAJj6qJi5RMBjuM4w8IZ33uwWwzVSHJdcqqTXJe/vma1rIl1mtKTDLmxTE7fqBLFKlis2jx5hVMBJK6Au9xi5TiOMyzkugDWSj4b71Q8abe/1c0t1CgUce6NQoqUTzIMnKpQrEYlFqsRkEvfqXzG1rkroOM4znAyfnQt23eHZ66n+naqhdUpt79OI6NUiZCWv62jk6bXWum0bAKKzk5ckRpCqkKxcouVU0kkitUudwV0HMcZFg7YazzPrNuWiR1xNyenGpg2cSzrtu7MrIsQU7X0kuOYMWXCgEoAOP3DFSvHGWbGjkqyArrFyukZSfOAxcAUYCNwlpmtzGlTC3wHeA/hP/UKM/teTpuDgEeB75rZZ4ej745TTmyKdat+9/9OYP/J40rcG8cZHN4+byq3L38xs27AuLoaQjnonuugOUNDTak7MBi4K6BTSWRdAX0iwOmV64BrzWwecC1wfZ42HwPmEAqvHgVcLmlmsjMqXtcDvxjqzjpOOdLe0cmGll1IMG3imFJ3x3EGjdUxvmryuLrMtp1tnZy7eFmpujTiKUqxkjRP0gOSno2v3SqnS6qVdK2k1ZJWSfpEat/lktZLWhGXa1P7bpH0YmrfF/p6E3Ux3Xpbpw9UnfIno1i1d1CJBbqd4UHSNOBw4La46TbgcEkNOU1PBW40s04zayYoUB9J7f8c8Evg2SHusuOUJc0tu+g0mDJhTMbDxXEqibUbtvPWr93L7EuXcOLV99O0sZXd7Z088fJWALbtbM+0NWBN8/YS9dQp9gkz4FlT4Adm9qa4/F3OsVek9n21T3dANt16bipVxylHamtEXa0wg93uvuoUZjrwkpl1AMTXl+P2NI3A86n1pqSNpMOAdwPf6ulCkhZJWi5peXNz8yB133HKg3VbQgzKPnu4tcqpTE65/gHWbd1Jhxmrm0PB36de2cru9k5mNUxgVsMEasJQ2JOzlJheFatBnDUdMmqjNHV0mlsAnGItrO+KA8ldkr5Z4DwHSWpN75c0XtJPolX2aUnv708fs0WCXbFyhgZJdcANwAWJclYIM7vBzOab2fyGhtxHu+NUNhnFatLYEvfEqQSKHEMU9MQaCtZv25V532nBIrXihc0AvGn6ZG5auIDZDfXUSp6cpcQUk7yi26yppGTWND21WXDWNHKapHcB64AvmdkDqX0XSzofWA1camZP5XZC0iJgEUBjY2PuPupqRVuH0dZhjB6lIm7LqWISC+utks4gWFhPyGmzBvgE8GGg279tD3EpnwW2mtmc+LD9naQ5ZtaSe46eGFNXy7Zd7aGWVco32nFSvADsL6k2Pndrgf3i9jRNwAwgcapPnsX7ArOBJZIAJgOSNMnMFg3HDThOOZBkTdtnD1esnKIoZgwBwRNryJMBtXd0Zgr5AihapB5t2gTAmxv39CQVZcRwORtfBxxoZm8ErgTukDQl7vsCMMfMDgV+DtwdBxBd6G1G1TMDOlC8hdXMVpnZCqCd/BSKSzmV6Aobs7MtB97b134mRYLdYuUUwszWAyuA0+Om04FHo0dAmtuB8yTVRDk/GfipmTWZ2VQzm2lmM4FvE7wKXKlyRhQZxcotVk4v9MFLa9h47KUtGaUKYO+JY/nKBw/hzsdeAeCG366maWNriXrn5FKMYpWZNYXMTH5Ps6YJjUkbM1tnZm3x/T1x+yFx/SUz64zvfwDUAwf09UZG1XhmQAcoPi6lIL3EpfRmmS2KdAILx+mBC4CLJD0LXBTXkbRE0vzY5r8IFtiVwJ+AL5vZc6XorOOUI69GV8C9XbFyeqcvY4jTJD0m6deSjip0woHGsP5h5QYARsdSLe85ZB8u/Z/HaYva1kubdngWwDKiV8VqoLOmAJL2TxpJehMwE3gmz753Ax3AS329kYzFyjMDOgOgL3EpvZynxwdp1mLlipVTGDN72szeYmbz4uszcftJZrY8vu8wswvNbHZcbihwrsu9hpUzEnFXQGcI6MkTqwsDjWH9/aqgWH30yBAG89Bzr7F2QzbrXxJz5ZQHxRYIvgBYLOkyYBNwFoRZU+Cy+Af/X8BbCLOm0HXW9GuSjiAoTbuBM81sXdy3WNLeQCewFfhrMyvknlUQdwV0IsXGpRSit7iUxDKbaEuNwH25J4mD2xsA5s+f382M6skrHMdxhodXt4bAf3cFdIqgqDFEagyLmd0jKfHEun8wO9O6u51HmjZRI7jwuNn88MHneWrdViRIcrV5FsDyoijFysyeJihNudtPSr3vAC4scPzCHs79zmL60BteJNiBYGGVlFhYb6WwhbXQ8U3A1GRd0uVAfWqm/3bgfGB5TF6xgKw1t2iyRYLdYuU4jjNUmFkmK+DebrFyeqHYMYSk/c3spfi+iyfWYNG0sZXTbnyAtg77/9u79/C46vvO4++vLr7IMjdZpoARxsYmFwKpY4eSDYGkXNo8gXhbWKAB3OBgzO6SJ6FkN2xaQsmTpE9N6G6LkwAxwQlZmhJYSBOXWwN0k+ViA46BBnzDCDAgYQy2LGNbM9/945wzczyakY6kkWbO0ef1PPNo5lxmfqNzdHR+t++XiU0N7NmXZ+6hrTy/dScOGEEgC0UBrC+ZyZQ3IeyxUl4gIcG8FDP7uJm9ClwJXBYmqT4zwXsvAw4ys40EwS2WuPvOoRZQQwFFREbfjvf62L0vR8uERqZOTDpIR8a5JHNbv2Vmz5nZb4Fb2H8kVlUsXrma198JGgX29uVZvHI1W8PXkdntrTx45Sl0tLVU86NlBDJzlVGPlUQS9rD+mgRBUtz92pLXu6hCfraJheAVaggQkfQzs7nASqAN2AZcHEZOjW/zewRRVY8GmoFvuvvt4bpG4O+BPwIc+Bt3/8FIy/VmLCJgOLxbZEAJ7yEqjsSqls3du4juaL3wuniPGy2T+pKZHqumBs2xkvQozrFSj5WIZEKU+2cusJwwLUWJG4A14YT/TxC0+kfR1j4HHAPMAU4CrjWzmSMt1OuKCCgpdXR7sRcqmkc1u70VK1km9SUzFavmJlWsJD2ioYB7VLESkZQbQu6fE4D7AMI5K2uB/xSuO48gz1o+XHcPwxwd0Lmtl9NveJTZV6/iK3f+FlBEQEmfq854X+F5NI9qxaIFHDO9lUYzza2qU5kZCtgc5bHKayig1L9i8Ao1BIhI6vXL/WNmUe6f+KT/pwhy/6whmOz/MWBLuC5xjkAzWwIsAejo6Oi3fvHK1Wzs6sGBrp1BRMBHXuyic1uv5qJIamx9ZzcA535kBsvOPaGw/MErT6lVkSSBzPRYRXOs1GMlaaDgFSIyDv0FcChBT9XfA/8KDDm9ymB5geJzUyLv9O5TElVJlac7twMw76iDa1wSGYrMVKyKeazUYyX1rzDHqk8VKxFJvULuHygEoiiX+6fb3S909xPc/SxgKvDv4eooR2Cko3T/pMrNO9FEf0mbZzrfAWBehypWaZK5ilWfeqwkBTQUUESywt27CHqhopx+lXL/tJlZU/j8U8CHgP8drr4TuNTMGsK5WQuBnw2nPCsWLWBi0/63N5roL2ny5o73eO2d3Uyd2MSc6a21Lo4MQWYqVk0N0VBA9VhJ/dNQQBHJmCS5fz4K/M7MXgCuA85y995w3Y+BzcAG4HHgOnd/aTgF6WhrYc6hwc3okQdP1kR/SZXObb0sXP4bAHJ559Xtu2tcIhmK7ASvUFRASZGJ6rESkQxJmPvnXwjCqZfbPwdcXq3yRDktb7poPh84/IBqva3IqFu8cnUhTcDufTkWr1ytgBUpkpkeq2JUQN2oSv0rDAXUHCsRkaqLIgRHga1E0iI+F1BzA9MnMxWrpih4RZ+GAkr9m9SkPFYiIqMlmm8dTRMQSYv4XEDT3MDUyUzFqhAVUD1WkgIKXiEiMnoKPVYNmbnNkXFixaIFhQaBow5p0dzAlMnOHKuwu79PwSskBYoVK/VYiYhUW3QvoKGAkjYzDp6MhaftfV/6ROF+QdIhM005xTxW6gGQ+leICqg5ViIiVVfssVLFStLl3d372JdzDpjUpEpVCmWmYhW1SincuqSBhgKKiIyeXDgtIJp/LZIW3T17AGifOrHGJZHhyMwVp7lBCYIlPSY1aSigiMhoiYYCNqrHSlKme6cqVmmWnYqVhgJKihQTBOt8FRGptmgoYLPmWEnKFCtWk2pcEhmOzFSsCkMB8xoKKPUvShCscOsiItUX5bRUj5WkTaFi1aoeqzTKTMWqGBVQPQBS/xS8QpIws7lm9piZrQ9/zimzTaOZLTezTWa20cy+EFv3V2b2vJmtM7OnzOzMsf0GIrVR6LFSuHVJGc2xSrfMXHGKQwHVYyX1b0JjA2bB+ZpTL6tU9n1gubvPBZYDN5XZ5nPAMcAc4CTgWjObGa57Eljg7scDlwA/NbPJo11okVrK5R33ILlqg3qsJGU0xyrdElWsqtBqeq2ZdZnZ2vCxPLauxcx+Gu7zgpl9ZjhfpElzrCRFzEwBLGRAZjYdmAfcES66A5hnZu0lm54H3OLueXfvBu4BzgVw9/vdvTfcbh1gQNuoF16khqJhgAq1LmmkilW6Je2xGmmrKcCP3P3D4eO/xJZfBexw92OAs4AfmFnr0L4GNDcoQbCkSzGAhSpWUtaRwGvungMIf24Nl8d1AC/HXneW2QbgYmCTu79ausLMlpjZGjNb093dXZXCi9RKITmwhgFKCmmOVboNetWpRqvpIM4jrKi5+wZgDfDHyYpfpKiAkjaFXFZ9OmdldJnZKcA3gAvKrXf3m919vrvPb28vvbSLpIuSA0uaaY5VuiVpzqlWq+n54QTqB8zspCHsBwzeoqqogJI2xSTB6rGSsl4BjjCzRgiGWwOHh8vjOoGjYq874tuE19vbgYXu/uKollikDkRBrJoUal1SZl8uz9u79tJgcMiUCbUujgzDWPWTfx84OpxAvQy418yGNM5/sBbVQo+VWv8lJSY2aSigVObuXcBair1MFwDPhCMC4u4ELjWzhnAkwULgZwBmtgD4KXCOuz89NiUXqa0oIFCjhgJKymzr2QtAW+tEpQpIqSRXnRG3mrr7G+6+L3z+YLj8uMH2G4qoYhVNWhWpd8UeK52zUtFS4AozWw9cEb7GzFaZ2fxwmx8Dm4ENwOPAde7+Urjuu8Bk4KZY8KAPjek3EBljSg4saaX5VenXNNgG7t5lZlGr6e0M3mp6N0HUqYXAyQBmdoS7vxY+/zAwE3gxtt9lwJow2uACKswDGPCLREMBFbxCUiIKXqEkwVKJu78AnFhm+adjz3PA5RX2XzB6pROpT1HwCrX4S9p097wHaH5Vmg1asQotBVaa2TXAdoLoUpjZKuAad19D0Gp6IkGrKezfavotM/sIkAP2Ahe5+xvhumXAbWa2MVy/xN13DvWLREkAFbxC0qIYvEIVKxGRaolGrkQjWUTSQqHW0y9RxaoKraaLBnjvXSSLHjigqMtf4dYlLYp5rNQYICLpZmZzgZUEI1a2AReHkX7j20wHfkgQoKoZeBj4orv3mdm1wH8mCI4F8JuS1CyJ9eXVYyXppIpV+mWmOaeQIFhzrCQllMdKRDIkSb7L/wH8LgxkdTzwEeBPYusr5bsckmIeK1WsJF00xyr9MlOxmqA8VpIyCl4hIlkwhHyXDkw1swZgIjABeK3a5YmGAircuqRJ57Ze7no6yN9+879tpnNbb41LJMORmYpVk4YCSsooj5WIZETSfJffAOYCrwNvAPe7+29i6yvlu9zPYHkt+xRuXVJo8crV9OwJ7gfe3PEei1eurnGJZDgyc9VpLkQFVOu/pMPEaCiggleIyPhwLrAOOAw4AviEmZ0Trkuc73KwvJZRA2uzhgJKimzu3lV47iWvJT0yVLGKhgKqx2q8M7O5ZvaYma0Pf84ps80ZYYvnHjO7vmTd58NW07Vm9qyZfTG27loz64rlBFo+3HIqeIWIZETSfJdXAD9x97y7vwvcC3wSBs13OSTRUEAFr5A06WhrKTxvMJjVPqWGpZHhykzFKgpe0aceK0k2iXoz8AWCltFSdwEnuPuHgY8Bf2Fmx8fWV2WCdTQUUHmsRCTN3L0LiPJdQuV8ly8BfwRgZhOA04DnwtdHRBuVyXc5JIUeK4VblxS54pPHFJ7Pbm9lxSKlIUyjzFx1oi7/veqxGteSTqJ2943uvhboK30Pd9/h7tGJ1EIQFrjqJ9buvcFH3/xvmzn9hkc1UVVE0mwpcIWZrSfomVoKQb5LM5sfbvMl4GQze5agIrYeuCVc9y0ze87Mfhsui+e7HJKcwq1LCm3fvQ+APzuxgwevPGW/HixJj6QJgute1DLVp3Dr412/SdRmFk2i7j/LuQIzOxv4NjAbuNrdn42tPt/MziCYfP11d3+szP5LgCUAHR0dZT/jH1cHo2Qc2NTdw+KVq3nwylOSFlFEpG4kzHe5CTi9wv4V810OVRS8ollRASVF1r+xE4BjD51a45LISGSmx0pRAaWa3P3n7v5BgghWF5nZseGqRBOsB5tcDfBWz57C87xroqqISDVEUwLUYyVp8sKbQcVqripWqZaZilXUY7VXc6zGu6STqBNx907gSeAz4euqTbA+7MBJheeaqCoiUh1Rj1WT5ljJMCQJgBXb9lgz6y0NgjVU+byzIaxYHft7qlilWWauOs0KXiEMaRJ1RWb2/tjzaQRRq54NX1dtgvVfn12sj2miqohIdRQSBKvHSoYnSQCsqOH2JuCekX7ga+/spndvjvapEzlkyoSRvp3UUGbmWDU2GGbBkKpc3jUEYHxbCqw0s2uA7cDFEEyiBq5x9zVm9nHgH4EDglV2PrDY3e8HloRzqPYBBtzo7g+E7/0tM/sIkAP2MoIJ1lGr1BEHTdbcKhGRKommBDQpQbAMUSwAVjQX8A7gRjNrL9NA+1XgF0Br+Bi2FzW/KjMyU7ECaG5oYG8uz75cnsaGxloXR2ok4STqXwMzKuz/5QHeu2oTrA9qaQbgnd691XpLEZFxrzAUUA2sMnSJAmCZ2QnAmQQjWv5qpB/6ouZXZUammnOiCEDRRVWknrVObKKxwdi1N8fePg1hFRGphugeoFFRAWUUmFkzcDOwNKqADbL9EjNbY2Zrurv7z0ro3NbL9x7ZBMAv1m1V6pWUy1TFSkmCJU3MjIMmB71W74b5K0REZGSie4Bm9VjJ0CUJgHUYQSqWVWa2hSA/26VmdnO5NxwsSvDilavp2RPktezu2cPilaur+HVkrGWqYhX1WCkyoKTFgYWKlYYDiohUQzFBcKZucWQMJAmA5e6d7j7N3We6+0zgfwK3uPuS4XxmPNWKK/VK6mXqqlOMDKihgJIOB7aox0pEpJr25ZQgWEZkKXCFma0HrghfY2arzGx+tT8snmpFqVfSL1PBK6IkwfvUYyUpEQ0FfKdXFSsRkWrI5ZUgWIYvSQCskuXXjuTzVixawCeWPQwElSqlXkm3TFWsoh6rfeqxkpQ4qCXIV6GKlYhIdShBsKTJjIMnF54/+OVTMFODQJpl6qrTHI6njpIDitS7aI7VOxoKKCXMbK6ZPWZm68Ofc8ps02hmy81sk5ltNLMvJFknkmXFPFa6QZX6F8UFaG40VaoyIFMVq8JQwD71WEk6HKiogFLZ94Hl7j4XWA7cVGabzwHHAHOAk4BrzWxmgnUimVXssdJNqtS/aPrKBPWwZkKiozjSltPYNseaWa+ZXR9bdpuZvWpma8PH14b7ZQpDAdVjJSkRJQl+V0mCJcbMpgPzgDvCRXcA88ysNFbveQTRqPJh1Kp7gHMTrBPJrCjcunqsJA2iPJYTmlSxyoKkc6yiltPbzexCgpbTT5VsE28dbQOeMbOH3H0LFHIB3ETwz73U37j7jcMo/34KCYI1x0pSIqpYaSiglDgSeC1KPunuOTPbGi6PZ5jsAF6Ove4Mtxls3X7MbAmwBKCjo6Ma5RepmUKPlcKtSwoUhwLqfM2CQY9ilVpOAb4K/AJYP+JSVxBdVcn1DQAAIABJREFURBUVUNLiQEUFlDowWAJLkTSJ5llrKKCkQTR9RT1W2ZDkKPZrOQWiltO4iq2jZnYCcCbwdxU+40oze9bM7jGz95fbwMyWmNkaM1vT3d1dbhOam1SxknQ5cHIQFVBzrKTEK8ARYU9/1ON/eLg8rhM4Kva6I7bNQOtEMquYIFgVK6l/e3M5QBWrrBj1o2hmzcDNwNKoclbia8Ax7v4h4G7gvuhmIi5Ji2pzg4YCSrocpATBUoa7dwFrgQvCRRcAz4SjAeLuBC41s4ZwFMFC4GcJ1olkViFBsIYCSgrs6VPwiixJchRH2nJ6GDAbWGVmW4AvEfyzvxnA3V9z93z4/EdAKzBjOF9GCYIlbYoJghW8QvpZClxhZuuBK8LXmNkqM5sfbvNjYDOwAXgcuM7dX0qwTiSz1GMlaRI1BKjHKhsGDV7h7l1mFrWc3s7gLad3EwSvWAic7O6dwLRoIzO7Fmh196vC10e4+2vh8zOBHPDacL5MMSqgeqwkHeLh1vN5p0E3AhJy9xeAE8ss/3TseQ64vML+FdeJVJuZzQVWEvz/3wZc7O4bSraZDvyQYJpAM/Aw8EV37wsbbf8e+CPACYJa/WA4ZYkaVzXHStIgigqo4BXZkPQojrTldCArw/lVvwX+Ejjb3fuG8iUi0UnZpx4rSYmmxgZaJzaRd+jZO6zTXkSkHiTJu/Y/gN+5+/HA8cBHgD8J11Ut71pOUQElRZTHKlsShVsfactpyT7Xlrw+LUkZkohyVmgooKTJgZOb6dnTx7u9+zhgUnOtiyMiMiSx6MGnh4vuAG40s/aS0S0OTDWzBmAiMIHiCJVCZGGg28yiyMLLhloeJQiWNFEeq2zJ1FEsRgXUUEBJj0IuK4VcF5F0Sho9+BvAXOB14A3gfnf/Tbgucd61wShBsKTJHg0FzJRMHcVm9VhJChWTBCuAhYhk2rnAOoKgVkcAnzCzc4b6JoOlXyn2WGXqFkcyKrpnnageq0zI1FFsKsyxUo+VpIeSBItIyiWNHnwF8BN3z7v7u8C9wCfDdYnzrg2WfiW6B1CPlaSBhgJmS6aOYjEqoHqsJD2UJFhE0mwIeddeIoj6h5lNAE4DngvXVS3vWjF4hSpWUv/25qKhgDpfsyBjFatwKGCfeqwkPZQkWEQyIEn04C8BJ5vZswQVsfXALeG6quVdixpXFbxC0qAQFVA9VpmQKCpgWhTCravHSlJESYJFJO0SRg/eRDFyYOl2Vcu7VkwQrBtVqX+FoYCNjTUuiVRDpq46UeuUogJKmkQTrX/wf1/i9BsepXNbb41LJCKSXvs0x0pSpBAVsEnnaxZkqmLV3BCFW1ePlaTH7Y8HEYYd2NTdw+KVq2tbIBGRFMtpKKCkSCEqoKJYZkKmjmI0x6pPFStJkTd3vFd4nnfY3L2rhqUREUm3YlTATN3iSEbtVR6rTMnUUWwqRAXUUEBJj6PaphSeNxjMap8ywNYiIjKQPkUFlBRR8IpsydRRLEYFVI+VpMdtn19A9P9/ZtsUVixaUNsCiYikWCHcuoYCSgooj1W2ZOooFqMCqsdK0uOotikcP+MgAL79Jx+io62lxiUSEUmvqAdAQwElDYp5rHS+ZkGmjmI0FHCv5lhJykTD/zZpfpWIyIiox0rSZG+Ye1U9VtmQrTxW4XiqHbv38offeYQtb/Uyqz0YWqVeAKlns9tbAdjc3VPjkoiIpFuxx0oVK6l/UWfARFWsMiFTRzHqRn3ype1s6t5Fzl3hq8chM5trZo+Z2frw55wy25xhZmvMbI+ZXV+y7vNmts7M1prZs2b2xdi6RjNbbmabzGyjmX2hGmWeXeixUsVKRGQkij1WmbrFkYza25cDNBQwKzLVYxV1+++JBa9Q+Opx6fvAcne/3cwuBG4CPlWyzWbgC8A5wKSSdXcBt7m7m9lU4Dkze8Td1wGfA44B5gBtwDNm9pC7bxlJgaMeKw0FFBEZmX2KCigpEiW0nqCKVSZk6iiWq+2bwlePK2Y2HZgH3BEuugOYZ2bt8e3cfaO7rwX6St/D3Xe4exQBpQVoJsjfC3AecIu75929G7gHOHek5e5oa6GxwXh1ey/v7cuN9O1ERMatqMeqURUrSQFFBcyWTB3Ft3ft7bdsxsGTFb56fDkSeM3dcwDhz63h8sTM7Gwzex54GVjm7s+GqzrCZZHOcu9tZkvCoYZruru7B/28iU2NHHnwZPIOL2/rHUpRRUQk5O7FoYCqWEkKKCpgtmTqKP7tfS/0W/bXZ39QgStkyNz95+7+QWAucJGZHTvE/W929/nuPr+9vX3wHYgPB9Q8KxGR4eiL9VaZqWIl9U89VtmSqaO49Z33+i3r2rGnBiWRGnoFOMLMGiEINgEcHi4fMnfvBJ4EPhMu6gSOim3SMdz3LjV7uiIDSsDMWszsp2GAlBfM7DMDbHtpuN0mM7vRzBrC5Z81s6fM7Dkze97M/mLsvoFIbfTl1Fsl6VKoWKnHKhMydRRntU8hupZGl9Q3VbEaV9y9C1gLXBAuugB4JpwPlYiZvT/2fBrwSSAaCngncKmZNYTzthYCP6tG2Q+c3AzAdx5Yz+k3PEqnhgSOZ1cBO9z9GOAs4Adm1lq6kZkdDXwdOIkgoMoc4MJw9RvAWe5+HPAx4HIzO3ksCi9SK315hVqXdInSA6jHKhsSHcWE4asHDUNtZseaWW88vPVQWmYHs2LRAma3t9JoxrSpEwF4c2f/XizJvKXAFWa2HrgifI2ZrTKz+eHzj5vZq8CVwGVm9qqZnRnuvyRs4V8L/Ctwo7s/EK77MUFEwQ3A48B17v5SNQp9x5OdQBAlQ2kCxr3zCKJZ4u4bgDXAH5fZ7hzgHnfvdvc8cEu4L+7+hLtvDZ+/C/yO/XtbRTJHodYlbfaqYpUpScOtJwlfPWAY6nBI1k0EUdTiCi2zYYXt/5rZMe4+5PFQHW0tPHjlKQDc99zrLL39abp2qGI13rj7C8CJZZZ/Ovb818CMCvt/eYD3zgGXV6GY/bweG8qqNAHjXqIgKUm3M7P3AX8AXFbuw8xsCbAEoKOjY3glFqkD+zQUUFImGgrY3KhzNgsGrR4nDV/N4GGovwr8AlhfZr8kLbNDMv2AIDVR104NBZR0iKcFUJqAbDOzp83srQqPxip/1mHAvcB/jnqwSg0n2IpIPSr2WOkmVdJBQwGzJclRTBq+umLLqZmdAJwJ/F2Z9x+V8NWHhhWrN9VjJSmxYtECpk4KOpGnTZmgNAEZ5u7z3H1ahUeO5EFSBtwubBh7CPhbd7+z+t9EpL5EN6lNDbpJlXTYE/ZYTWysapua1MioX3nMrBm4GVgaVc6GY6gtqu2twRyr7p17Ci1YIvWso62F//5H7wPgY8dMU5qA8e1OwmF74RDpBcB9Zba7C1hoZu1hNMBLgX8K92sDHiSYI7hiTEotUmPqsZK0iRoDmpt0zmZBkopV0vDVlVpODwNmA6vMbAvwJYKoajcPst+ITGhq4JApE8g7bOvRcEBJh9/vOAiAZzrfqXFJpMaWAQeZ2UaCIdRL3H0ngJldZ2ZLAdx9M/ANgkAqGwgCq9wevsdXCfKwXWZma8PH58f4e8g4kTDI1Y9i5+JaM8ub2dnhumvNrCu2bvlwyhFFBWzUHCsZpoTn8ufNbF14rj5rZl8c7ucp3Hq2DBq8wt27wuhoFxD8w64UvjoKQ303QfCKhcDJYR6gadFGZnYt0OruV8X2uwxYE2uZvYAqmD51Im/v2kvXzj2FOVci9ezYQ6fSMqGRzrd7eatnD9PCnlcZX9x9F/vPUY2vu6bk9U2E81RLln8F+MqoFFCkv0GDXLn7xdHzcIrAr4D7Y5v8KHZvMCxRgmAFr5ARSBKw7S7gNnd3M5sKPGdmj7j7uqF8UF8uT96DedVqDMiGpNXjQcNXM/ww1BVbZkdK86wkbZoaGzh+xoGAeq1EJB2GEOQqbjHwE3ev6pCSYoJgtf7L0CU9l919h7tH80xagGaCbClDEkWxnNDYgJkqVlmQKNx6wvDVicJQu/u1Ja8rtsyO1KEHhLmslCRYUuT3Ow7m8c1v80zndk7/wKG1Lo6IyGD6BbkysyjIVb9oU2Y2Afgz4LSSVeeb2RkEya2/7u6PlfuwgdID9GmOlYxM4nM5HMb6bYLpLle7+7Pl3nCg87UwDFARATMj00dy+lT1WEn6zDhoMgDffWQTp9/wKJ3bemtcIhGRqloIdLr72tiy7wNHu/vxBCNZ7g0DsPQzUDCrvkJUQFWsZHS5+8/d/YMEc1kvMrNjK2xX8Xzdkwtiuml+VXZk+khGPVbKZSVp8oNfF0fQburuYfHK1TUsjYjIoJIGuYpcAtwaX+Dub7j7vvD5g+G+xw21IMU5Vpm+vZHRM9RzmTCWwJPAZ4b6YYWhgOqxyoxMH8lCkmD1WEmKxHuo8g6bu3fVsDQiIgNz9y4gCnIFlYNcYWYzgJOBn5QsPyL2/MPATODFoZZF4dZlJJKey2b2/tjzacAngbJDAQeioYDZk+kjWQhesVMVK0mPWe1TCs+t5LWISJ1KEuQKYBHwz+6+vWT/b5nZc2b2W+AW4CJ3f2OohYhyAinCmoxAknN5iZk9H0bN/leCfIEPDPWDCjmsNBQwMxIFr0iraKz1c6/t4PQbHmXFogVKuip1b8WiBfzH7/6Gbbv2csDkZlYsWlDrIomIDChJkKvw9Tcr7L+oGuWIeqx0oyrDlTBg25er8VnKYZU9mT6SX727mE5Ac1UkLTraWvhf5/8+ALPbp6gxQEQkoWjOinqsJA32aChg5mT6SL7Urbkqkk4fOiLIZfX81h2FnlcRERlYscdKFSupf9FQQPVYZUemj6TmqkhaHdjSTMchLezpy7Ohq6fWxRERSYW+fDTHKtO3N5IRCl6RPZk+kisWLaC9NQi53jqpSXNVJFU+NCPotXr21XdrXBIRkXToy0Xh1tVjJfUvqliphzU7Ml2x6mhr4dY/DypTbVMmaK6KpMrx4XDA/7fpLU6/4VFmX71KCYNFRAYQ9VipYiVpUBgKqB6rzMj8kXzfYVOZ1NzAlm29bOtRomBJj+lhgut71m5lQ1cPOXcFYRERGUCf8lhJiuwtVKwaa1wSqZbMV6yaGxs4fsZBADzT+U6NSyOS3D/8amO/ZXmHDV096rkSESmjkCBYc6wkBTQUMHvGxZVnXsfBADzdWZqPUKR+vfxW5YrTRvVciYj0o3DrkiZRj9VEDQXMjHFxJOd1BD1WqlhJmsxqn0KlewNX+gARkX5yefUASHooQXD2jIsjGc1VeXzz25x2wyMaQiWpsGLRAma3t9JoxpzprcxsayF+q6D0ASIi+yv2WI2L2xtJuSh4RbMqVpnRVOsCjIWv3Lmu8HxT1y4uvvUJmhob2Nzdw+z2VlYsWqCIgVJ3OtpaePDKUwqvO7f1cuGKJ+h8u5fmBlP6ABGREkoQLGmiPFbZMy6OZHzIlANbtvWysauHvMPGLs1VkXToaGvhoStPYUJjA/vyzsFTmmtdJBGRutKXixIEq2Il9a8YvGJc3I6PC+PiSA44VwXNVZH0mNDUwJxDWwF44Y2dNS6NiEh96Sv0WI2L2xtJub3h0FX1WGXHuDiS0VyVSqI5WCJp8MHDDwDg37fuqLhN57ZeJRUeIv3ORNIvqlipx0rSIOqxUlTA7BgXRzKaq9Jo5S+0v3fApDEukcjwfeCwwStWi1euZqOSCg/Jxbc+UTeJmM2sxcx+amYbzewFM/vMANteGm63ycxuNLOGkvWTzOx5M1sz+iUXqa2+XJTHShUrqX8KXpE94+pIzmqfQlS3arDg9eTmBp555R1mXf1LtVJLKnzg8AMB+PfXK1esNnX34OHz/DgMzZ609ynabtbVv2RLbJs6SMR8FbDD3Y8BzgJ+YGb9ut3N7Gjg68BJwJzwcWHJZt8EHh/d4orUh74w3LoqVpIGCl6RPYmOpJnNNbPHzGx9+HNOmW0azWx52Gq60cy+EFv3eTNbZ2ZrzexZM/tibN21ZtYVrltrZsur89X6W7FoAceE4atnt7dy259/lIlNjUBwI1XrVmqRJN532FQAXnxjJ5u6ezh12cP9KhDtU4vDW43xF5r9/FseK/Q+bezu4eJbn+BT1z/SrwHlkpVPsiEMZFNODa8J5wE3Abj7BmAN8MdltjsHuMfdu909D9wS7guAmZ1MUNn68aiXWKQOFIYCqgdAUiBKEKw8VtmRNNz694Hl7n67mV1I8A//UyXbfA44huCfeBvwjJk95O5bgLuA29zdzWwq8JyZPeLuURz0H7n7VSP9MoMpDV8NsOO9fYXn47FlX9LngEnNHH7gJLa++x5/+J1HC8ujSsCDV57CBw47gDd3dAPQOqlp3IRm39zdw59+7/+xvbf4d+3Ofr1RG7p6+MSyh2k0yFWoUEVqeE3oAF6Ove4EjhzKdmY2BfifwNkE1+WKzGwJsASgo6Nj2IUWqbVc+EfdrB4rSYGoYtWsHqvMGPRImtl0YB5wR7joDmCembWXbHoecIu75929G7gHOBfA3Xe4e3QL0wI0A4Pc0oyNeFALs/HXsi/p9G6sQSASVQL6cnmeenl7YfmUCU0cecjksSzemOvc1ssnr3+ET33n0f0qVQMprVQ1GMyZ3sqc6a39hgxXm5k9bWZvVXg0VuljlhE0iL022IbufrO7z3f3+e3tpZd2kfTYl1e4dUmPwlBA9VhlRpIjeSTwmrvnAMKfW+nfejpgC6uZnW1mz4fbLHP3Z2Pbnh8OFXzAzE4qVwgzW2Jma8xsTXd3d4JiJ7Ni0QIOmBR03B3SMmHctOxnWcKhq2eE59MeM7u+ZN1fhZP915nZU2Z2ZmzdbWb2amzo6tfG4juV6t2b67csGvL31Mvb2fFeH0dPm0LblAm8seM9Nr+V7Z7Yi1Y8wUsj/I5RsvDSIcOjcU1w93nuPq3CI0dw/TwqtksH8EqZtxpou48D15jZFuAfgQ+Z2TpERkHC6+6PYtfOtWaWN7Ozw3UVpxMMRU7h1iVFFBUwe5IOBRwxd/858HMz6wDuMbNV7v4iwTDDb7r7PjM7HbjXzN7v7ttK9r8ZuBlg/vz5Vevt6mhr4W/POZ6ltz/N0dOm4DgnfftfeXPHe4Wbqo62lmp9nIyNJENXNwNfIJijUhoW8kngO+7ea2YnAI+a2WHuvjtc/zfufuMoln9Qs6ZNYXP3rv26fRvM+N6F87jzqVcB+NT7ptO1cw///Nut/GbjW8xub6VzWy+XrFzN5u6e1J3fndt6+fxtT/LSW7v2K3tfLs/Lb/cPMNFgQat1Lu8V51BF281ub91vmHDpkOEauBO4DFgT3qAuAC4os91dwL+Z2V8D24BLgf8N4O7HRxuZ2anA9e4+f5TLLePXoNddd784eh5eW38F3B8uGmg6QWJRVED1WEkaKCpg9iQ5kq8AR0TDU8Kfh9O/9TRRC6u7dxLcuH4mfP2Gu+8Lnz8Y7nPc0L7GyHx8TjvNjcbTnds56x9+zevvvkfeYaOCWaRO0qGr7r7R3dcCfaXv4e73u3t0p76OoDOobfRKPXQ//POPcsz0oFdlzvRWOg5pIefOaTf8Gzc9uhmA+557nd8Lc7R9/d7nOf2GR7n41ifYFAZr2NiVjvM7itz3iWUPs6l7VyFi3yeWPcycr61iztf+pex+s9tb+fElJzK7vfh7+sdL/4A501tpAJobrVCpqsOe6mXAQWa2EfgFsMTddwKY2XVmthTA3TcD3yCI+reBoMHg9toUWcarIUwZiFsM/MTd94SvK04nGIooKmBzoypWUv8UFTB7Bu2xcvcuM1tL0Fp6e/jzmfDCF3cncKmZ3U1wE7oQOBkg7IH6Xfh8GvBJ4O7w9RHRHAAz+zAwE3hx5F8tudaJTZww4yDWhEOoIh4LuZymlv1xrt/QVTOLhq4OZwzpxcAmd381tuxKM7sM2ARcHZ3bY6k0EMuJ33yo3zavv/set/1mCxBMaNzUvX/0u2hZvenc1svilavZ1NVDY6Oxb4AIE/F1TQ2GezAcMv73Wtr7VAe9UYNy911UuKl092tKXt9EGEFwgPd7BFBvlYyWIV13zWwC8GfAabHFSQO2DBhspdhjpRtVqX/FHis1BGRF0qGAS4GVZnYNsJ3gZhMzWwVc4+5rCML5nkjQagpwnbu/FD5fYmZnAPsIWv9vdPcHwnXfMrOPADlgL3CRu78xwu81ZFu2VZ6fEY+2JuOHmZ1C0Btwemzx14DX3T1vZhcD95nZrOiGIrbvmEZZe6tnb79leYe8+36vS7nD7KtX9auM1EI01G9TLApffrCwfTHusOnbnx6NoolIdS0EOsNRA0M20NSAKNx6k25UJQX2qMcqcxJVrNz9BYJKU+nyT8ee54DLK+z/5QHee1GSMoy27bsqRxKLJwv9xmeP4+r/s46Xt/Uyq30Kty76qHqy6kth6GrYalpp6OqAwiAqtwOfDecCAhCPsObuPzKzvwNmsH9L66jNCaxkVvuUfj1S0RyjvpwX5mJNbm5g9748RtBj5UDOvTi0bnrt5l197geP88r23YNvWMZoRe8TkUSGet29BLi1ZFk0nSAan1zag5WIEgRLmkTh1hW8Ijt0JEOz2qfQEAux3NxohZDLkQ1dPZx/y+O89FZvOEdlF5esfLIwB6Q0SauMPXfvAqKhq1B56GpFZrYA+Clwjrs/XbLuiNjzMwl6WgcNZz3aVixawOz2/nOHfnzJicyeXqxw7N4XXMTvvvxjlLvv2BQm0y13Pkfn+ayv/pI5X1vVL9nucHVu6+XUZQ8nqlSlbJ6UyLgwlOuumc0gmCbwk5JV0XSChnBu1kLgZ0Mti4JXSJooeEX2jFlUwHq3YtECFq9czebuXcxqn8I3Pnscf3Xvc2zoGngOysauXZx6/cOFnoKo5b+5MYhGlrbIaxkx6NBVM/s4QQjqA4JVdj6w2N3vB74LTAZusmLt+qIwRcBKMzsUyAM7gLPdvV8AjLFWLvl15KErT+XEbz3Emzv2FJb9t7vWMbu9lY3dPcRGC5IPk+lGPVrxYbCLV64Otqc4RC8KgDHYMNlo3lT09xX/m/jzHz65XwLfuEp/RxqWK1J3kkwZAFgE/LO7by/Zf6DpBIn1Kdy6pIiCV2SPKlahcjemD155Cqff8Gi/IValyq2LJtVvDHsAmhsbyt5USvUlHLr6a4IhfOX2r9j14e6nVVpXz97auf8crM3du3j4qlNZvHJ12caD6JSOkg5H+7j3325Td0+/gBNRZahcA8XGkjmL5fJP1XJIoogMXZLrbvj6mxX2rzidYCiiipV6rCQNlCA4e1SxGkTUkzVYz1UlHvYAROI9Wn05pym8CT3ykMkYxitv71blS6puVvuUQu9UNB8pakzo3NbLoh8+WbaCEyUdBmhrnUDXzj39tjlwcjPn3fwYr7/7HlDszdrU3cNFtz7RL6pfPNrmoo/NLMnF1T+nlIhIUrko3LqiAkoKRP8fm9VjlRmqWA0ifvMZH8q0L5en8+1grpURRCAaKCx0qWjb6OfL24rzS0orX40NRt737wGoVe/XQEO6SreJei/iFUgNjayN0qGu8flIHW0tPHzVqfz+dQ+wvXf/IC4NDcY1Z32AP/zOI/tVqqIhenkn3Kd/8Je8DxzVb0NXD395z3MAHNLSzLu7+/qVTURkKDTHStJEPVbZo4pVQqVDBctVMIDE+XeSiPaPhjZEwTMiUQXsoMnNNDQEkQ2bwopMQ0Nw49sU+9mX77+8scHIuXPYAZNoamzglbd7g2XxfQxyTmF56edHFb9prRPAoTsW+jtfUoFU6PraGGgOVmTH7v5TxXJ556IVT+63bM70Yo/SB79+H7v25PrtN1RtrRN5+pozRvw+IjJ+dW7rLeTmu/z2p/jx4hPViCd16+VtuwpRAc/6h1+r0TkjVLEapko3qvFlSeZnVcM7u4u9BVEFJqoARZWyffnyy6OfW8NhXGX3Ccufq/BFouXdO/vnUioVn7Mj9SUesr3BwMzKHvP48du9t3+lqrlCo8Kc6a379fRWek8RkeFYvHJ14drTub1XjXhS1xavXF14rkbn7FDf4yiKQmA3mpUNE20Uw0XPbGth5jhoqVC+ofoVP19nt7fipZEq6H/8Zre37pemYM70VjZ889P9Qrk3mvHglafwo0tOZHZ764DvKSIyHPEGGlcjntS5l7qL8+/V6Jwd6rEaRZUiDQ6k0vykkQ4rrJXSIB3KN1S/Ss/X0294tF849tLjV2nuVjyUe7ziVGnOos4JERmpWe1T2NgVpIRQg43Uu6PbW9jUtUvna8aoYlVnKg0xLL0RjQexOPKQyYVt4pWxpD9zeafjkJZE71EaRjseXjt6D0U2zIZylabS41npfB0oWMZA+4mIDNdg1x2RenLroo/qfM0gVaxSYji9X6Ot1p8vo2sklR9VnERkrOm6I2mi8zWbNMdKRERERERkhFSxEhERERERGSFVrEREREREREZIFSsREREREZERsnK5auqdmXUDL5dZNQ14a4yLMxxpKSeMflmPcvf2UXz/mqtwvuocGB06X0coA+drEln7PlD+O+l8rX9pKetYlFPna/1LS1lrdi+QyopVJWa2xt3n17ocg0lLOSFdZU2TNP1eVVbJ2u81a98HsvmdhitNv4u0lDUt5UyjNP1u01LWWpZTQwFFRERERERGSBUrERERERGREcpaxermWhcgobSUE9JV1jRJ0+9VZZWs/V6z9n0gm99puNL0u0hLWdNSzjRK0+82LWWtWTkzNcdKRERERESkFrLWYyUiIiIiIjLmMlGxMrO5ZvaYma0Pf86pdZkAzKzNzFaZ2Ytm9qyZ3W1m7eG6PzCz34ZlfsDMpte6vABm9nUzczM7Lnxdl+VMM52v1aPztXrMrMXMfmpmG83sBTP7zADbXhput8nMbjSzhnD5qWbWa2Zrw8cTY/cNkv1tmVmjmS0Py77RzL6QZF0tVOH7XGsGmzD4AAAESElEQVRmXbHjsXxsv8HYqtdrK+j6Kv3V6/maxnMV6uh8dffUP4BfAReGzy8EflXrMoVlOQQ4NfZ6GbCCoEK7Efh4uPwvgVvroLzzgH8BtgDH1Ws50/7Q+Vq18up8re7v8xrglvD5HOANoLXMdkcDrwLt4e/8fuDicN2pwJoafodB/7aAi8MyN4Tf4VVg5mDrUvp9rgWur/W5VU+/rxqWTddXPUp/x3V5vqbtXA3LUjfna81/GVX4ZU4H3gEaw9eN4ev2WpetTFn/FHgIWAA8F1s+DeipcdkmAo8BM2MnZt2VM+0Pna9VK5vO1+r/Tp8H5sde/wI4t8x2XwFujL0+B/hl+PxUalSxSvq3BfwSOCf2+kbgK4OtS+n3uZZxUrFK07U1LJ+ur+P4kabztZ7P1bAcdXW+ZmEo4JHAa+6eAwh/bg2X141wqMzlwM+BDmKZt939LaDBzA6pUfEArgNud/ctsWX1WM600/laHTpfq2+/3x/QSfnzcrDt5prZ02b2hJktqn4xK0r6tzVQ+ZP+DsZCNb4PwPlmti4cCnPSaBa4xlJxbQVdXwVIyfmagnMV6ux8zULFKi3+AeghaE2sK+E/2/nAd2tdFqkbOl8zJqzsvFXh0Vilj3kaONLd5wHnA9eY2WlVem8Zuu8DR7v78QTDee41s7Yal0l0fZX0qNtzFerzfM1CxeoV4IjoxiD8eXi4vC6Y2fUEcxbOc/c8QYviUbH104C8u79doyKeArwfeMnMtgAzCMbsH0N9lTMLdL6OnM7XYXD3ee4+rcIjR8lxJmjxK3deVtzO3Xe4+7vh85eAe4D/MBrfp4ykf1sDfc+kv4OxMOLv4+5vuPu+8PmD4fLjRrnctVL311bQ9VUK6v58TcG5CnV4vqa+YuXuXcBa4IJw0QXAM+7eXbtSFZnZt4CPAAvdfU+4+Clgspl9PHy9FLizFuUDcPe/cffD3X2mu88kmPx8JkELZ92UMwt0vo6cztdRcydwGUAYnWoBcF+Z7e4CFppZezhM5FLgn8L9DjMzC58fApxBcL6PuiH8bd0JXGpmDWGkq4XAzxKsG1PV+D5mdkS0kZl9mGAOwoujXPSaqPdrK+j6KkX1fr6m4VyFOj1fx2Ii12g/gPcBTwDrw5/H1rpMYbk+CDjBP7K14eP/hOs+BjwLbAAeBA6tdXlj5d4CHFfv5UzrQ+dr1cut87U6v8cpBP94NobnwGdj664DlsZeXwZsCh/fozgB+78SBMFYCzzHGAd+qPS3BawiDMxBMEn8e7HyL4ntX3FdjY7JSL/PyvA4/BZYDXy61udZLX5f9fDQ9VWPMr/bujxf03quhuWr+flq4YeLiIiIiIjIMKV+KKCIiIiIiEitqWIlIiIiIiIyQqpYiYiIiIiIjJAqViIiIiIiIiOkipWIiIiIiMgIqWIlIiIiIiIyQqpYiYiIiIiIjJAqViIiIiIiIiP0/wF4MKu4kNTzoAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 864x432 with 10 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"HXFQcoG0kWE7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594568572041,"user_tz":-540,"elapsed":42956636,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import shutil\n","new_weight = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + name_input\n","if os.path.exists(new_weight):\n","  shutil.rmtree(new_weight)\n","os.mkdir(new_weight)\n","\n","weight_last = '/content/yolov5/weights/last_' + name_input + '.pt'\n","weight_best = '/content/yolov5/weights/best_' + name_input + '.pt'\n","\n","!cp '{weight_last}' '{new_weight}'\n","!cp '{weight_best}' '{new_weight}'\n","!cp 'results.png' '{new_weight}'\n","!cp 'labels.png' '{new_weight}'\n","!cp 'test_batch0_gt.jpg' '{new_weight}'\n","!cp 'test_batch0_pred.jpg' '{new_weight}'"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtigXSkIl15i","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}