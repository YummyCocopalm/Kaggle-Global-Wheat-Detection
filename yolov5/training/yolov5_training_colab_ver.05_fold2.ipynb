{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov5_training_colab_ver.05_fold2.ipynb의 사본","provenance":[{"file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","timestamp":1594621303712}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1cszNqQoiyO24fzqqlqCnZbQDLYdjznfN","authorship_tag":"ABX9TyO++zCUOMZ1eVeGLNj3wBy8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AiQPodddRTaD","colab_type":"code","colab":{}},"source":["\"\"\"\n","function ClickConnect(){\n","    console.log(\"Clicked on connect button\"); \n","    document.querySelector(\"#ok\").click()\n","}\n","setInterval(ClickConnect,60000)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yf22UTuLusak","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1594572017452,"user_tz":-540,"elapsed":5261,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"5d99f237-c068-44d3-c410-b4a6a2d2d694"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Jul 12 16:40:13 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OoBHduIadAI7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572027326,"user_tz":-540,"elapsed":1365,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import numpy as np\n","import pandas as pd\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlvKV6g3Kcdn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"executionInfo":{"status":"ok","timestamp":1594572035657,"user_tz":-540,"elapsed":9235,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"abd9c6ce-bfc9-413a-ba3c-98979944c8ca"},"source":["!pip install -U PyYAML"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting PyYAML\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\r\u001b[K     |█▏                              | 10kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 7.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: PyYAML\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=70b1da7010df1f1f781a903e21e6292d8da65c73fa249755eb08c02b34e7715c\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built PyYAML\n","Installing collected packages: PyYAML\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SDekTiLTg1WA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594572035659,"user_tz":-540,"elapsed":8685,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"5e5f3545-a10f-4d97-a1a2-47bdfdb720c8"},"source":["%%writefile setup.sh\n","\n","export CUDA_HOME=/usr/local/cuda-10.1\n","git clone https://github.com/NVIDIA/apex\n","pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Writing setup.sh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wPuaO9L9g2GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594572588227,"user_tz":-540,"elapsed":560599,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"210c7c08-e78d-4251-d971-30a09c4c2708"},"source":["!sh setup.sh"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 80, done.\u001b[K\n","remote: Counting objects: 100% (80/80), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 7335 (delta 40), reused 42 (delta 19), pack-reused 7255\u001b[K\n","Receiving objects: 100% (7335/7335), 13.88 MiB | 11.77 MiB/s, done.\n","Resolving deltas: 100% (4939/4939), done.\n","/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n","  cmdoptions.check_install_build_global(options)\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-oe16xvoe\n","Created temporary directory: /tmp/pip-req-tracker-3cu87j89\n","Created requirements tracker '/tmp/pip-req-tracker-3cu87j89'\n","Created temporary directory: /tmp/pip-install-ai2949zz\n","Processing ./apex\n","  Created temporary directory: /tmp/pip-req-build-2l70cf28\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-3cu87j89'\n","    Running setup.py (path:/tmp/pip-req-build-2l70cf28/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    writing manifest file '/tmp/pip-req-build-2l70cf28/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-2l70cf28/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-2l70cf28 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-3cu87j89'\n","Skipping wheel build for apex, due to binaries being disabled for it.\n","Installing collected packages: apex\n","  Created temporary directory: /tmp/pip-record-cgwjmc0_\n","    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-2l70cf28/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-2l70cf28/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-cgwjmc0_/install-record.txt --single-version-externally-managed --compile\n","\n","\n","    torch.__version__  = 1.5.1+cu101\n","\n","\n","    /tmp/pip-req-build-2l70cf28/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","\n","    Compiling cuda extensions with\n","    nvcc: NVIDIA (R) Cuda compiler driver\n","    Copyright (c) 2005-2019 NVIDIA Corporation\n","    Built on Sun_Jul_28_19:07:16_PDT_2019\n","    Cuda compilation tools, release 10.1, V10.1.243\n","    from /usr/local/cuda-10.1/bin\n","\n","    running install\n","    running build\n","    running build_py\n","    creating build\n","    creating build/lib.linux-x86_64-3.6\n","    creating build/lib.linux-x86_64-3.6/apex\n","    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n","    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n","    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n","    creating build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n","    creating build/lib.linux-x86_64-3.6/apex/contrib\n","    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n","    creating build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n","    creating build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n","    creating build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof\n","    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n","    creating build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n","    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n","    creating build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n","    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n","    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n","    running build_ext\n","    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","      warnings.warn(msg.format('we could not find ninja.'))\n","    building 'apex_C' extension\n","    creating build/temp.linux-x86_64-3.6\n","    creating build/temp.linux-x86_64-3.6/csrc\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from csrc/flatten_unflatten.cpp:2:0:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         return tensors[0].type();\n","                                ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/flatten_unflatten.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'amp_C' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n","    building 'syncbn' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n","    building 'fused_layer_norm_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(dout);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(mean);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(invvar);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(input);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(gamma);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                                              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n","     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n","                                                                     ^~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n","       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n","           ^~~~~~~~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n","     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n","                                    ^~~~~~~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n","     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n","                           ^~~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n","     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n","                            ^~~~~~~~~~\n","    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n","       CHECK_INPUT(beta);\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/layer_norm_cuda.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n","    building 'mlp_cuda' extension\n","    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n","                                                                                 ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n","                                                                        ^\n","    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_fp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n","    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < num_layers; i++) {\n","                       ~~^~~~~~~~~~~~\n","    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","       for (int i = 0; i < inputs.size(); i++) {\n","                       ~~^~~~~~~~~~~~~~~\n","    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n","                                                                       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","                                                          ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","         const auto& the_type = TYPE;                                             \\\n","                                ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n","         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n","                                                            ^\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n","     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n","                           ^~~~~~~~~~~\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp: In lambda function:\n","    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < num_layers; i++) {\n","                         ~~^~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n","         for (int i = 0; i < inputs.size(); i++) {\n","                         ~~^~~~~~~~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                                                                    ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n","       DeprecatedTypeProperties & type() const {\n","                                  ^~~~\n","    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n","                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n","                     from csrc/mlp.cpp:1:\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n","         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n","                                      ~~~~~~~~~~^~~~~~~~~\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n","         auto result = mlp_bp<scalar_t>(\n","              ^\n","    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n","         return __VA_ARGS__();                          \\\n","                ^~~~~~~~~~~\n","    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n","       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n","       ^\n","    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n","\n","    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n","\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n","    running install_lib\n","    creating /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n","    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n","    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n","    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n","    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n","    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n","    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n","    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n","    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n","    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n","    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n","    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n","    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n","    running install_egg_info\n","    running egg_info\n","    creating apex.egg-info\n","    writing apex.egg-info/PKG-INFO\n","    writing dependency_links to apex.egg-info/dependency_links.txt\n","    writing top-level names to apex.egg-info/top_level.txt\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    writing manifest file 'apex.egg-info/SOURCES.txt'\n","    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n","    running install_scripts\n","    writing list of installed files to '/tmp/pip-record-cgwjmc0_/install-record.txt'\n","    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n","  Removing source in /tmp/pip-req-build-2l70cf28\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-3cu87j89'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"665tCOfRpIIx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572588582,"user_tz":-540,"elapsed":559912,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import torch.random\n","import random\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqnYi7N2Kfjy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572608827,"user_tz":-540,"elapsed":20221,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["zip_name = 'split-fold2.zip'\n","zip_path = '/content/drive/My Drive/Colab Notebooks/gwdsplit/' + zip_name\n","!cp \"{zip_path}\" .\n","!unzip -q '{zip_name}'\n","!rm '{zip_name}'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"978lsjD2vQAF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572614950,"user_tz":-540,"elapsed":26318,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["yolov5_name = 'yolov5.zip'\n","yolov5_path = '/content/drive/My Drive/Colab Notebooks/' + yolov5_name\n","!cp '{yolov5_path}' .\n","!unzip -q '{yolov5_name}'\n","!rm '{yolov5_name}'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROkeoZzd_ljI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572618699,"user_tz":-540,"elapsed":30054,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["weight_name = 'yolov5x_coco.pt'\n","weight_path = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + weight_name\n","!cp '{weight_path}' ."],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1l1XG4zejqR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594572618700,"user_tz":-540,"elapsed":30046,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["train_input = '/content/drive/My Drive/Colab Notebooks/yolov5/train.py'\n","data_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/wheat_colab.yaml'\n","cfg_input = '/content/drive/My Drive/Colab Notebooks/yolov5config/yolov5x.yaml'\n","weights_input = '/content/' + weight_name\n","name_input = 'x-b2-e50-fold2'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-Sb84dpxl6U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594572618702,"user_tz":-540,"elapsed":30035,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"6372ff4c-1d9d-426f-8320-57436d611e7b"},"source":["%cd /content/yolov5/"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/yolov5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYOIA2YaeNgC","colab_type":"text"},"source":["# **train.py**"]},{"cell_type":"code","metadata":{"id":"9UCW99OCx4QA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1594572625181,"user_tz":-540,"elapsed":36501,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"5f11ce21-bd73-4d69-b39a-c9298329f4e0"},"source":["import argparse\n","\n","import torch.distributed as dist\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","import torch.utils.data\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import test  # import test.py to get mAP after each epoch\n","from models.yolo import Model\n","from utils import google_utils\n","from utils.datasets import *\n","from utils.utils import *\n","\n","mixed_precision = True\n","try:  # Mixed precision training https://github.com/NVIDIA/apex\n","    from apex import amp\n","except:\n","    print('Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex')\n","    mixed_precision = False  # not installed\n","\n","wdir = 'weights' + os.sep  # weights dir\n","os.makedirs(wdir, exist_ok=True)\n","last = wdir + 'last.pt'\n","best = wdir + 'best.pt'\n","results_file = 'results.txt'\n","\n","# Hyperparameters\n","hyp = {'lr0': 0.01,  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","       'momentum': 0.937,  # SGD momentum\n","       'weight_decay': 5e-4,  # optimizer weight decay\n","       'giou': 0.05,  # giou loss gain\n","       'cls': 0.58,  # cls loss gain\n","       'cls_pw': 1.0,  # cls BCELoss positive_weight\n","       'obj': 1.0,  # obj loss gain (*=img_size/320 if img_size != 320)\n","       'obj_pw': 1.0,  # obj BCELoss positive_weight\n","       'iou_t': 0.20,  # iou training threshold\n","       'anchor_t': 4.0,  # anchor-multiple threshold\n","       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n","       'hsv_h': 0.014,  # image HSV-Hue augmentation (fraction)\n","       'hsv_s': 0.68,  # image HSV-Saturation augmentation (fraction)\n","       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n","       'degrees': 0.0,  # image rotation (+/- deg)\n","       'translate': 0.0,  # image translation (+/- fraction)\n","       'scale': 0.5,  # image scale (+/- gain)\n","       'shear': 0.0}  # image shear (+/- deg)\n","print(hyp)\n","\n","# Overwrite hyp with hyp*.txt (optional)\n","f = glob.glob('hyp*.txt')\n","if f:\n","    print('Using %s' % f[0])\n","    for k, v in zip(hyp.keys(), np.loadtxt(f[0])):\n","        hyp[k] = v\n","\n","# Print focal loss if gamma > 0\n","if hyp['fl_gamma']:\n","    print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])\n","\n","\n","def train(hyp):\n","    epochs = opt.epochs  # 300\n","    batch_size = opt.batch_size  # 64\n","    weights = opt.weights  # initial training weights\n","\n","    # Configure\n","    init_seeds(1)\n","    with open(opt.data) as f:\n","        data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n","    train_path = data_dict['train']\n","    test_path = data_dict['val']\n","    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes\n","\n","    # Remove previous results\n","    for f in glob.glob('*_batch*.jpg') + glob.glob(results_file):\n","        os.remove(f)\n","\n","    # Create model\n","    model = Model(opt.cfg, nc=data_dict['nc']).to(device)\n","\n","    # Image sizes\n","    gs = int(max(model.stride))  # grid size (max stride)\n","    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n","\n","    # Optimizer\n","    nbs = 64  # nominal batch size\n","    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n","    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n","    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n","    for k, v in model.named_parameters():\n","        if v.requires_grad:\n","            if '.bias' in k:\n","                pg2.append(v)  # biases\n","            elif '.weight' in k and '.bn' not in k:\n","                pg1.append(v)  # apply weight decay\n","            else:\n","                pg0.append(v)  # all else\n","\n","    optimizer = optim.Adam(pg0, lr=hyp['lr0']) if opt.adam else \\\n","        optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n","    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n","    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n","    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n","    lf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.9 + 0.1  # cosine\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n","    print('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n","    del pg0, pg1, pg2\n","\n","    # Load Model\n","    google_utils.attempt_download(weights)\n","    start_epoch, best_fitness = 0, 0.0\n","    if weights.endswith('.pt'):  # pytorch format\n","        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n","\n","        # load model\n","        try:\n","            ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n","                             if model.state_dict()[k].shape == v.shape}  # to FP32, filter\n","            model.load_state_dict(ckpt['model'], strict=False)\n","        except KeyError as e:\n","            s = \"%s is not compatible with %s. This may be due to model differences or %s may be out of date. \" \\\n","                \"Please delete or update %s and try again, or use --weights '' to train from scratch.\" \\\n","                % (opt.weights, opt.cfg, opt.weights, opt.weights)\n","            raise KeyError(s) from e\n","\n","        # load optimizer\n","        if ckpt['optimizer'] is not None:\n","            optimizer.load_state_dict(ckpt['optimizer'])\n","            best_fitness = ckpt['best_fitness']\n","\n","        # load results\n","        if ckpt.get('training_results') is not None:\n","            with open(results_file, 'w') as file:\n","                file.write(ckpt['training_results'])  # write results.txt\n","\n","        # epochs\n","        start_epoch = ckpt['epoch'] + 1\n","        if epochs < start_epoch:\n","            print('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n","                  (opt.weights, ckpt['epoch'], epochs))\n","            epochs += ckpt['epoch']  # finetune additional epochs\n","\n","        del ckpt\n","\n","    # Mixed precision training https://github.com/NVIDIA/apex\n","    if mixed_precision:\n","        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n","\n","\n","    scheduler.last_epoch = start_epoch - 1  # do not move\n","    # https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822\n","    # plot_lr_scheduler(optimizer, scheduler, epochs)\n","\n","    # Initialize distributed training\n","    if device.type != 'cpu' and torch.cuda.device_count() > 1 and torch.distributed.is_available():\n","        dist.init_process_group(backend='nccl',  # distributed backend\n","                                init_method='tcp://127.0.0.1:9999',  # init method\n","                                world_size=1,  # number of nodes\n","                                rank=0)  # node rank\n","        model = torch.nn.parallel.DistributedDataParallel(model)\n","        # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","    # Trainloader\n","    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n","                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect)\n","    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n","    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Correct your labels or your model.' % (mlc, nc, opt.cfg)\n","\n","    # Testloader\n","    testloader = create_dataloader(test_path, imgsz_test, batch_size, gs, opt,\n","                                   hyp=hyp, augment=False, cache=opt.cache_images, rect=True)[0]\n","\n","    # Model parameters\n","    hyp['cls'] *= nc / 80.  # scale coco-tuned hyp['cls'] to current dataset\n","    model.nc = nc  # attach number of classes to model\n","    model.hyp = hyp  # attach hyperparameters to model\n","    model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n","    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights\n","    model.names = data_dict['names']\n","\n","    # Class frequency\n","    labels = np.concatenate(dataset.labels, 0)\n","    c = torch.tensor(labels[:, 0])  # classes\n","    # cf = torch.bincount(c.long(), minlength=nc) + 1.\n","    # model._initialize_biases(cf.to(device))\n","    if tb_writer:\n","        plot_labels(labels)\n","        tb_writer.add_histogram('classes', c, 0)\n","\n","    # Check anchors\n","    if not opt.noautoanchor:\n","        check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n","\n","    # Exponential moving average\n","    ema = torch_utils.ModelEMA(model)\n","\n","    # Start training\n","    t0 = time.time()\n","    nb = len(dataloader)  # number of batches\n","    n_burn = max(3 * nb, 1e3)  # burn-in iterations, max(3 epochs, 1k iterations)\n","    maps = np.zeros(nc)  # mAP per class\n","    results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n","    print('Image sizes %g train, %g test' % (imgsz, imgsz_test))\n","    print('Using %g dataloader workers' % dataloader.num_workers)\n","    print('Starting training for %g epochs...' % epochs)\n","    # torch.autograd.set_detect_anomaly(True)\n","    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n","        model.train()\n","\n","        # Update image weights (optional)\n","        if dataset.image_weights:\n","            w = model.class_weights.cpu().numpy() * (1 - maps) ** 2  # class weights\n","            image_weights = labels_to_image_weights(dataset.labels, nc=nc, class_weights=w)\n","            dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # rand weighted idx\n","\n","        # Update mosaic border\n","        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n","        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n","\n","        mloss = torch.zeros(4, device=device)  # mean losses\n","        print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n","        pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n","        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n","            ni = i + nb * epoch  # number integrated batches (since train start)\n","            imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n","\n","            # Burn-in\n","            if ni <= n_burn:\n","                xi = [0, n_burn]  # x interp\n","                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # giou loss ratio (obj_loss = 1.0 or giou)\n","                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n","                for j, x in enumerate(optimizer.param_groups):\n","                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n","                    x['lr'] = np.interp(ni, xi, [0.1 if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n","                    if 'momentum' in x:\n","                        x['momentum'] = np.interp(ni, xi, [0.9, hyp['momentum']])\n","\n","            # Multi-scale\n","            if opt.multi_scale:\n","                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n","                sf = sz / max(imgs.shape[2:])  # scale factor\n","                if sf != 1:\n","                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n","                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n","\n","            # Forward\n","            pred = model(imgs)\n","\n","            # Loss\n","            loss, loss_items = compute_loss(pred, targets.to(device), model)\n","            if not torch.isfinite(loss):\n","                print('WARNING: non-finite loss, ending training ', loss_items)\n","                return results\n","\n","            # Backward\n","            if mixed_precision:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            # Optimize\n","            if ni % accumulate == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                ema.update(model)\n","\n","            # Print\n","            mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n","            mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n","            s = ('%10s' * 2 + '%10.4g' * 6) % (\n","                '%g/%g' % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n","            pbar.set_description(s)\n","\n","            # Plot\n","            if ni < 3:\n","                f = 'train_batch%g.jpg' % ni  # filename\n","                result = plot_images(images=imgs, targets=targets, paths=paths, fname=f)\n","                if tb_writer and result is not None:\n","                    tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)\n","                    # tb_writer.add_graph(model, imgs)  # add model to tensorboard\n","\n","            # end batch ------------------------------------------------------------------------------------------------\n","\n","        # Scheduler\n","        scheduler.step()\n","\n","        # mAP\n","        ema.update_attr(model)\n","        final_epoch = epoch + 1 == epochs\n","        if not opt.notest or final_epoch:  # Calculate mAP\n","            results, maps, times = test.test(opt.data,\n","                                             batch_size=batch_size,\n","                                             imgsz=imgsz_test,\n","                                             save_json=final_epoch and opt.data.endswith(os.sep + 'coco.yaml'),\n","                                             model=ema.ema,\n","                                             single_cls=opt.single_cls,\n","                                             dataloader=testloader)\n","\n","        # Write\n","        with open(results_file, 'a') as f:\n","            f.write(s + '%10.4g' * 7 % results + '\\n')  # P, R, mAP, F1, test_losses=(GIoU, obj, cls)\n","        if len(opt.name) and opt.bucket:\n","            os.system('gsutil cp results.txt gs://%s/results/results%s.txt' % (opt.bucket, opt.name))\n","\n","        # Tensorboard\n","        if tb_writer:\n","            tags = ['train/giou_loss', 'train/obj_loss', 'train/cls_loss',\n","                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/F1',\n","                    'val/giou_loss', 'val/obj_loss', 'val/cls_loss']\n","            for x, tag in zip(list(mloss[:-1]) + list(results), tags):\n","                tb_writer.add_scalar(tag, x, epoch)\n","\n","        # Update best mAP\n","        fi = fitness(np.array(results).reshape(1, -1))  # fitness_i = weighted combination of [P, R, mAP, F1]\n","        if fi > best_fitness:\n","            best_fitness = fi\n","\n","        # Save model\n","        save = (not opt.nosave) or (final_epoch and not opt.evolve)\n","        if save:\n","            with open(results_file, 'r') as f:  # create checkpoint\n","                ckpt = {'epoch': epoch,\n","                        'best_fitness': best_fitness,\n","                        'training_results': f.read(),\n","                        'model': ema.ema,\n","                        'optimizer': None if final_epoch else optimizer.state_dict()}\n","\n","            # Save last, best and delete\n","            torch.save(ckpt, last)\n","            if (best_fitness == fi) and not final_epoch:\n","                torch.save(ckpt, best)\n","            del ckpt\n","\n","        # end epoch ----------------------------------------------------------------------------------------------------\n","    # end training\n","\n","    # Strip optimizers\n","    n = ('_' if len(opt.name) and not opt.name.isnumeric() else '') + opt.name\n","    fresults, flast, fbest = 'results%s.txt' % n, wdir + 'last%s.pt' % n, wdir + 'best%s.pt' % n\n","    for f1, f2 in zip([wdir + 'last.pt', wdir + 'best.pt', 'results.txt'], [flast, fbest, fresults]):\n","        if os.path.exists(f1):\n","            os.rename(f1, f2)  # rename\n","            ispt = f2.endswith('.pt')  # is *.pt\n","            strip_optimizer(f2) if ispt else None  # strip optimizer\n","            os.system('gsutil cp %s gs://%s/weights' % (f2, opt.bucket)) if opt.bucket and ispt else None  # upload\n","\n","    # Finish\n","    if not opt.evolve:\n","        plot_results()  # save as results.png\n","    print('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n","    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None\n","    torch.cuda.empty_cache()\n","    return results"],"execution_count":12,"outputs":[{"output_type":"stream","text":["{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9csFml3nfP7H","colab_type":"text"},"source":["# **Train Option**"]},{"cell_type":"code","metadata":{"id":"h0uu9IpAyJC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594619504771,"user_tz":-540,"elapsed":46916075,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}},"outputId":"42a1c00d-eb89-4501-bc90-1260d6f72060"},"source":["check_git_status()\n","class opt:\n","    epochs=50                #parser.add_argument('--epochs', type=int, default=300)\n","    batch_size=2            #parser.add_argument('--batch-size', type=int, default=16)\n","    cfg=cfg_input           #parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='*.cfg path')\n","    data=data_input         #parser.add_argument('--data', type=str, default='data/coco128.yaml', help='*.data path')\n","    img_size=[1024, 1024]   #parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='train,test sizes')\n","    rect=False              #parser.add_argument('--rect', action='store_true', help='rectangular training')\n","    resume=False            #parser.add_argument('--resume', action='store_true', help='resume training from last.pt')\n","    nosave=False            #parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n","    notest=False            #parser.add_argument('--notest', action='store_true', help='only test final epoch')\n","    noautoanchor=False      #parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n","    evolve=False            #parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n","    bucket=''               #parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n","    cache_images=False      #parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n","    weights=weights_input   #parser.add_argument('--weights', type=str, default='', help='initial weights path')\n","    name=name_input         #parser.add_argument('--name', default='', help='renames results.txt to results_name.txt if supplied')\n","    device=''               #parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n","    adam=False              #parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n","    multi_scale=False       #parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%')\n","    single_cls=False        #parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n","\n","#parser = argparse.ArgumentParser()\n","#opt = parser.parse_args()\n","\n","opt.weights = last if opt.resume and not opt.weights else opt.weights\n","opt.cfg = check_file(opt.cfg)  # check file\n","opt.data = check_file(opt.data)  # check file\n","print(opt)\n","opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n","device = torch_utils.select_device(opt.device, apex=mixed_precision, batch_size=opt.batch_size)\n","if device.type == 'cpu':\n","    mixed_precision = False\n","\n","# Train\n","if not opt.evolve:\n","    tb_writer = SummaryWriter(comment=opt.name)\n","    print('Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/')\n","    train(hyp)\n","\n","# Evolve hyperparameters (optional)\n","else:\n","    tb_writer = None\n","    opt.notest, opt.nosave = True, True  # only test/save final epoch\n","    if opt.bucket:\n","        os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n","\n","    for _ in range(10):  # generations to evolve\n","        if os.path.exists('evolve.txt'):  # if evolve.txt exists: select best hyps and mutate\n","            # Select parent(s)\n","            parent = 'single'  # parent selection method: 'single' or 'weighted'\n","            x = np.loadtxt('evolve.txt', ndmin=2)\n","            n = min(5, len(x))  # number of previous results to consider\n","            x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n","            w = fitness(x) - fitness(x).min()  # weights\n","            if parent == 'single' or len(x) == 1:\n","                # x = x[random.randint(0, n - 1)]  # random selection\n","                x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n","            elif parent == 'weighted':\n","                x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n","\n","            # Mutate\n","            mp, s = 0.9, 0.2  # mutation probability, sigma\n","            npr = np.random\n","            npr.seed(int(time.time()))\n","            g = np.array([1, 1, 1, 1, 1, 1, 1, 0, .1, 1, 0, 1, 1, 1, 1, 1, 1, 1])  # gains\n","            ng = len(g)\n","            v = np.ones(ng)\n","            while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n","                v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n","            for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n","                hyp[k] = x[i + 7] * v[i]  # mutate\n","\n","        # Clip to limits\n","        keys = ['lr0', 'iou_t', 'momentum', 'weight_decay', 'hsv_s', 'hsv_v', 'translate', 'scale', 'fl_gamma']\n","        limits = [(1e-5, 1e-2), (0.00, 0.70), (0.60, 0.98), (0, 0.001), (0, .9), (0, .9), (0, .9), (0, .9), (0, 3)]\n","        for k, v in zip(keys, limits):\n","            hyp[k] = np.clip(hyp[k], v[0], v[1])\n","\n","        # Train mutation\n","        results = train(hyp.copy())\n","\n","        # Write mutation results\n","        print_mutation(hyp, results, opt.bucket)\n","\n","        # Plot results\n","        # plot_evolution_results(hyp)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["<class '__main__.opt'>\n","Using CUDA Apex device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n","\n","Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n","  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  2                -1  1    315680  models.common.BottleneckCSP             [160, 160, 4]                 \n","  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n","  4                -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n","  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n","  6                -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n","  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n","  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n","  9                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1   5435520  models.common.BottleneckCSP             [1280, 640, 4, False]         \n"," 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1   1360960  models.common.BottleneckCSP             [640, 320, 4, False]          \n"," 18                -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n"," 19                -2  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 21                -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n"," 22                -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n"," 23                -2  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 25                -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n"," 26                -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n"," 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [1, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n","Model Summary: 407 layers, 8.84337e+07 parameters, 8.84337e+07 gradients\n","\n","Optimizer groups: 134 .bias, 142 conv.weight, 131 other\n"],"name":"stdout"},{"output_type":"stream","text":["Reading image shapes: 100%|██████████| 2699/2699 [00:00<00:00, 8784.74it/s]\n","Caching labels /content/labels/train (2699 found, 0 missing, 0 empty, 0 duplicate, for 2699 images): 100%|██████████| 2699/2699 [00:00<00:00, 3242.87it/s]\n","Reading image shapes: 100%|██████████| 674/674 [00:00<00:00, 8822.34it/s]\n","  0%|          | 0/674 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving labels to /content/labels/train.npy for faster future loading\n"],"name":"stdout"},{"output_type":"stream","text":["Caching labels /content/labels/valid (674 found, 0 missing, 0 empty, 0 duplicate, for 674 images): 100%|██████████| 674/674 [00:00<00:00, 3227.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Analyzing anchors... Best Possible Recall (BPR) = 0.9992\n","Image sizes 1024 train, 1024 test\n","Using 2 dataloader workers\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      0/49      4.8G   0.07331    0.1853         0    0.2587        36      1024: 100%|██████████| 1350/1350 [13:41<00:00,  1.64it/s]\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [03:20<00:00,  1.68it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.23       0.949       0.659       0.231\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      1/49     5.28G   0.05586    0.1552         0    0.2111        49      1024: 100%|██████████| 1350/1350 [13:00<00:00,  1.73it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:43<00:00,  2.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.612       0.924       0.904       0.387\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      2/49     5.28G   0.05397    0.1549         0    0.2089       157      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:50<00:00,  1.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.619       0.913       0.874       0.367\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      3/49     5.28G    0.0468     0.151         0    0.1978        99      1024: 100%|██████████| 1350/1350 [12:49<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.63       0.948       0.933       0.484\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      4/49     5.28G   0.04211     0.145         0    0.1871        52      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:40<00:00,  2.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.631       0.944       0.931       0.468\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      5/49     5.28G   0.04006    0.1437         0    0.1837        50      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.691        0.95       0.942       0.506\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      6/49     5.28G   0.03947    0.1454         0    0.1848       105      1024: 100%|██████████| 1350/1350 [12:52<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:33<00:00,  2.20it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.719       0.947       0.943       0.511\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      7/49     5.28G   0.03872    0.1413         0      0.18       148      1024: 100%|██████████| 1350/1350 [12:50<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.732       0.943       0.939       0.515\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      8/49     5.28G   0.03762    0.1407         0    0.1784        21      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.755       0.945       0.943        0.52\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["      9/49     5.28G   0.03757    0.1391         0    0.1767        64      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.717       0.947       0.943       0.519\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     10/49     5.28G   0.03683    0.1391         0     0.176        15      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.743       0.948       0.944       0.529\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     11/49     5.28G   0.03645    0.1382         0    0.1746       196      1024: 100%|██████████| 1350/1350 [12:52<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:39<00:00,  2.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.735       0.946       0.943       0.514\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     12/49     5.28G   0.03605    0.1381         0    0.1741       119      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.771       0.941       0.942       0.523\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     13/49     5.28G   0.03618     0.139         0    0.1752        24      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.734       0.948       0.944       0.526\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     14/49     5.28G   0.03554    0.1367         0    0.1722        47      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.748       0.946       0.945       0.528\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     15/49     5.28G    0.0351     0.136         0    0.1711        47      1024: 100%|██████████| 1350/1350 [12:52<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.754       0.947       0.945       0.532\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     16/49     5.28G   0.03481    0.1345         0    0.1693        42      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.748       0.949       0.946       0.534\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     17/49     5.28G   0.03504    0.1359         0     0.171        61      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.739       0.948       0.945       0.526\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     18/49     5.28G   0.03478    0.1319         0    0.1666        30      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.744       0.946       0.943       0.532\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     19/49     5.28G    0.0345     0.134         0    0.1685        24      1024: 100%|██████████| 1350/1350 [12:52<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.75       0.947       0.945       0.534\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     20/49     5.28G   0.03416    0.1341         0    0.1683        97      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.757       0.944       0.943       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     21/49     5.28G   0.03406    0.1336         0    0.1677        95      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.767       0.945       0.944       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     22/49     5.28G   0.03401     0.133         0     0.167        23      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.762       0.946       0.945       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     23/49     5.28G    0.0336     0.132         0    0.1656        46      1024: 100%|██████████| 1350/1350 [12:49<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:33<00:00,  2.20it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.759       0.946       0.946       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     24/49     5.28G   0.03353    0.1328         0    0.1663        49      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:38<00:00,  2.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.772       0.944       0.945       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     25/49     5.28G   0.03337    0.1327         0    0.1661        48      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.769       0.945       0.945       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     26/49     5.28G   0.03326    0.1316         0    0.1649        57      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.755       0.947       0.944       0.532\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     27/49     5.28G    0.0331    0.1302         0    0.1633       148      1024: 100%|██████████| 1350/1350 [12:51<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.768       0.946       0.945       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     28/49     5.28G    0.0332    0.1309         0    0.1641        70      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.764       0.945       0.945       0.535\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     29/49     5.28G   0.03282    0.1297         0    0.1625        71      1024: 100%|██████████| 1350/1350 [12:56<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.771       0.944       0.944       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     30/49     5.28G   0.03273     0.129         0    0.1617       141      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.771       0.945       0.944       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     31/49     5.28G    0.0327    0.1286         0    0.1613        59      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.77       0.945       0.944       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     32/49     5.28G   0.03265    0.1285         0    0.1611        25      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.783       0.941       0.943       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     33/49     5.28G   0.03254    0.1285         0     0.161        60      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:37<00:00,  2.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.781       0.944       0.944       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     34/49     5.28G   0.03242    0.1274         0    0.1598        47      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:39<00:00,  2.12it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.779       0.944       0.944       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     35/49     5.28G   0.03224    0.1279         0    0.1602       158      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.778       0.943       0.944       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     36/49     5.28G   0.03213    0.1275         0    0.1597        54      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.19it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.787       0.941       0.943       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     37/49     5.28G   0.03204    0.1273         0    0.1593        27      1024: 100%|██████████| 1350/1350 [12:56<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.779       0.942       0.943       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     38/49     5.28G   0.03192    0.1262         0    0.1582        81      1024: 100%|██████████| 1350/1350 [12:56<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.783       0.943       0.944       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     39/49     5.28G   0.03184    0.1268         0    0.1587        58      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:33<00:00,  2.20it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.78       0.942       0.943       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     40/49     5.28G   0.03184    0.1256         0    0.1575        85      1024: 100%|██████████| 1350/1350 [12:52<00:00,  1.75it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.785       0.941       0.943       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     41/49     5.28G   0.03175    0.1243         0    0.1561       132      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.78       0.942       0.944       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     42/49     5.28G   0.03162    0.1249         0    0.1566        98      1024: 100%|██████████| 1350/1350 [12:56<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.789       0.942       0.945       0.539\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     43/49     5.28G   0.03169    0.1249         0    0.1566        47      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.781       0.942       0.943       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     44/49     5.28G   0.03163     0.124         0    0.1556        55      1024: 100%|██████████| 1350/1350 [12:53<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.782       0.942       0.943       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     45/49     5.28G    0.0315     0.125         0    0.1565        33      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.791        0.94       0.943       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     46/49     5.28G    0.0315    0.1245         0     0.156        57      1024: 100%|██████████| 1350/1350 [12:55<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.784       0.941       0.943       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     47/49     5.28G   0.03144    0.1253         0    0.1567        26      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:34<00:00,  2.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04        0.79        0.94       0.943       0.537\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     48/49     5.28G   0.03158    0.1254         0     0.157        62      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:36<00:00,  2.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.786       0.942       0.943       0.538\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"],"name":"stdout"},{"output_type":"stream","text":["     49/49     5.28G   0.03145    0.1251         0    0.1566        18      1024: 100%|██████████| 1350/1350 [12:54<00:00,  1.74it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 337/337 [02:35<00:00,  2.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["                 all         674    2.96e+04       0.788       0.939       0.942       0.536\n","Optimizer stripped from weights/last_x-b2-e50-fold2.pt\n","Optimizer stripped from weights/best_x-b2-e50-fold2.pt\n","50 epochs completed in 13.011 hours.\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1YAAAGmCAYAAAB/URVbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXxU5fX/32cmC4SwhiAghhA2FxCUxWqtCIqift1q3aqIgiKtXbF+v1b7da/airRaaQWLSkWxat2+P7WWqmjd2BQQFdkJq1kggSSQbc7vj3vvZGYyEyYLWYbzfr3ymjv3PvfeJ5Mnd57znHM+R1QVwzAMwzAMwzAMo+H4WroDhmEYhmEYhmEYbR0zrAzDMAzDMAzDMBqJGVaGYRiGYRiGYRiNxAwrwzAMwzAMwzCMRmKGlWEYhmEYhmEYRiMxw8owDMMwDMMwDKORmGFlGAmOiJwuInXWVRCRt0Tktubqk3F4IiJ3iciiZrjPlyJyVcj7ESKyQkT2icjTInKViHzZnH0wjPoiIlkiUiIiWXG0vU1E3mqOfhlGUxH5nSAii0TkrpbrUeMxw6qZEZFhIvJ3EdklIqUikisib4rIxe7xek08Yg1Cd/LwdJN13Gi1uJPG10Vkt4iUicjX7pdscrzXUNVzVPX+JurPtSKyuSmuZbQ9ROR4EXnBfcaViMhGEfmbiAxprj6o6nGq+mzIrgeARaraUVWvVdVnVfW4priXiGSLiIpI9kH6YCQA7nduhTu294rIahGZcijupaq5qpquqrlxtL1fVc85FP0wEpsoY/pLEbmhpfvVVjHDqhkRkTOAT4HtwHeAjsBg4E/A91uwa0YbRUTGAR8CXwHHAl2AG4FrgVdFxP7HjWZDRE4HFuM8407CecaNBD4CLmy5npEDrGjB+xuJxf2qmg50BR4E/uqO/TDqs7hlGC2MN6a7AHcDs0XktBbuU5vEJl3Ny+PAAlWdrqqbVTWgqvtV9S1VnRjtBBHpJiJPisgOEckTkX+ISJ9m7rfRevkL8A9VvVVVd6lqhap+gDOJPQu4zGsoIj8UkU0iUiQiL4tIZsixMM+niBwpIs+JyHZ33C2IaJ8mIg+IyHo3vGqdiFwiIt/DGedeCEuJiFwUsqp/tYiscs/5WESODrmmX0Rudj1uxSKy3F2M8I4PE5H33f7vcY8Pdo+NFZFl7nmFIvKRiHQ9JJ+4URezgRdU9ZequkUddqvqbFX9bWRjEbnJXR3d5461WSKSFnL8Mvf4XhEpEJF/hxz7iYhscM/9NtRDLyKbXc+pX0RKcAyrx93xeEmkV1VEkkTkFnfs7RORLSJyk3usl4i84f4f7BWRpe6ChocXUvile/2HQ/sQco9T3TFf5P7f3Coi/pDjKiI/dtuUuP8npzT0D2EcelS1WlXnA4XACPdv+HMRWSwiZcDZItJORO53x+oeEflARE4IvY6IXCciK93n104Ruc/dH+YNPcgzMDKkqs65gzhRLc+KyGPuM3OXtPEQLKPxuPPSF4DdwGgAETlJnDlCoftsvFdEkrxzxAlZXeA+w4vd72JvXF4qIp+5+791x1z3lvntmgczrJoJERkEDACeq+ep84EjgeOB/kAZ8HroF7JxeOKOqUHA05HHVPVrYAnwXyG7LwdOBPoB7YC/xbhuKvAOsNW9fg5QRfjYnQuMBc5V1Y7AOGCdqv4HmAZ4ISzpqvpqyHkTgfFAJrALmBVy7H+Bq3CMwq7AfcBrItLfPf5nt1/d3fOnAEXusfnutboAvYBfARXRfj/j0CAiA3HGyzP1OG0nzt+7E3AGzmLA7e710nD+rj9V1U5AH+D+kHv9HrjQHX/9gScjL+5OfNOBXGCaOx7/EaUf9wI3AFe7fRkJLHWP+YG/4vzfdAdeA14JmRx4IYXHude/OfLiItIX+BfO/1wmToTCj4GfRzS9Hud/pAvwPvX7LI1mxjXIJwLdqBkvNwKTgA44z6vHgRHAaTh/+78Db4tIF/caN+J4vX7pXudo4J8xblnXMzCSeOYOl+CMsx7u9u3iLI4ZhynumP4hkAF84xpI/8b5fj0CZxyfD/yP2z4NeBcoxRlrXXHG5T73kvtw/h+64fwf5ACPNNfv0xKYYdV8eKv9270d7gpmkWvJH3C/fAk53gs4B/ilqhao6j7gJ8AwYFRzddxotdQaUxFsw/nC9LhVVfeo6h7gZmCCO8YiOQ9Ic9uXqmoJjqFypoj0EcdzdQXORHUtgKpuVdVVcfT5blX9VlUP4EyER4cc+yVwi6qudVfNXgH+A1zpHq8AsoC+qlqlqitU9duQY/2B3q7X7hNVLY2jP0bT4Y21WOOxFqr6sqqudz1ba3AmjmeGNKkEjhGR7qp6QFXfdfdXAQIcJyKdVLXE9dTWGxERnOfqf6vqcrcv+aq6xO3jNlV9xf1fqFDV+wClfs/gHwKrVfVxVa10/1d+D0yNaDdDVTeoahWO9y9HRDIa8nsZh5RbRaQIZ3HoF8C1IePvYVVdo6qK8xydBPxYVbe7z61ZOB4ub9HrZ8ADqvquuxBQrKofxrhvXc/AIPWYO3ygqi+69/0IWEn4M9k4fPDG9AGcBZ3bVPX/gJuAV91xUqWqW3ByVq9zzzsPZzHqR6pa6H53r1TVHQCq+k9V/cIdY9twnntnRt48kTDDqvnId1+P9Hao6oeq2gXnYZeKM1EI5Sj3dWPIOcXutTyVoEogWhx3snvMSFxqjakI+gB5Ie83Rdk+itoMBHoDe1zDvwj4BijHGXfZbrtvGtDnHSHbJUA6gIgcgfNwfsW7p3vf06j5/a7FmdC+KyJbReQPItLBPXYBzkrYcnHCEu80r26z4421WOOxFiLyAxH5VJwwv2Lgt7gGmqqWARNwvoS/cUPjfuIe24Rj3F8H5LqhV5dFv8tB6Y4zDqOO55CQqs3ihAIW4YzVHtHax+AoQp7jLuupeY57RP5/gJOnZrQuHlTVLqraXVVHqGqo9z/0OTvAfV0e8Vzri/N8Bud5Gu+z9FpiPwNDiWfuAOHjDZwxZ+Pt8ORBdz7aFXgKZyE1CWc+cGnE+H0C6Omelw1sUtWo801xwvQXuWGAe3GMtvo8O9scZlg1E+7K/gaclct42eq+9vN2iEgnnImApxK0CWfgRzLQvZ+RoLhjaj1wTeQx130/GngjZHd2lO1tUS69C9joThxCf9qp6sfAZrfdoBhdC8T9S9TgrZRNiLhnB1X9EYA6OTs3qGpfnDDEs4D/do99oao/VNWewKU4YVa1Phfj0KGq64C1OOGcB8XN9/g7MAM4UlU744QBBheYVPU/qnoxzjPvZ8AMERnrHntNVSe4xx4GFoSEjdaHApwJZazx/CDOM/i7QGecicfekH7GM963EvIcd+lPzXPcSBxCx8Mu9/XYiOdamqo+6B7bTOyxF0Zdz8AI4pk7GEYtXO/mTThj5yacMfy3iPHbSZ0Qa3DGbz+JItQiIinA/wGvAjnqhHRH1RNIJMywal5+DPxQRB4Wkb4i4nPzWU6N1lhVd+LEWs8Uke4iko6jIPglNfHc84ALxUnIThGR9uIkXR+HM2kxEpsfA5eJkxx9hIgki8ipOHkg7wAvhLR9QES6iiPq8BDwL89dH8HLQDtxkqE7A4hIDxG5HEBV84EFwJ/dXBfcEMHj3fN3AZlSD/EIVS3HyUV4SESOEYf2InKam0vmybj3cUO39uKEg1W74/46qRHXKAaq3R+jebkRuFxEHhInoVlEpIuITJHaddI64nwHFahquTt+bvIOikhPcRKfu7hhVUU4q/XVIjJYRM4VkXQ3bK4Yx9Cp99/cvfafgN+JyAlunzNFxAuZ6gzsB/bg5Cbeh+tpdcnHmUwPruM2C4ChIjLV/R8dgjMh/mt9+2u0HdywqVdxnpV9AUSko4icIzVh2I8AvxaRMeKIrXR2n+G1iPUMjHLfeOYOhhEV9/v4HuA3ODncl4XMMf0iMkBEJrjN/x/OWHzM9e77xCm50RtIwXlmFqlqqYjkALc2/2/UvJhh1Yyo6r+AU3Bc8UtwkvrW4azwXgRsiXLa1cC3wBc43qmOwPmqWu1e8yPgB8AtOBPaXJzE6DPdcBkjgVHVhcD3gKHAGpwH3FycxOULvHHi8iLwGc4KUxUxVo7cFauTcVasvnDd9x/jhOV53IAjof22OKpr71ET9vIujqdsvRs6cEGcv86vcAzBF3Em0ZuBX1MT6joW5/+mBCcX4BMcAxGc/4EvRaQUJxn7afczMJoRVV2EM3b6AstwnnGf44zRVyPafo3zxf13d4zNIFxQRXCEUDa6Y+wlnLj/D3C+sG8HtrvnPgxMVNXNDez6HThj5nm3z8twBCzAEVXpjGNAfYPzPA56elV1P3AbMM8d77+PvLjbrwk4oYsFOAsfc4A/NLC/RtvhhzhS/wtFZB/OGLoB1+OpqnNw/g8ew3nurQHOjnGtup6BkdQ5dzCMg/AMjjLgmTjj8Uac/NlCnGdxXwg+/87A8eR/hbMA9SSQrk5+9o3APe4z/Fn3J6ERZ7HOMIzDGRH5D/CWNlGRYMMwDMMwjMMN81gZxmGOG3s/AMd7ahiGYRiGYTQAM6wM4zBGRE7GSXT+gIhQLcMwDMMwDCN+LBTQMAzDMAzDMAyjkZjHyjAMwzAMwzAMo5GYYWUYhmEYhmEYhtFIklq6Aw2he/fump2d3dLdMA4By5cvL1DVzIO3bBvYWE1cbKwabQUbq0Zbwcaq0Raoa5y2ScMqOzubZcuWtXQ3jEOAiESr5dVmsbGauNhYNdoKLTFW3cLe84AMnNo316jquog2PYCngKNw6tW9B/zMLfocExuriYs9V422QF3j1EIBDcMwDMNoah4HZqnqIGAWMDtKm9uAr1X1eOB4YAROgXvDMIw2iRlWhmEYhmE0Ga4n6kRggbtrAXCiiESGzijQUUR8QCqQAmxvto4ahmE0MWZYGYZhGIbRlBwFbFfVagD3dYe7P5R7gUHATmAX8LaqftScHTUMw2hK2mSOVSS5hWVMmbeUjfml5GR2YO6kUWRlpLV0twyjFt5YLdhbxi3fy2RozzSSfNLS3TIawMKFC4euXLlyc0v3oxEEgNVVVVXXjxgxIq+lO2McllwKrALOADoCb4nID1T1pciGIjIVmAqQlZXVrJ004iPaXAyw+VkDsHlt2yUhDKuJcxezZXcZABvyS5gybykLp49p4V4ZRm2ueOITdhQd4PbTMhjcpwcpnbowuFenlu6W0QCqq6urhgwZUtDS/WgogUBA8vPzj921a9dfgQtauj9GQrEVOFJE/KpaLSJ+oLe7P5SfApNVNQAUi8hrwFiglmGlqnOAOQAjR47UQ9r7w4iGTOBzC8u45snFbN29P+ycKfOWsj6vBAXW5zlzsYAqG/NLUWBdXgmnPfQeyX6hOqD0z0xvNoMhTjGVnji5gP1wxFR+q6rz3WN3AT/G8bwCfKSqNx2q/oZ9ljavbVMkhGG1dU9ZcDugsDG/tAV7Yxix2VV8AIC+XZJJSutIRbXND4yWwefzaWZmZvGuXbuGtHRfjMRCVfNEZAVwJTDfff1cVfMjmm4CJgBLRCQFOBN4uVk7m8DEYzRFLkxf8+Rikv2+4Dn3XjiE21/9gk0FpeRkpvPkpFH84PGPydtXDoRP+jfkO4YAEDSkolHpfu81s8HgianMF5GrcQyocRFtZgLLVPVCNx9wuYi8r6regsDfVPVXzdFZzxgFUJvXtikSwrDK6pbG5kLnweATyMns0MI9Mozo9Orcnu1F+xEEnwipSZbmaLQcPp9PsVxb49AwDZgnIncAe4BrAETkTeAOVV0G/AJ4XES+APw4cutPtFB/E47rnl7CBndCHs1bdN9FQ4JGFTgL095cyjvniic+Db5fn1fC6TPeIxCyHqjqtMv59Rth++OhuQyGEDGV8e6uBcBjIpIZYewPA/7g9E3z3cWBy4CHD3knI8jJ7BA0TAWb17YlEuIL9ZErhge3PdeyYbRGbjvvmOB2apKfvt0tZtowjMRDVdeo6kmqOsh9/cbdf65rVKGqG1R1vKoOVdVjVfWmg9WwMuInmtFSWa0EXGPo8jmfRjmrbmIZT/U1qqBZF8LjFVNZDlwhDv2AU4C+IcevEJFVIvIvETk51s1EZKqILBORZfn5kU7a+Jg7aRR+N/86LdVv89o2REJ4rAb06AhA+2S/xaAarZq+3RxDKsUvDOrZsYV7YxiGYbQ26pP35LXdkFeCP8QbdfNZg4nX1kn2SzA8rynwi5CT2YEN+SUE1DGgsrqlkez31epnKzMYbsbxWK0AcoF3AM/Qfxwn56pSRMYDr4nIMapaGHmRpsgHPKpbe3wC1UCfLmkmXNGGSAiPVbtkPwAHqqpRtZwVo/XSLtn5lzucRunmzZvp3r178P1dd91FRUXFIb9vdnY2q1evrrU/EAhwySWXMHjwYIYNG8b48ePZsGFDg+4hIiMGDRp07NFHH33s0UcffeySJUvae8eee+65zv369TsuKytryHnnnZezb9++mM/bn/3sZ7379et33IgRIwbXdb/p06f3njp1ap9oxx599NGMCRMm5ADMnz+/y3HHHXfMwIEDjxswYMBxd9555xEN+gUNwwiSW1jGKQ++Q86v32D8zPfJDQmba+j1xs98n/6/fjPsep5wQbVqMITPOx55zjVPLmZ9XgkBwr1R0+YvBxyj5mAEAjCwRzpykLbJfgm28YnzPvL6nhdq7qRR9M9Mxy9C/8x0/jb5JBZOH8PGB89j3W/PZeMD57Fw+pjmMhiCYioAscRUVDVfVa9W1WGqej6OUuVX7rFdqlrpbi90zz1k+al791cFjd3NhaUEGuISNFqEhDCs/D4h2S+oQkV1oKW7YxgxSfE7iwANsf9jfQk3NVVVhzYS5+67724Ww6ouJk2axNdff83KlSu58MILmTp1aoOvtXTp0jVr1qz5as2aNV+NHj16P0BxcbHvZz/7Wfbrr7++Pjc3d3V6enr13XffHdO4mTNnTs+PPvrom+XLl3/T4I6E0Lt378o33nhj/bp1675cvHjxmqeeeirzn//8Z3pTXNswDlcmzl3MjqIDBLRGgbgxXPf0kqABFXq9UBEID09l77qnl7AuxOjaXFh20IW67Iw0BvZIx4djDIUSaggNcA2hgT3Sef6G7zCwR837D24ZyzvTTw+26Z+ZzjOTT6J/Zs11fUKY0t/C6WPY8MC5zWlARUVV83C8UFe6u6KKqYhIhogkudvjgKHAc+77I0PaDQeygSZ5XkejoLQ8uF1eFWDX3gOH6lZGE5MQoYAA7ZL8VFZXcaAyQGqSv6W7YxhRSY3iscq+9Y16X8dbxYyHzQ+ed9A2IsKdd97JG2+8wYQJE7jllluYPn06q1at4sCBA4wdO5aZM2fi9/u5++67WbBgAe3atUNEeO+99ygqKmLkyJEUFDjq45s3bw5773HTTY467SmnnILP52PRokW88MIL/OEPfyA1NZVAIMALL7zA0UcfHbWf9913H5999hkvv/wyZWVlnHTSSfzud7/j3HPPjdp+/vz5LFy4kOLiYn7xi1/wk5/8BJ/PxwUX1KiLn3zyyfzxj3+M+dksXryYW2+9lb179wJwzz33cN55dX+m//jHPzoPHTq0dOjQoeXu750/efLkfjNmzNgZ2XbEiBGDy8vL5fTTTx80duzYvbNnz952++2393zhhRcyAIYNG1Y6d+7c3M6dO4etGh04cEAmT56c9dFHH3Xs2rVr1ZAhQ4KW9rhx44LJFRkZGdUDBgw4sHHjxpQ6O20YRp3kNqECcSCgYcpvnqfpzJmL8PuEQERonuLcL1DPVbmAwtbd+9nwQM0zMlaoYWQqRbTUinjatFLiEVMZDTwqItVAAXC+qnp/9PtFZAROdF4FMFFVd9WnA7mFZVw9dzHb9pTRN6MD864bHdPgLCwJX3zcXFhK7y7to7ZtKFsKS5k4dwnb9+y3WllNSMIYVqnJfvaVV1FeWQ3tk1u6O4YRFU8FsDWGrLZv356lS50V0+uvv54xY8bw17/+lUAgwFVXXcWTTz7JJZdcwh/+8Ad27txJ+/bt2bdvH+3bt6eoqCiue8yaNYs///nPfPzxx6SnOw6UW265hTVr1tCrVy/Ky8uprq6Oef5tt93GhAkT+NOf/sTnn3/OOeecE9OoAsjLy2P58uV8++23nHDCCZx22mkcf/zxYW0ee+yxMEMrlKKiIqZNm8abb75Jr1692LlzJ6NGjQoLMfzud787uKqqSs4444ziGTNm7Gjfvr1u2bIlpU+fPsFvxv79+1fs2rUrqmGzfPnyb0RkxNKlS9d07tw58MILL3R64YUXMhYvXvx1ly5dApdcckn2rbfe2usvf/nL9tDzHn744cwtW7akrF279suKigo5+eSTB/fp06c88vqff/55u88//7zDk08+uSXmB2UYxkFJT0liX7nj0W+oUptn1Hg1iiJZnxfbWGuf4qekPHZEgaf45/cJVQFFNbpARDQjKtFR1TXASVH2nxuy/RYwMMb5kxrbhynzlpLrqjBuLigNk5qPNHYnfqdv2LmbC8o4pX9jexDOJX/5mALXgLMasE1HwhhWXu7KgUoLBTRaLylR5NXj8SgBjJ/5flgycP/M9CZ9CE6aVPO98frrr7NkyRIefthRmS0rK6NPnz507tyZAQMGcM0113DWWWfxX//1X3Ts2DgRjnHjxjFp0iTOP/98zjvvPHJycmK29fl8zJ8/n+HDh5OVlcWHH35Y57WnTJkCwBFHHMF5553HokWLwgyr3//+93z99de8++67Uc//+OOP2bRpE+ecc05wn4iwfv162rVrx7p161YNGDCgcvfu3b5LL7203//8z//0evTRR3dEvVicLFy4sNPFF1+8u1u3bgGAadOmFUyfPv0oIMywev/99zteffXVhampqZqamqqXXXZZ4ccffxwW7rdly5bkiy++eMDDDz+cm52dXdmYfhlGIpNbWMZ1Ty9hc0FZzNX7tBR/0LDqkpYcFF6oj9hEpFGV5BpBkQjQN8MVfHCf+55R5ZNwFb7I74No/TFanlAPp0a8nzxvSdCo3pBfwp/eWx927ubC2AZ3Q4o8BwIaNKrAasA2JY3OsRKRQSLyiYisdV9rWfsi4heRWSKyQUTWi8j1Icf+JiIrQn4CIhJ9+bgOQgUsDKO1kuL3PFb191pFJgM39Zel50Fy+qe8+uqrrFixghUrVrB27Voeeugh/H4/n376KT/5yU/Ytm0bI0aMYNWqVSQlJREI1CxqHDgQfzz4yy+/zH333UdpaSljx47lrbfeqrP9pk2b8Pl8FBUVsX//fgDefvtthg8fzvDhw3nooYfiuu+f/vQnnnvuOd58803S0pwvoaeeeip4nWeffRZV5fjjjw9+DitWrGDr1q2MHDkSgAEDBlQCdOvWLTBlypSCxYsXpwP07du3Ytu2bUEP1YYNG1J69uxZATBx4sQsT+xi5cqVqXF/UPVk+/btSWecccagn//857smT56851DdxzASgcnznJpPkflOHruKD/DtvhqH8KAjOgYnr5F5T2fMXFQrF9bLkV0X4alSdYQjIkUgFCeEb+H0MWx84DzSU8NTHLy8qWjfB60pv8moIdRzGOnxDDVqAgoF7ljL6e602VQQ2+gJFTtZHzF2Y+Vmf7qplpih1cpqIppCvMKrZj0ImIVTzTqSq4ABOC7Wk4G7RCQbQFWvUdXhqjocmIQT+/p2fTtR47Eyw8qITpyLAGe59SfKRWRGxLEeIvKGW8fiaxH5s5foGi9Jfh9+n6DUXxmwOb8sL7jgAh588MFgWF5BQQGbNm1i37595OfnM2bMGO6++26GDBnC6tWr6dmzJ5WVlaxf76yyPffcczGv3bFjR4qLiwFHKGPjxo2MHj2aW2+9lbPOOovPP/885rl79uzhqquu4vnnn+fyyy/nhhtuAODss88OGj633HJLsP3TTz8NQH5+Pm+++SZjx44FYPbs2cyZM4eFCxfSrVu3YPvrrrsueJ2rrrqKU045hXXr1vHeezX5bEuXLkVVKS4upqSkRAAqKyt56aWXug4ZMmQ/wMUXX1y8atWqDl988UUqwKxZszIvvPDC3QDPPPNMrid2MWzYsFqhe+PHj9/76quvdt2zZ48vEAgwZ86c7mPGjNkb2e7000/f+9xzz2VUVlZSUlIiL774YoZ3bNeuXf5x48YNuuGGG/J++ctfFkSeaxhGOJET28jV++VbnLWJ43p3AmDVtmI25pcw5qH3gkV4PSqrtZaBNumpJcGCrx6RCnrRjnmUVdTMbby8KTOe2hZzJ42iUztnypDZMTXMGO6bEWJ0CXRq77Qb0bcr4ORDxSJU7CSy6PLkeTVGf+h4/PtSRxCxY2pS2HUOpTDW4UKjDKuQatYL3F0LgBNFJDOi6eXAE6oacFVYXgUujXLJKcCzqlprsnEw2rmCFRYKaNRBPIsAG4HrgWhuj9uAr1X1eOB4YATw/fp2oibPqr5nNh9//OMf8fv9DBs2jKFDhzJhwgS2b99OcXExF110EccffzxDhgyhZ8+efP/73ycpKYlHHnmE8ePHM3r0aPz+2AIyN998M+PGjWP48OEUFhZy7bXXMnToUIYNG8bOnTu58cYbY547efJkJk+ezKmnnsodd9zBrl27ePzxx2O27969OyNGjODkk0/m17/+NUOHDmXfvn386Ec/oqSkhPHjxzN8+HBOOqlW6D0AXbt25fXXX+fuu+9m2LBhHHPMMdx1112oKhs3bvSdeOKJxwwePPjYo48++rjk5GSdOXPmdve8wCOPPLLl/PPPH5iVlTVk7969/jvvvPPbeD77yy67bO+ll166e/To0ccMHjz4OIAHHniglujF9OnTC/r06VMxYMCAIaeeeurg4cOHB79N77zzzl5btmxp99RTT2V63rFHHnkkI/IahmE4dEipmWAKTh2h0JX+975x/n3POrYn2Rlp7K+sZtKTS9hSxyQ0oLAhr4ST7v93VI9DpILeB7eMjemF6p9Z49VqxsK6RhOSlZHG+cN6A/DTcQPCjOHf/aAmRL1X53YMP6oLACOzPcOqrJbkuif/HxlJWpcnbENeCeNmLOK1FU7E+l+vHUln14hrKrXLw53G5ljVqmYtInvik4QAACAASURBVF4161AZyywgNHE6l4iK1yKSAvwQODPajURkKjAVICsrq9bxYCigeayMKIQsAox3dy0AHhORzFDJVVVd77a/KMplFOgoIj4gFUghIu8lHsIFLOIoMtIMRIYlduzYkb/85S9R2y5evDjqfs/o8bjzzjsBp55UqDrgnXfeGTwG8J///Cfufr7yyivBbb/fz6JFi2K23bx5MwAPPPBA2P6OHTuGhS0ejFGjRkW9zwknnBBYu3bt17HOu/rqq4uuvvrquFQ9VHV56PvLL798zxtvvNGlqKgoacOGDe1yc3OThw4dWj5z5sxg/lZSUpImJSVpIBBg9+7dSSeccELZ9OnTCwBmz569bfbs2dtWrlyZ+p3vfOfYiRMn5v/85z+vHfthGAal5VVhpVo6uKv4Xi7U+rySoOjAyOyubCksZXNhGVv37K91rchiuwHg273ha8WxcmTrEpWYO2mU5U0lAMluOkBFhOpjz47tgts/Pn0Ar7uGT1a3DnRPT6WgpJydew9wZIgy4JR5S9lRVDvs/tErTwhu9+7Snm3uOBXA75cwI/83r6xm34EaQZTG5lo1JN8r0WhNdawuAnJVdUW0g6o6R1VHqurIzMxIh1jNZNUMKyMGtRYBAG8RIF7uBQYBO4FdwNuq+lFkIxGZ6oYTLsvPz488HBSwsHp/RiymTp3ad+rUqXmbN29ePXXq1Lwbbrihb2Sbxx9/PGPTpk2pmzdvXv3pp5+u+d3vftf7m2++CeZ1VVVVccMNN2SfeeaZ8Uk2GsZhyj9X76K8KkDPTs7ktnP7ZLbu3l8TXoVTSwjgjtdW0zmttvKwT5xcqXemn35Qb1JDcmQtbyox8L7/qyJqrlaFLPZt3V0WrGPVPT2FXp2dVNzv/e7dsFC9DfnhoaUe3iIAwLQxNVKCqck+qgMaloawMb80LAw1mre2PqGBU+YtZX1+9Hyvw4XGGlZxVbPG8VCFTgyyorSZDDzZ0I7UiFdYKKBxyLgUWAX0Ao4EThORH0Q2OvgigFck2CyrWIwcOTIoIuH9TJs2raW71Sxs37496csvv0ybOnXqboCpU6fu/vLLL9N27NgRFmHw0ksvdZ0yZUqB3++nd+/eVWeffXbR/Pnzu3rHb7/99p4TJkwoGjhwYL1Dqw3jcCG3sIzfvOqUTwiokpbiZ3vRfnp1aRe1/aaCUp75pHblgtCwvndvPr2WGAXUGF9mGB2+eAWaKyMMq+qQldbc3WXBOlYZ6alsdg2byFC97uk12kc+gYwOzrraom/ygvslZBweqAzQNS0l7BzPq9TVXSzo5JYrila4Oh425pcG0xxUYxt/iUyjDKt4q1kDLwI3iIjPzb+6CHjJOygifYDvAc82tC+pJl5h1E28iwB18VOcHMCAqhYDrwFj69uRYChgfU88jFi2bFmYEt+KFSvqzKVKJDZu3JhyxBFHVCYlOXZUUlISPXr0qIws8Ltjx46UnJycoNGUlZVVvnXr1hSATz75pP0777zT+Y477qgzr2vGjBndL7300l6xvKuGkehMnLuY/e68oaCkPLjg5U1SI+2jgFJLHt0vUstYCs2JCt1nIXyHN0m+6KGAoWNqQ34Jxfsr8Ql0aZ8cVrssNFTPy8MSN7T0d5c4eVqLvskPjuPIQsO7SyvCzvEWA5681hmX6alJ5O4uCytcHRoa6KkM5tz6BgNvf5OcX78R5tWK9Naq0iDPV1umKUIBpwE/FZG1OBPPaeBUsxaRkW6bZ3BEAdYBnwL3qOqmkGtMAv5PVRssCex5rMrNsDKiUI9FgLrYBEyAYE7gmcDqOs+IQkqSD0Wprkeej2HES3l5udx44419Z8+evcUzzmIxffr0whdffHF7LO+qYSQygYCyJSRsKqA1AlgrtznKpX+8YniYHLpPHK+DHERIIrQ8xsAe6Xxwy1jzVBnBUMC6PFaeemS3Dqn4fBIMUYWa8aaqfLHdGaNv/fx7LJw+hnFH96BrWgo7iw/Q/zbHmNlc4FxrYA8n3E9xaqf9e/qYsPE4rE8Xuqensr1oP/6QFYFIWXin3lYJARz1y0gv2t0XHBf2eyk0yPPVlml0geA4q1lXAz+q4xq/bWw/TBXQiINpwDwRuQNH1v8acBYBgDtUdZmInAo8D3RyDskVwBRVfRv4BfC4iHwB+IH3gCfq24nUJB9biio5bvdu0nr2QKR1CFgYrYOcnJyKb7/9NrmqqoqkpCSqqqrIy8tLzsnJCVt67N27d8XGjRtTx4wZUwaQm5ub2rdv3/Lc3NzkrVu3pl5wwQUDAfbu3esH2Ldvn3/BggXBGKZAICD5+fmdacDigGG0dXILy7jk8Y/D9vkEenZqx45iRxAg2S+MPboHJxzVNSwh/94Lh/C/r62uU0iiLiEK4/DFCwWsnWNVY1h5oXTd0x2v6UM/OJ6r5y4BarxMW3fvZ2fxAbqkJTOoR0cAfD4J5mp5Bs9OdywXldXUh68OKNOeWR42Pn0+4aR+3Xjji51h4iud2ieHje+N+aW1om1CvVqbXFn4c4f25J+rdwVzyQ+nAsSNNqxaC1bHyjgYcS4CfAj0iXH+BmpUBRtMapKfPy3ew4isruwt2t3YyxktxK5du5Kqq6u7H4pr5+TkVN177719v//975e+/PLLHfr371+Zn5/fJTRc79RTT63685//3Hv48OH+3bt3+956661uc+fO3VVWVtZp0aJFQbXKRx55pEtZWZnceuutpStXrgztbwBYXVVVdT2GcZgx6anF5O8LTz/sn5nOr84axI3zPwMcBbei0sqoRpIZTUZD8EIBKyNCAaNFsHg5VN/JySAlyUdFVYBXbvou6alJvODWoTqpXzd8IR6myLBB731hac1YV6IbOZ/l1g4ay+qWFuZlbZ/sp7QifJ4d6tX6eIMjPntK/+6s+7Yk6H2L9HwlMglkWHniFWZYGa2blCQfe8sDFCd15cSje7R0d4wGcuyxx36hqiMP3rL+rFq16uhVq1bNu+eee7oC3wLXDBs27JtQ7+rw4cP9wGMnnnjiWUA18OMLLrhgTuS1nnrqqbuA9Oeff/5Xh6KvhtEW2RyR7+HlSY2f+X5w3/6KaqbMW2pGlNFkJCd5OVYRHqvqSD8QZLgeqyS/j5zuHVizax/r80rolpbCvW98BTiFq3MLy4LGT68Qj6tPwO9z5P/7dE1j254yAho7fDVvb22do6937mV/RTXtU/yUlFdR4QrECU6eVkChS5rj1QoElE+ChlUGpw3M5IonPmFH0QF8PuEvV49oyEfW5mhNcuuNosZjZaGARuvGE68oNwVLIwaqukZVT1LVQe7rN+7+c1V1mbtdrao/UtX+7k8to8ptd5eqmlFlGCF4z2EIn2iGruTHWtk3jIaSEiMUsDpK/ZWMDjWqfwOPcML91n27jynzlgZrTxWWVoTlLt138ZDgdv/MdNLcwtePXDE8mPMXS0QlJ7NDWC5hSpKPqoCyeoeTy/XemjwqA8ro7G5sevA8nrpuNABZGR3Iykjjm2/3sbu0gp6d2tGvu7Pvo/8ZR3ZGGtUB5aw/vH9YiFgkkGFlBYKNtkFK0LCysWoYRmIiIoNE5BMRWeu+DozS5m8isiLkJyAiFxzqvhXvrwyuvEdONCMnl4dL+JLRPHgFgiNDASOVJqHGYwU14hPr80rCJMw1IndpZHY3wAnZe+vn32PvgUpEYOiRnQ9aBy1UcKV/ZjoTjusJwIpcpxTiP7/cBcDZQ5z9I/t2xe8TVm8v5uude5k4dzEApRVVbN3tFiUWocwNHYwUukhUEicU0MQrjDaCV8fKPFaGYSQwjwOzVHW+iFwNzAbGhTZQ1Wu8bREZBrwLvH2oO/bhugIC6uSn/P3Gk8OOzZ00KkyowuTRjaYkyR89FNDzWCX5JGhkdQ8xrAYd4RhW6/JK6NYhhQJXRj3S+O/ULpmOqUnsK69iU4FTU6pbh5TgfesiMpfwhWVbeX3lDj7akM/zS3PZ4BpwQ47sBECH1CSGHtmZFVuLmPL00mCfSg5UhYXQhkq+BxQ25JUwfub7rM8rIcknVKuGSb+3dRLGYxWsY2VeAKOV443VCjOsDMNIQESkB3AisMDdtQA40a1jGYspOHUCD3lBa6+A6umDa+e4epPLulb2DaOheKGAlVXRVQF7da6RVv/jv9cFw+YGuMp/a7/dR5+u7QHHqIoW1te7i3N8lVsywKvJVl96dnJCERd9UxA0qgB+80qNkOx3cjIAgnldUDuENiezQ1ih4gCOgahAZcCRbF+flzierIQxrKyOldFWSPFbjpVhGAnNUcB2t9SKV3Jlh7u/Fm5dwB8CT8a6oIhMFZFljS1mHQgoi9Y654892mq3Gc2LFwoYGfrneawKS2u8O7v2HggaG30z0kj2C9v27OeL7XtJ8gmf/+9ZUY3/3l0c42zVNieELzSksD7c+/++jro/1Gjql1l74SHSizZ30igGZKbXeS/PGMstLOPMmYvadFHhhDOsLBTQaO14HivLsTIMwwDgIiBXVVfEaqCqc1R1ZGOKWecWljFmxnvk7ysnySe0d+cNhtFc1ORYRQ8F3B8iZR6aP5Xs99Gve4dg21HZ3eiclhz1Hke6Hi2vyHVGemrUdgcjmnBLpNE05/2NtdpEetE8L7D/IDU7czI7cN3TS1ifV9qmiwonjmGVZHWsjLaBl2NloYCGYSQoW4EjRcQP4L72dvdHYzJ1eKuaiinzlrLNTaqvCijXz1t2qG9pGGEkuaGAkd//XmHfDqlJwbC5SCNmoBsOCHDGMbFLtXihgF/t3AtA9waGAkaG8EFto2lzQfSyBdFCaEOFYTyS3R1JPmHupFFsKqgx5gLqhAy2Nc9V4hhWVsfKaCOY3LphGImMquYBK4Ar3V1XAp+raq0YPhHpA3wPePZQ92tjfika8d4wmpOUg3isTumfwYAYsug9OtZ4nuZ/uiWmsXGka1h5xlv3BnqsvBA+vwgDe6TzwS1jaxlN9VHRDFUd9K731b0T8LsCFj06pUb1rq3LK+G0h95rMwZW4qgCWiig0UYIGlY2Vg3DSFymAfNE5A5gD3ANQGiRa7fdJOD/VHXPoe5QTmYH1uU5UtViUupGCxArx8p736l9csyC1J7cOUDu7rKYxas9w8qjoaGAkSqB0aiPimas62V1S2NTQSlbCss4dUAGr3y+I+r5693QwNZesDuBDCsLBTTaBqnByus2Vg3DSExUdQ1wUpT950a8/21z9WnupFGcPuM9AgrZGSalbjQ/sUIBQ+XWY5G3t0YwM6CxPa69axlWDQsFjId4jK+DkZ3hGFabCkrYUeSoC/bu0o6dxQfQEPszsmZXbmFZLaOuNah4Jl4ooHkBjFZOinmsDMMwmp3OackE1Cme+u7NJqVuND+xQgE9j5W/DsMq3rC7Hh1Tw67T/RAaVk1Bv+6OYuDGglLWfrsPgEevOCGqkmDo7zx53hLW5ZW0OqGLxDGskkxu3WgbBMUrqs2wMgzDaC68/IysbmnIQRTKDONQEFNu3Z0P1OWxCs1Rila/yiPJ76Nnp5p6WBkdGhYK2Fz0c42lZZv3sKesko6pSYzo25WF08fwwS1j6dvNWQDxBC48Qr1XoR683MIyxs98n5xfv9EieVkJEwpoBYKNtoLlWBmGYTQ/W3Y7E6++5qkyWohk9/s/VoFgvy+2v6M+YXdHdmnP9iJHAfNQhgI2BTmujPyH6woAGNSzY3DhIysjjXd/dTpD73qbsopq2qfUlEhI9vvCRMA8b9aUeUtZ7xYgXpdXwriHF6FKs4ULJozHKjXJhwhUVmswVtUwWiPBUEBbBDAMw2g2trgr12ZYGS2FJy9eUR29QLCXg9VYvCLBKUk+0lNbtw8l2zWsvCieQUeEhwD6fcLQIzsDNUWPV20rorwqgPdpCfDwZcMA2JBfEqb+WRXQeoUL5haWMW5Gw4sUJ4xhJSJBT4AJWBjREJFBIvKJiKx1XwdGaXOWiCwTkXIRmRFx7G8isiLkJyAiF9S3HxYKaBiG0fxsKXQ8VlkZpgZotAyxCgTHk2NVHzq4xlRFVYCz/vBBq5Yp79WpXXD+DjDoiI612gw/qgvgFD3OLSzjqr8uBqBz+2SG9emMAhc+9hHjZ74f5tUKxauLNfD2N4Nhgp9uKGT8zPfDjKhrn1rCxoKGFylOGMMKQgUszLAyovI4MEtVBwGzgNlR2mwErgceijygqteo6nBVHY4jEbwHeLu+nTDxCsMwjObH81hlm8fKaCG8UMCqGHWs6sqxqg8Lv/o2uN2ahB2i4fMJ/brXLHZEM6yO7+MaVluLuPapJew7UAVA8YFKvtzhFEL2Qv9Kyx0bwCeQ7BciP9HKaiWgzucy8cnFrM8PF8DYXBg9dyvu36derVs5noDFASu8akQgIj2AE4EF7q4FwIkikhnaTlXXq+oKoOogl5wCPKuq5QdpVwsrEGwYhtH85O52QwG7mcfKaBk8w6kyIhSwqT1WBSXxSbO3FrIz6jashh3lhAKu3FbEpoKa30W1thCIR//MdN6ZfjoDetRWFwTnc6ms1qCku/c5dWyXHGwj1L/eXWIZVlbLyojNUcB2Va0GcF93uPvrhYikAD8EnmxIRzyhlcg6FoZhGMah4UBlNTuLD5Dkk2D+iWE0N14oYEV1AA0p0lQdOLgqYH3on5ke9NTUJc3eWggV2PjhE5/WCl2sDih+gaKyyrD8Kc8rFe1j25hfGhT8GNgjvVYbwTk3lJzMDmR0qOlL1w7J9a53l2CGlYUCGs3CRUCu69mqhYhMdfO0luXn59c67tWxMPEKwzCM5mGr6606smt7kvwJNfUx2hB+nwS9UqFCa/GoAtaHuZNGMaDHwaXZWwsHC128ft4yQp18ST4J/m7PTD6J/hE1ryKNSU+q3keNV7Bdso/fnHdM2Hm/Oe8YNoWEAh7Xu3O9VQRbt1RIPUm1IsFGbLYCR4qIX1WrRcQP9Hb315fJ1OGtUtU5wByAkSNH1vJRe+PUPFaGYRjNQ40iYOteuTcODSIyCJgHZACFwDWqui6iTU+c3Ot+QDLwW1WdH9FmMPA58GdV/VVD+pLsF6oDSmW14mawUF3dtDlW9ZFmbw0UllQEt6OFLka+V4UND5wbfL9w+hhyC8uYMm8pG/NLg9LqHqGfR3FZJSfet5CKamXttyVh131uSS6qjnLolsIyVuQWOd6yevxdEmrZpl1QFMA8AUY4qpoHrACudHddCXyuqrVdSnUgIn2A7wHPNrQvlmNlGIbRvHgJ6V6xUeOwIx7xqpnAMlU9HjgNuF9EgukC7oLsbODVxnQk2VcTDujR1DlWbY2czA7BUL1ooYsHOw41xtOGB85l4fQxMT1NndOSGZ3djeqAsmBJLgDnDOkJwNtffuu+78WRXdqzr7yKdXn76vW7JJZh5XmsLMTKiM404Kcishb4qfseEXlTREa626eKyDZgOnCjiGwTkbNDrjEJ+D9V3dPQTqSYYWUYhnHIyS0sY/zM98m59Q3uf/NrAN5avbNVS08bTU+84lXAMOCfAO6i6wrgspDjtwL/D1jbmP4EiwSHGFZNXceqreGF6sUKXTzY8fpyxjE9AMc71jE1if+ecHTY8dH9ujKib1cAlm+p33QvoUIBa8QrbMJq1EZV1wAnRdl/bsj2h0CfOq7x28b2w/NYWSigEYs4w1b8wKPABByl2QdV9a/usf8FrgCqgUrgNlWtd2kAw2jLTJm3lHV5bqiPG5RdWFLBlHlL21SYlNFoaolXiYgnXhUatbIcuEJElgHZwCnAZgARGQacDYwF/reum4nIVGAqQFZWVq3jnmBCVXW0HKvD07A6WOhiU4c2Hte7U3BbAb9IMPwP4L43vua0gY7d/ZtXVvP0R5uZO2lUXPlWCemxMlEAozWTEqIKFIghE2oc9sQTtnIVMAAYCJwM3CUi2e6xJcAoN6RlMvB3EWl/qDttGK2J9fkltfYprV962mgxbgaOwPFUPQq8A1SJSDJO3vQ0zzirC1Wdo6ojVXVkZmakUwySfNE8Vk2rCmjUzR2vfRncLi2vYsq8pRSXVQb3bS4oZf6nWwDnmVGfWmCNNqxEZJCIfCIia93XgVHa+EVklohsEJH1InJ9xPHLROQLEVntvh7RkL4E61iZx8poxYhIMBywotrGqhFOPcJWLgeeUNWAG7byKnApgKq+rapevNMqHGXZjEPeecNoBeQWlvHdB99Bo6xbtQXpaaPJCYpXQdDbX0u8SlXzVfVqVR2mqucDHYGvgF5Af+BNEdkM/AK4QUTmNKQz0b7/m1oV0Kib0MUVb7Fl74EawyoQUR+rPrXAmuIv2KiVVTe35S5gvKoOAU4FihvSEatjZbQVTMDCqIN4a65lAVtC3udGaQNwDbBBVbdFHjhYaQDDaItcPfdTthcdCNvn1bppC9LTRtMSr3iViGSISJK7PQ4YCjynqrmq2l1Vs1U1G/gjzqLW1Ib0J1ooYDDHyjxWzUI0MYz+melh+5L90qBaYI0yrJpiZRX4JTBDVXcBqGqxqh6gAbQzuXWjjVBjWNkigHHoEJExwL3UTCjCOFjIimG0JXILyzjlwXfI3b0/bL9fhHW/PZeND5xXp1qYkdAcVLwKGA18LSJrgHuA80M8/02GVyS40lQBW4xoYhiR+56ZfFKDaoE1Vrwi3oTAulZWjwU2icgHQDrwMk7tgHonn6RagWCjjZDqhq2W2yKAUZt4a67lAn0BL/A77DkrIicD84ELVfWbQ99tw2hZJs5dzI4IT5WF/hkQt3jVWziRVQe71l2N6UuSv3YoYFPXsTLqJpYYRuS+hghmtIZgTj9wPDAeGAOcA0yMbBRPyEowFNC8AEYrJ9VyrIwY1KPm2os4cf4+N0rgIuAlABEZBfwd+IGqftY8PTeMGuLJv3bbNUmONcDWPbWdCxb6Z7Q2UtxQwMoq81glIo01rOJKCKRmZdUjK6RNLvCSqpar6j7gNRx3bBjxhKy0My+A0UYI1rKysWpEJ56wlWeAjcA64FPgHlXd5B77M9AemC0iK9yfoc36GxiHOwfNv27KHGuA7umpwW2fwMAe6Rb6Z7Q6vFDAUHGEoCrgYVrHKpFoVCigquaJiLeyOp+Dr6y+jKNMdRHwPffYc8C5IvKM258zcFdd60s7CwU02gjmsTLqIs6wlWrgRzHOtyV6o8UIyb8e7+5aADwmIpkR84NaOdaNue/Ek/vy8L/WIpinymi9RAsFNFXAxKEp/oKNXVl9HsjDkbRcAXwJzG1IR0wV0Ggr1ORY2Vg1DCPhiFfZ8lggR0Q+EJHPROQ3IhJ1yT6edIBO7ZIBuPo7fc1TZbRaooUCmipg4tBY8YqmWFkNANPdn0ZhqoBGWyHF5NYNwzBCc6xTgH/ipAf8LbKhqs7BKdLKyJEjo4pbeSprXqiVYbRGalQBa4ax5VglDgn19DHxCqOtEAwFNMPKMIzEoz751wfNsY4Xb6KabHkqRiumJsfKPFaJSGIZVkmWY2W0DVKTzWNlGEZiUg9ly+eAs8QhGSfHemVD72seK6Mt4AlUVJgqYEKSUE+fVAsFNNoIKX4rEGwYRkITT/51k+VYA1RVm7Ka0fpJiRIKGFQFNPGKNk+jc6xaEyZeYbQVPPEKCwU0DCMRiTP/uslyrAEqgqGANjk1Wi/RQgGrqs1jlSgk1NPHE6+w8CqjtWOhgIZhGE1LVTAU0CanRuslWihgMMfKxm6bJyENK/NYGa0dLxTAPFaGYRhNg+VYGW2B6KGA5rFKFBLq6dMuyUIBjdiIyCAR+URE1rqvA6O0OcutlVIuIjOiHL9MRL4QkdXu6xEN6UuNx8rGqmEYRlNQGVz1T6ipjZFg1Mit1xavMFXAtk9CPX2sjpVxEB4HZqnqIGAWMDtKm43A9cBDkQfchOu7gPGqOgQ4FShuSEdS/Ba2ahiG0ZR4BVdTLJzKaMUEc6yqa4cCmseq7ZNQhlXevnIA9ldWM37m++QWlrVwj4zWgoj0AE4EFri7FgAnikhmaDtVXa+qK4CqKJf5JTBDVXe5bYtV9UBD+uN5rCwU0DAMo2moWfVPqKmNkWAEc6zCCgSbKmCikFB/wal/Wxbc3pBfwpR5S1uwN0Yr4yhgu6pWA7ivO9z98XIskCMiH4jIZyLyGxGptbwkIlPdcMJl+fmRZVscvALB5rEyDMNoGiq8HKukhJraGAlGSpRQQPNYJQ4J9fTZmF8a3A5o+HvDaAL8wPHAeGAMcA4wMbKRqs5R1ZGqOjIzMzPyMAApSZZjZRiG0ZQEVQFtcmq0YjzVyirLsUpIEsqwysnsgES8NwyXrcCRIuIHcF97u/vjJRd4SVXLVXUf8BowuiGd8epYmcfKMAyjaai0OlZGG8DzqIaGAlZ7dawsP7DNk1BPn7mTRpHd3TGmBPjTlSe0bIeMVoOq5gErgCvdXVcCn6tq9Fi96DwHnCUOycAZwMqG9MdCAQ3DMJoWL7TKagEZrZlkn6kCJjIJZVhlZaTx3q9O58SsLiiwwUIBjXCmAT8VkbXAT933iMibruIfInKqiGwDpgM3isg2ETnbPf95IA/4CsdI+xKY25COBEMBTcHSMAyjSfAmqinmsTJaMclJjvEULcfKVztt22hjJLV0Bw4F38nJ4LPcIn7y3Gf88d/pzJ00iqyMtJbultHCqOoa4KQo+88N2f4Q6BPj/ACOwTW9sX1JDYYCmGFlGIbRFFRVWx0ro/VTI7ceTRXQDKu2TkI+fd78YieA67UydUCj9RHMsbJi1oZhGE2C5wFItlBAoxXjSap7C6uBgOI6rEwVMAFISMNq6+79wW1TBzRaIynmsTIMw2hSTLzCaAukRIQCVmuN1HqUCi5GGyMhnz6haoCCqQMarY9Uy7EyDMNoUmo8Vgk5tTEShMhQQKthlVgk5NNn7qRRdGrnpI9175jK3EmjWrhHhhFOu2SrY2UYhtGUBJXVLBTQaMV4hpUXsWKKgIlFQhpWWRlpTDolm6LSpwAAIABJREFUG4Afjs4y4Qqj1VGwrwJwlCvHz3yf3MKyFu6R0ZoQkUEi8omIrHVfB0Zp4xeRWSKyQUTWi8j18RwzjESlospUAY3Wj5cDGAwFrDaPVSKRsE+fjA4pAOwurWjhnhhGbX79yhfB7XV5JZz20HtmYBmhPA7MUtVBwCxgdpQ2VwEDgIHAycBdIpIdxzHDSEiCymrmsTJaMZ7HqjLosTJFwEQicQ2r9FQACkvLW7gnhlGbaAbUelOwNAAR6QGcCCxwdy0AThSRzIimlwNPqGrALXT9KnBpHMcMIyEx8QqjLRA7x8rGbSKQsH/FjHTHY1VQYh4ro/WRk9mByMUpNQVLw+EoYLuqVgO4rzvc/aFkAVtC3ueGtKnrWBARmSoiy0RkWX5+fhN13zAc4gxpvUtE8kRkhfszq6H3C4pX2ATVaMV4oYCWY5WYJOzTp7vnsSoxj5XR+pg7aRT9M9Nr7TcFS6M5UdU5qjpSVUdmZkY6xAyj0cQT0grwN1Ud7v7c1NCbBQ2rJJugGq2XyFBAUwVMLBLWsPJyrAotx8pohWRlpLFw+hg+uGUsfbq0B5yEa1OwNICtwJEi4gdHiALo7e4PJRfoG/I+K6RNXccM45BTj5DWJsMLrUoyj5XRigkaVlXOeDU1y8QiYZ8+XdJS8AkUlVUGVwUMo7WRlZHGv28eQ7JfqAwE6NIhuaW7ZLQwqpoHrACudHddCXzu5kqF8iJwg4j43MnqRcBLcRwzjOYg3pBWgCtEZJWI/EtETo52sYOFrapqcIKabBNUoxUTzLEKeB4r59U8VolBwhpWfp/QzfVa7TGvldGKaZfs57jenVGFFblFLd0do3UwDfipiKwFfuq+R0TeFJGRbptngI3AOuBT4B5V3RTHMcNoTTwO9FPV44GHgNdEJCOy0cHCViura/JURGyCaoQTZ75fTxF5zTXyvxaRq0OOXefuXyEiX4jIzxral2COVZVnWDn7LccqMWi0YdUE9VaaLHE1Es+wMgELo7Uzsm9XAJZt2dPCPTFaA6q6RlVPUtVB7us37v5zVXWZu12tqj9S1f7uz5yQ82MeM4xmIq6QVlXdpaqV7vZC9/iQ+t4smF9lioBGdOLJ95sJLHON/NOA+0XE87D+AximqsOBU4CbReT4hnSkJsfKCwX0PFY2dhOBpvgrNrbeCjRR4mokGR0cAQurZWW0dkZmO4bV8i27W7gnhmEYjSfekFYROTJkeziQDXxT3/sF86ssDNCIoB75fsOAfwK443QFcJn7fq+qqtsuDUgGlAZQOxTQVAETiUYZVk1Ub+WQ4UmuWy0ro7VzRKd2AHy0vpAzZy6yQsGGYSQC8YS03i8iq0VkJfAEMFFVd9X3Rp50dYp5rIzaxJvvtxwn309EpB+OZyooAiQiF4jIlzilLB5S1S8a0hkvFLCyWsNyAy3HKjFo7BOoKeqtQByJqw3Bk1y3UEAD4g5bPctNkC4XkRkRxw5Z2Op/v7QquL0hv9QKBRuG0eaJM6R1kqoOUdVhqjpKVd9syL281X/zWBmN4GbgCBxP1aPAO0CVd1BVX1fV44BBwEQRGRztIgcTWhGRoHeqslrNY5VgtIalnbgSVxtSyDIouW61rAyHeMJWNwLX44zFaBySsNXQwsBWKNgwDKN+eNLVlmNlRCHefL98Vb3aNfLPBzoCX0VeTFVzgSXAf0W7WTz1AUNrWXlhrOaxSgwa+wRqdL2VeBNXG1LIMiNYJNg8Voc78Yatqup6VV1ByCpVc5CT2QHvkSpYoWDDMIz6UBkw8QojOvXI98sQkSR3exwwFHjOfX9MSLvuwFigQaGAUBMOWBXqsTJva0LQqCdQU9RbaarE1WhYjpURQn1qqtTFIQlbnTtpFEd0chYC0lL9VijYMAyjHtSoAtrk1IhKPPl+o4GvRWQNcA9wvqp6Cc9TReRLEVmBEyL4mKr+q6Gd8RYAKqoDpgqYYCQ1wTWmAfNE5A5gD3ANOIMVuMONo34GOAmnpgqE11S5X0RGANVABQ1MXI1G93STWzealMeB36pqpYiMxwlbPUZVC0MbichUYCpAVlZWXBfOykjjiWtGcf5jH9KnSxpZGWlN3XfDMIyEJagKaJNTIwqqugZnHhq5/9yQ7bdw1Kujnf/LpuxPaCig5VglFo02rOIcrNXAj2KcP6mxfYiFJ7duHiuDkLBVVa2uI2w1JqEGv6ouFBEvbPX9iHZzgDkAI0eOjFuONbu7Y0xtKiwlEFB89pA1DMOIC08VMDnJDCuj9ZOcVBMKaKqAiUVCP4G8UMDd5rE67KlH2GpMDmXYKkDHdsn06JhKRVWA7UX7m+qyhmEYCY/nsUq2yanRBkj21YQCmscqsUhowyo9NYkUv4/Simr2V1S3dHeMluegMdYicqqIbAOmAzeKyDYROds9v0nqrdRFv+6OaMWmAlMFNAzDiJeaHKuEntYYCUKYKqB5rBKKpsixarWICBnpKewsPkBhaTl9Uixv5XAmzrDVD4E+Mc4/ZGGrHjmZHVi8aTebCko5bVB86peGYRiHO55hZcpqRlvACwV0cqzcsWuGVUKQ8Es7QWVACwc02gA53dMB81gZhmHUh0o3FDDFPFZGG6DGY6Uhdaxs7CYCCf1XzC0sCxZa/dH85eQWlh3kDMNoWbxQwA35JS3cE8MwjLZDlXmsjDaEl2NlqoCJR0IbVlPmLaXMza3aWXyAKfOWtnCPDKNu+mVajpVhGEZ9qbAcK6MNERoKGMyxskWBhOD/s3fmYXJVZf7/fHvJzpp0lK0JhAQdEBhMZHDYR1AZF2YGBBSIigR0Rh9BmEd0REZH1Amio+CwBQmiiIwM+NOIoBLc2IJElmHJQmgWIZ0mIXSaJL28vz/OudW3q6u6q7url3v7/TxPPVX3nnPvPbfqvafOe97l5LoHSqxVAFa07Thjkcadp1BbI17Y+Dpb2j3hiuM4TiUUsgK6YuVkgEROOzrNLVY5I9c90N4NU1HRtuOMZepra2jceQpm8Gx0XW1qaeOYbyxj9oVLOfaye9yl1XEcp4jurIA+OHXGPnWpdOueFTBf5FqxWrxgPrvsOAmAyfU1LF4wf5Rb5Dj988btg8y++79+y7GX3cMHr72PNc2b6TRjdXOru7Q6juMU0Z7M+rvFyskAEzwrYG7JdQ/UOH0KP/zY3wCw89SJNE73dOvO2OeJv2wCoMtCEovnN3QvFtxl7tLqOI5TTHtHGJx6VkAnC5Rex8plNw/k/lfcdcfJSPCXV19nW+x4HWcss2lLe+Fz7G8LCHdpdRzHKabDZ/2dDJFOt97Z6TFWeSL3itWEuhp23WEyXQYvbny9/wMcZ5SZ3TCNct3rTlPq3aXVcRyniGQdq/q63A9rnByQxAK2e4xV7hgXPdDuO00G4LkNHvTvjH0WL5jP7Jk9rVJJd/tXu+7gLq2O42QCSXMl3Svp6fg+p4+6+0pqk3TpYK5VSF7hg1MnAxQsVh2+jlXeGBeKVePOYSD63CtusXLGPo3Tp/Cr844i3ccmHoErnttY6ISd/CFpiqSbJa2S9KSk9/RR96xYb7WkyyXVxP3vl/SQpMckPS7pMyN3B47TgyuBK8xsLnAFcFWpSpJqY9ltg71Qu69j5WSItCugr2OVL8ZFD7RHVKyaXnGLlZMdZjdMKyhXNQqzWa1bO1jd3Dq6DXOGk/OBTWa2D/Be4FpJ04orSdoL+CJwKDAnvk6LxS8B7zWz/YG3Ax+XdPhINN5xEiTNBA4Gboq7bgIOltRQovpngZ8BTw/2esk6Vp4V0MkCBcWqy7MC5o1x0QPtsbO7AjrZY/GC+cxumEatxOyGaRw+ZwYADzdtGOWWOcPIycRZfTNbCSwH3l2i3onAbWbWbGZdwDXxWMzsfjN7MX5+FXgC2HME2u44afYAXjCzToD4/mLcX0DSgcA7gW8O5WLbfB0rJ0O0besAYNEdT3HL8ucBzwqYF+pGuwEjQbcroCtWTnZonD6Fu847srB97e/WcPdTzTzctJGT5zeOYsucYaQReDa13UTRQHQg9SS9Cfgb4OxSF5O0EFgI0NjoMuWMLJLqgauBj5hZp1ReKepPVhOLlbsCOlngZ4/8BQhu/htfD5mA3WKVD8aFYrXHTq5YOdlnlx2D5fVHDz7HQ89uYPGC+Z7IImNI+hNBKSrFG6p8rV2A24FPJBasYszsasLAlnnz5nnwnlNNngN2k1QblaZaYNe4P2EXYDawNCpVOwKStL2ZLUyfrD9Z9RgrJ0tsaNvWa59nBcwH46IHathuIhPratjQ1s5rqTWCHCdLXHbnU4XPK9e1csSiuzn2sntoavEJg6xgZgeb2Ywyr06C5SntttdIz4FoQp/1YnzLr4D/NLNbqn8njtM3ZrYOWAGcGnedCjxsZs2pOk1R9meZ2SzgW8A1xUpVJbQXYqx8cOqMfWZMm9hrn1us8sG4UKwkFRJYeGbA8UslqX8lHSdpuaSt5dL+DjUt8GBZu763ArW6uZUzlzw4ks1whpdbiG57UT7nA3eUqPcT4ARJDTEb4FnAj+Nx04G7gMvNbPGItNpxSnMO8ElJTwOfjNtIWippXjUvlFisJrjFyskAC4/YCwhLqWw3KTiP1bhilQvGTQ9UiLPyBBbjmUpS/64BPgYsKnWCaqQFHix7N0yluN/tMljTvHmkm+IMH4uAHSWtImRJW2hmrwFI+pKkcwDMbA3wZeA+YCVBbm+M5/gsMBc4W9KK+PrICN+H42BmT5rZIWY2N74/Ffcfb2bLS9S/2MzOH8y1OpLMam6xcjJA485hrcq/e/NM/u5NMwG3WOWFcRFjBbDj5HCr59z4EPs0TPP4lHFGKvXvsXHXTcDlkhqKXFNWxfonlDlVkhZ4WnyNGIsXzOfMJQ+ycl3PdOtJ1ksn+5jZZuCkMmUXFW1fRYnJATO7ALhgWBroOGOUbR2evMLJDtMmhjFp69YOJtXXAh5jlRfGjWL125XrATDrdp9KZ1xzck+v1L+SktS/zX0eGUmlBT4a+EIf9YYl01qSJbCppa2HgrW2pY2jFt0NBFfXvRumFiYOkrprmjf32O84jpMnEouVp1t3ssDUqFi1beukMy4QXOfp1nPBuPkVX9ncnYHF3aecgZJKC3xOopyVw8yuNrN5ZjavoaHUWphDI1Gw9prRrSCtbWljbUsbnWY94q7OXPIgq5pbe+13HMfJE54V0MkS0yYGK1Xr1g46omLlFqt8MG4sVns3TGXVuqBMSWHbGVdUkvq3LypOCzxSNLWUTsTSZSFr4LGX3cPq5lbMuvf7hILjOHmkkBXQZ/2dDJBYrDZv7UhZrFyxygPjpge6bsHbCj6tM6ZOYPGC+aPcImckqST1bz/HVy0tcLUolcwizcp1rXQVrfbiEwqO4+SRQlbAOh+cOmOfKRMSxaqz22Llbqy5YNwoVo3Tp/DlE/YDYN83bu9xJuOTflP/SjpM0vPAeYSsas9LeueotbgPFi+Yz+yGadRKzJo+hVkVyPRF7/2rEWiZ4zjOyNLhFisnQ0ydEFwBN2/roCNOCrjFKh8M2RVQ0lxgCTAdaAHOMLOVRXVqgW8D7wIM+JqZXVtUZ1/gYeC7g0232h9HzZ1JjeD+Z1p4bUs7202qH47LOGMUM3sSOKTE/uNTn38P7F7BuS6uauMGQRJrlebYy+5h1bpWigxViPDg/X7leg6fU/24L8dxnNHEY6ycLFFXW8Ok+hq2tHfRurUD8BirvFCNHqiStYE+BOwDzAEOBS6WNCspHKm1gXaaOoH9dt2e9k7jwH+/k2Mvu4emFl/XyskPixfMZ5+ZPbPA1wjesH1Y5f2q367hHZctc7l3HCdXuCugkzWS8JRXX28H3NqaF4b0K6bWBrop7roJOFhS8ZT4yYR4lK4Y03IbPddqSdYGenoo7amEFzduAUIgv2dJc/JGYsX67QVHM2dmcBOc3TCtsE4GwOp1m13uHcfJFZ68wskaU4sUK7dY5YOhugJWujZQI/Bsarsp1ql4baBqsaGtZ9r1JHuar+/j5IliN8HZFy4tfDaC3M++cCl7N0zly+/fny/c/pivdeU4TmZJ4lTq61yxcrJBksBiU8Fi5YpVHhjVHmggawNJWihpuaTlzc0VJXIryeyGaRSLrluunLxTKoNgsrbV6dfdz8p1vtaV4zjZZVu0WNX74NQpgaS5ku6V9HR8n1Oizhsl3S7pEUlPSDotVfYFSY/HsoeqkdQqWcsqyd7rFqt8MFTFqrA2EBRipUqtDdQE7Jnabox10msDrQU+DZwl6eriC1Vr0dVSMSi+vo+Td9IZBNN0WbcLTbLtz4LjOFmjo8uTVzh9Ukk+gMuA5WZ2AHAEcImkPWLZA8D8WPZR4GZJk4fSoMQVMKHO063ngiH1QANYG+gWgsJUE+OvTgD+ZzTWBkpcpObM7Gm56jTzZBZObknkfvVXj+8l+2mEr3XlOE72aO+IKat9cOoUMYB8AAcCdwDEcewK4ANx+5dmlgwQHyH8XU4fSrt6KVZuscoF1Zja6XdtIOD7wBpgJXAf8CUze6YK1x40pSxXq9wNyhkHLF4wv6zyNHViXY/Fs5ta2jj2snuYfeFSn3hwHGfM0h79qdxi5ZSgVz4AIMkHkOYh4BQF9gLeTk9vq4QzgNVm9nypi1UaujJtQk/FqtYTr+SCIa9jVeHaQJ3Axys418VDbU+lJDP4sy9cSqdZvL67QTn5p3H6FH79maN4+1d/zYuvhiyZyTpXO0wOa7u947JlrGnejCQ644Alib8qXjvLcRxntPF1rJwq8BngmwRLVRPwa6AjXUHSkcCXgWPLncTMribkD2DevHnFy0oWmDKxtse2W6zywbjvgfZumEo67GT3nYbkMus4meHlTVsLn5Oe/4WNr7Pgew+wet1muoyCUgU9s2i65cpxnLFCZ5dhFtbs8wQATgkqygdgZs1mdpqZHWhm7wW2A/4vKZd0KHAjcIKZPTXURk2bWGyxctnNA+NesVq8YD77NHS7BD77ShtHLbqboxbd7e5PTq5JZwqsEUyOa10927KZslNsBOXqiEV3+7PhOM6YILFW1bm1yilBpfkAJE2XVBc/HwO8Bfhh3J4P3AycaGZ/qka7PMYqnwzZFTDrJC6BR1+6jGfWBzfAtanBors/OXll8YL5nLnkwcL6VW/fZwZL/riWGomu6B4rQjB4OnNgwurmVs647n7qasWa5s3M3G4idbU1/GXjFl8Py3GcESNRrCa4YuWU5xxgiaSLgA2EOCkkLQUuMrPlwNuAb0vqBNYD700lrPguMBm4St1uTqeb2aODbVCxYuUWq3ww7hWrhHIz755+2skrxYsIL3tqHUv+uJaO6P4nwT4N0woK2OrmVlKegXRZz0mIl1KuhT4h4TjjG0lzgSWEzGktwBlmtrKozkeAc4EuoJaQFfjbA71WMvHjGQGdclSYD+AXQK/1rWLZ/FL7h8LUCcUxVj4xkAf8V4yUWkA1wVOxO+OBhu0mFj7XCO789BHcdd6RNE6fUlgHq1J8QsJxxj2VrBv0E+BAMzuIkIHtM5IOGOiFOjxxhZNBelmsfGIgF3gvFEkvoDpr+hT23LmnC5PHlTh559M/WlH4bAaf+EG3G3li3frtBUczZ2ZlCpZPSDjO+KTSdYPMbJOZJXbwKUA99BniWZJtiWLlrlROhihOXuExVvnAXQEjxW5RAHtf+PMerk/QHVdSX1tTiE3xWBInD6QtTEZpi1OpZQoSZsVnoDhG0Z8Xxxl39Fo3SFKyblBxwoD3AV8FZgMXlotZkbQQWAjQ2NjYo6wjugLW1/lcsZMdPMYqn3gv1AezG6b1cg9M4kpWrmul08wXFc4QkuZKulfS0/G9ly+1pOPiwn5bJV1aVPYRSY9IWiHpUUmfGrnWDz/FWQLLLSJcqu6cmdNYdsHRLLvgaGpT6xckz8uq+Lys9uelTyRNkXSzpFWSnpT0nj7qnhXrrZZ0uaSaovJJkh6XtHz4W+44g8PMfmpm+wFzgdMl7Vum3tVmNs/M5jU09DB8dWcF9IGpkyGmFa1jlf7vdLKLK1Z9UElciVmYlXcyQSU+/2uAjwGLSpRVJR5grJJ2h50dk1YMpm7x2nDQ7dvjsVf9cj6wycz2Ad4LXCupVyckaS/gi8ChhGDrOcBpRdW+Atw3vM11nJJUtG5QGjNrAh4Ayk4mlCNJXuExVk6WmDKh22JVI6jxiYFc4L1QH1QaV9JlwW3Q40nGLgPw+V9lZisoWm09llUlHmCsksj76q8eX0haMZi6xWvDFeOxV31yMlHhjxnUlgPvLlHvROC2uKBlF3BNPBYASYcTlK3vD3uLHaeIAawb9ObU5xnA0cCA01e3e/IKJ4OkXQE9I2B+8F+yApJB5JyZvV0Dk80u65ng4r7VLRx72T2+yPDYoZfPP5D4/FeMpPdJehx4Flg0lDUs8kryvPTl1uAutGVpJMhWQhOlZbRsPUlTgW8BH+/vYpIWRtfX5c3Nzf1Vd5yBcA7wSUlPA5+M20haKmlerLMwuquuAH4NXG5mdw70Qh1diWLlM/5OdkinW/f4qvzgitUASLs/zZk5jd9ecDQ1JQaPK9e1cso19xXisDyjYH6oJB7AB6uB4jisNBYnIsbbxIOkP0laX+ZV2/8ZKmIRweX1hf4q9hW34jhDwcyeNLNDzGxufH8q7j8+LsaKmZ1rZvuZ2UFmdqCZfWcw19rWkaxj5UMaJzvU1dYwqT7IrMcH5gfPCjgASmYObJjaa+HUcqxc18rfXbaMri48O9rIU/D5jxmq+vX57wsza5KUxAM8VVR2NXA1wLx583LjKjhQkoWFk2yA7Z1dNL3S1uNZSU881NeKjk6jrlZ0dlkhditPz4iZHdxXuaQmYE+6M6c1AneXqJrUI1UvkeXDgOMlXQRMAnaS9IiZ5SYe0HHSJBarCa5YORlj2sQ6trRv8zWscoT3QkNkoAuntneaW7FGgUp9/vuiWvEA44XiOKwbPnpIweJbivZOw+J7l41bd8FbgLMBYtbK+cAdJer9BDhBUkPMBngW8GMAMzvAzGaZ2SzgFOBRV6qcPFPICuiDUydjJAks3GKVH9xiNUSSwWNTSxtnLnmQlesGliEwPVuf11n6McQ5wJI4k78BOAOCzz9wkZktl3QY8CNg+1CkU4AzzeyXhHiA44B2QnjdoOIBxitpi++xl93Tr6XXYgbBZ9Zv5ozF9/PCxtfHw/OxCLhe0iqgE1hoZq8BSPoS8KKZXWlmayR9me6sf3cCN45Kix1nlPGsgE5WSRJYeIxVfnDFqkoUK1iJ+9OX378/X7j9MdY0b6amJixkWGosmfwxJIrWnJm5H0COOGb2JHBIif3Hpz7/Hti9zPHnDl/rxheJm2B/ExGdZhx96bLCdt4nIsxsM3BSmbKLiravovSSAek6y4B5fdVxnKzTnRXQB6dOtkjWsvKsgPnBFasqUyoOK9keiFVr5bpWjvnGMjq78h1z4oxPiiciVq9rpTYVY5VMNJQjKV/d3MoZ191PfW1NYTLDnxHHGV90uMXKyShuscofrliNIAN1G+yIflLF1qzxEOTvjA9KTUQAzL5wKZ3Wf96PLoO1LW1IwXUwicsqdU7HcfLJtiTGymf9nYyRKFYeY5UfXLEaBcrN1vc3S5+Q1EsrXJ5t0MkT6Wybgn6tWIkOlsRlOY4zfkgsVhPqfHDqZItkLSu3WOUHV6xGkeLZ+nR8Vk1NsFhVMGkP9LZq1dUEa1ZtfHfrlpMlilO1L14wH6CiiQjDmH3hUp9kcJxxQrtbrJyM4q6A+cMVqzFEWtEarDUrIXEjLOVOeMw3ltHVZdS6suWMUcq5CKb3lXMXDCJvrB6gW2CPZ65GdJo/G46TBbqTV7hi5WSLaYkroCdeyQ2uWI1RylmzioP8E6tUuWyDpUiUra4SsVuuaDlZIe0uWCOY3TCNVc2tBStvl8Hqda0htXt8btLyDXDGdffz3Cuvs3fDVLa0d/LchtfDsV09n409p0/h+x89xJ8JxxmDdKdb98Gpky26LVY+KZAXXLHKCOVm8GFg2Qb7otidcPq0CdTX1PDypi0lXQrTqeTd7coZaUq5CxY/B11Q2E4mEpIEFxvatrG+dRuk6pQjecY8KYbjjD063GLlZBRPXpE/XLHKAf2lru5l3aowdqslDjqhtEvhKdfcVyhfua6Voy69GzN6XLNUG3bbaTK1UsFS4AqZMxhKTTYsXjCfM667n7UtbWWPM+tfkep1DJ4Uw3HGIk0tbXzvD88A8MMHnuUD8/bw/xMnM2zZ1gHAQ89u4NjL7vHxUA5wxSpH9GXVShhq7FZfRN2rV9bC4vfnXnm9cMxA42Acpy8ap09h2QVHs/eFPy/I42CoL3o2ahRcDx3HGVsE63M7ABs2t/v/iZMprvvD2sJnHw/lA1esxhn9xW5VU9GqhC5Pj+0MA7MbprFqXWuPuMNiZakUSaxW2gJcnJnQcZyxw5rmzYXn3C3LTtZ4edOWwmcfD+UDV6zGOX2lfN9j58mFfWnXwlKD0/rayl0M07glwBkOSsVfNU6fEhJZFCW8KJfavRILsOM4o8veDVMLSWvk/ydOxkgnXfLxUD4YsmIlaS6wBJgOtABnmNnKojq1wLeBdxEmlb5mZtfGso8A5xLizGuBa8zs20NtlzM4BuJO2NcaQ33FWDXuHPyH0zFWjlNNyslxOYXLFSjHySblJkYcJwu4/OaPalisrgSuMLMbJZ0GXAUcU1TnQ8A+wByCAvawpF+Z2VrgJ8D1ZmaStgMek7TMzB6pQtucYaCSNYYcZyziSpTj5At/pp0s4/KbP4aUm1TSTOBg4Ka46ybgYEkNRVVPJliiusysGbgNOAnAzDaZFRzIpgD1UPGSTI7jOI7jOI7jOKPOUBd92AN4wcw6AeL7i3F/mkbg2dR2U7qOpPdJejzWWWRmjxZfSNJCScslLW9ubh5isx3HcRzHcRzHcarHmFhNz8wVpVEcAAAgAElEQVR+amb7AXOB0yXtW6LO1WY2z8zmNTQUG8Qcx3Ecx3Ecx3FGj6EqVs8Bu8XkFEmSil3j/jRNwJ6p7cYSdTCzJuAB4D1DbJfjOI7jOI7jOM6IIRtofuziE0jLgGtTySvONLOji+p8GDgVeDcxeQVwuJk9I+nNZvZErDcD+APwSTO7s49rNtPTtTBhBrB+SDc0snh7e7OnmeXGJOmyOmq4rA6QHMlqJeTxnqD8fY0HWc3ab+rtLY3L6tjD29ubsnJaDcXqTYR06zsBGwjp1p+StBS4yMyWR0vW5cBx8bCvm9nV8fhvxv3tgAhK2ncG2ZblZjZvSDc0gnh7xy9Z+y69veOXPH6XebwnyO99VULW7t3bO37J2nfp7R0YQ063bmZPAoeU2H986nMn8PEyx5871DY4juM4juM4juOMJmMieYXjOI7jOI7jOE6WyZtidfVoN2CAeHvHL1n7Lr2945c8fpd5vCfI731VQtbu3ds7fsnad+ntHQBDjrFyHMdxHMdxHMcZ7+TNYuU4juM4juM4jjPi5EKxkjRX0r2Sno7vc0a7TWkkTZe0VNJTkh6VdKukhlj2N5L+HNt+p6SZo93eBElflGSS9o/bY7atWcFldXhwWR08kqZIulnSKklPSiq7jqCks2K91ZIul1QT9x8lqU3Sivi6f+TuoEf7+n2+JNVKuiLewypJH6ukbDSpwn1dLGld6ve5YmTvYHgZy/1qVvtU8H51OHBZHR7GlKyaWeZfwG+A0+Ln04DfjHabitq3M3BUansRsJig2K4CDov7/w24brTbG9tyMPALYC2w/1hua5ZeLqvD0maX1aF9fxcB18TPc4CXgGkl6u0FPA80xO/4l4TlNQCOApaPgXvp9/kCzohtr4n38jwwq7+yjN/XxcClo30fo/n9jGLbMtenxvZ4vzo836vLavXbPaZkddS/kCp8oTOBjUBt3K6N2w2j3bY+2vxPwK+A+cBjqf0zgNYx0L6JwL3ArJSgjsm2Zunlsjos7XNZHfp3+DgwL7X9M+CkEvUuAC5PbZ8I/Dx+PopRVqwqfb6AnwMnprYvBy7oryzj93UxOVWsstavjvU+NbbF+9Xh+V5dVqvfxjEnq3lwBdwDeMHCWlnE9xfj/jFHdJ35OPBToJHUitxmth6okbTzKDUv4UvAjWa2NrVvrLY1S7isVh+X1aHT4/sCmigtk/3VmyvpT5Lul7Sg+s3sl0qfr77uo9LvYiSpxn0BnCLpkegWc+hwNniEyUy/mpE+FbxfHS5cVqvPmJPVPChWWeM7QCthNnHMEf9w5wHfHe22OKOOy2oOiMrO+jKv2ipd5k/AHmZ2MHAKcJGkd1Tp3M7QuRLYy8wOILj33C5p+ii3aTwypvtU8H7VKeCyOkjyoFg9B+yWDBDi+65x/5hC0qWEGIaTzayLMKO4Z6p8BtBlZq+MUhMBjgTeDDwjaS2wO8Fvfx/GXluzhstqdXFZrQAzO9jMZpR5dVL02xJm+0rJZNl6ZrbJzF6Nn58BbgP+djjupw8qfb76ut9Kv4uRZMj3ZWYvmVl7/HxX3L//MLd7pMhEv5qRPhW8Xx1OXFary5iU1cwrVma2DlgBnBp3nQo8bGbNo9eq3ki6BHgrcIKZbY27HwImSzosbp8D3DIa7Usws6+Z2a5mNsvMZhECoN9JmOUcU23NGi6r1cVltWrcApwNEDNUzQfuKFHvJ8AJkhqim8hZwI/jcbtIUvy8M3AcQdZHjAE8X7cAZ0mqiRmvTgD+p4KyUaEa9yVpt6SSpIMI8QhPDXPTR4Qs9KtZ6VPB+9XhxGW1uoxZWR2pYK7hfAFvAu4Hno7v+452m4ratx9ghD+yFfH1v7Hs7cCjwErgLuANo93eoravBfbPQluz8HJZHda2u6wO7nubSvjTWRV/9/enyr4EnJPaPhtYHV//TXcQ9r8QkmCsAB5jlBI+lHu+gKXEBB2EgPH/Tt3HwtTxZctG+Tca6n0tib/Ln4EHgeNH+55G4vsZC68s96mxjd6vVvf7dFkdvvaPCVlVbIDjOI7jOI7jOI4zSDLvCug4juM4juM4jjPauGLlOI7jOI7jOI4zRFyxchzHcRzHcRzHGSKuWDmO4ziO4ziO4wwRV6wcx3Ecx3Ecx3GGiCtWjuM4juM4juM4Q8QVK8dxHMdxHMdxnCHiipXjOI7jOI7jOM4QccXKcRzHcRzHcRxniLhi5TiO4ziO4ziOM0RcsXIcx3Ecx3Ecxxkirlg5juM4juM4juMMEVesHMdxHMdxHMdxhogrVqOEpGWSLh7tdjj5olpyJekoSdZPnV9I+txQr+Xkk2rIoqSLJS2rTov6vM7jkj6U2n6rpBWSXpN0vaQPSXp8JNvgOI7jZA9XrMYwkg6UdLOklyRtltQkaamkf0jVGdDAo9xgJw4erq9Kw50xTRw0/lTSK5LaJD0h6XOS6gdyHjN7t5ldUqU2fVjS2mqcy8kOkg6Q9OPYx7VKWiPpBkn7j2Q7zGw/M/tBatdXgWVmtp2ZfdjMfmBm+1XjWpJmSTJJs/ppg+M4jpMxXLEao0j6O+A+4AXgb4DtgH2B7wD/OIpNczKMpGOA3wP/B/wVsCNwNvBh4DZJ3ic4I4Kko4D7CX3cIYQ+bh7wB+D9o9cyAPYGVoxyG5wcIOlrUZE+rUTZMknb4qTCJkmPSTqzRL1d43keiRNiL0j6maR/KnPNT8eJ2DZJf5B0YD9tXCtpS2xH8nrP4O/aGWnyKmeS/lrSH+M1miR9qp/6O0taLOnF6HFwu6TdU+XJxNbmonbs0Nd5B4IPogaBpE9IerJo33bxxzkmbn9Z0qq479m4PZDv+0rgJjM7z8zWmlmXmb1uZr8ws9P7aNvOkq6LQrVO0k/SQuWMXUZIrv4b+ImZfdbMXjKzbWb2W8JA9jjgA0XX/6CkZyRtlHSrpIZUWQ/rp6TdJP0wdsbrJN1UVH+KpK/G9r8maaWkf5J0OEHeG1Od3AmpDvC02NG/FjvYN6XOWSvpMwpWt1clPaQwKZGUHyjpntj+DbF831h2tKTl8biW+Mew0wC+y9wyQrJ4FfBjMzvXzJ61wCtmdpWZfaVMu/5ZwWXutShnV0iakir/QCzfJGm9pF+lyv5F0up47MtKWegV/vA/HOWplaBYXRnv7Z9UZFGVVCfpgih3r8X7/+dYtoukn8dnYJOkB5PvLJK4FD4ez/+NdBtS1zgsyvvG+D1/VlJtqtzi7/THeJ5HJL19AN+/M8xImgB8FGgBzilT7RIzmwbsBHwNuFZh0iE5x3uAPwJtwEnAG4DZwH8Cpyt4H0xO1T8FuIjQl+8M3AncIWm7fpp7jplNS71+NuAbdkaFvMqZpO2BO4Bfxmt8ALhY0ol9nH8JMJMwcbxLvJ//V+K/ab+idrzaT7srx8z8NcAXYZb/deBvU/s+BqwGFLdPA3YHBMwH1gNnpeovAy4uc/65gAHvqKAtFxNcVpLtpQQhnEGYAf4+8Cegtq/rAtcD14/2dzueX6MtVwRLwY3x81Gx7u2EjninKFu/KHUtYCLwJPB1YCowLcreXan6NxGssHPj9h7AAfHzh4G1Re2ZFdvwS0InPwm4Ffh1qs7FUb7nEiaK/gFoBWan7ukioC6+DgLeEMteAD4Sv8sJwKHA1NGWg7HwGgFZnNOXLBb9vstS2/8I7BOv+SZgJfCVWDYF2AYcE7cnpT7PIfzB7h+3pwFHpM67FvhwH9s95JPgKvg08NbYlgbgbbFs9yiHU6Nc/RvwKjCjSK5nFd1r4ZrAnrG95wD1wAFAE3Beqr5F2Z8dZfs7wOrRlp28vqI8/xfwE+A1YA1wLHA08CiwidBfbp865oPxOfr7+HvtX+KcFxftWw98Jn4+MMr4Xn206xLgW0Xn/Hpquwb4C3BGH+foIe/+cjkbC3JG6HdfBGpS+74O/KZM/alAFzAvtW+f+J0cHrdnUaL/rebLLVaDwMw2EoQ+bUo9E7jO4i9nZjea2fMWeBD4AfCOCi+RzPK/kOyIs5cb4+z6Fkl7Fh8kaRfg3cC5ZrbezF4D/oXw0Mwf4G06I8xoyFURzxNmetJ81sw2mNkG4DPAu6KcFfP3hIHtZ81ss5m1AucD75C0e7RcnUKYrXo63stzZvZIBe3+dzN72cy2ANcBb0uVnQtcYGZPW7Dq/i/wO+DUWL4NaAT2NLMOM1thZi+nymYDu1qw3N1rZpsraE/uGQFZTOSsnCyWa9etZrYqXvNJ4LtF12wH3ixphpltMbPfxP0dBAVoP0nbm1mrBUvtgJEkQr/6r2b2UGxLs5k9ENv4vJn9b3wOtpnZfxD+yAfSB38QeMzMrjSz9vic/CewsKjepWa22sw6CBbAvSVNH8x9ORVxGnApYeLhR4TJo08ARwJ7Edz1z03V/zjBQ+DnBPfrj5c7cbSCnk6YmX8w7v4K8Ekze0YhNvbeaF2/QyEu+nTgC4R+OfndDwSWJ+c1sy6CAn5QP/f2nwruX49J+lcNMObWqSrjUs4UPGQ2puoeCDwcz52wvI9rqOg9/fmvi+r+IXo1/FGpvAXVwBWrwXMt8AFJ0yT9FeFP83tJoaSPK2SV2hAF5Wx6D1rL0Rzfd0t2mNnvzWxHgqBNpKfgJOwR39ekjns1nq8x7monzIAWUx/LnNFlROWqiN2BdUX7ninxeQ96MwfYFdgQJwA2Ak8BWwmyNyvWe6rCtqZ5MfW5lWBtQNIbgO2B/02uGa97BN33+GHCoPY3kp6T9E1JU2PZ+wguXw8puCV+Me1q5QyrLCZyVk4WSyLpREn3xT/EVwkDgpkAZtYGvIugaD0VXeP+JZY9Q1DsPwI0Sbpf0gdKX6VfZhBksKQsq9sde210BdxIkNNKvxsIz9iaon2r6O7HE4qfDQieCs7w8D9xAqYTuJFgSb/MggtrC8GqPw9AIQHLYYTniPh+Wqr/SfhslJGXgE8TZvR/K2kiwV3pjqjM3wp8iyBHnwPeQ/BE6SRYMubG820PbCy6RiKD5VhAmGSaSVDezwH+o9Ivxak641LOzOyHcZybMKBrxAnd3wD/Lmm6QtzUVwhjgKRfXA+8naCg7gFcDtwk6fg+2j0gXLEaPPcQzJ4nE3xb7zCzFwGin/u3gE8BDVFQrqK0MtSLOKO/mjBrORCei+97JTuij+oMghsJhMHxnBLHzonXdEaX4ZarVcAZxWUKcUdvA35eVDSrxOfnS5z+JWCNme1Y9JpkZn8kuABAd6dcTFeZ/X2xEdgCvKvomlPN7OMAFmJ3zjKzPQmuFMcB/xrLHjWzD5rZGwk+5Z+gxHczjhlOWVxJcKWrOL24QqzozYSZ3N3MbAfg8+lrmtnvzOwfCH3ep4BLJR0dy243s3fFsm8Q/kxnV3r9FOsJSkw5Wf4aoQ/+W2AHghvtplQ7K5H150j145HZdPfjzujwl9TntjL7kgHcx4GVZrYsbt9AmBQtlvmvxX5rhpm91cxuiPunE/pVCDI7xcxuNrNOM/sTwRUrYc9U3U0EuUuzY9xfEjO7x8xei1b9PxLcp8vGcjvDjsvZIK9BsPa9AjxCiGf9A6G/Xh/b0BqV1m0W8hb8kKC89kr6MVhcsRok0R3mOsIs7el0zxZAEIROgoWgUyE4f6Drk3wC+KCkb0jaU1JNnFk4rI82/YUQ6HeZpBmSphH87h+n2+S7BHi/QkD2BEmTFYKu9yMMWpxRZITk6gOSLpH0Bkn1kg4j+Gz/GvhxUf2vStpJIanDIuDOZHBdxK3AJIX0/zsASJop6eR4X82EGKvvSpoTy3eXdEA8/iWgQQNIHmFmWwlJLxZJerMCkyUdIWluvMaH43VE6Iw7CN/dBEkfUXdyjVcJ321npdfPOyMgi2cDJ0taJKkx/n47SjpTpddH247wn7XezLZG2fnnpFDSGyWdJGnH2PaNhJnKTkn7Sjpe0rToNvcqQdEZ8O8dz/0d4OsKGaskqUFS4uq3AyHeYQMhzus/iFbWSDNBudq3j8vcBLxF0sL4jO5PmBC4to9jnDFC/O89HdhDYSmBlwj/w7WUTy5QTAvwxvh5PbBZ0skKCVYOIFjmp0j6LPBStMoC/JlozYhtqSG4QQ0ky2UXFU6SOKPHOJCzPwN/rZ6JJ97a1zUsJOU6zcx2M7PdCRas7eipIA60HQPCFauhsQQ4mPDnnc5s8ktgMUFTfoUwczqg9UnM7E6CubIReIAQxLiSMHg5AXi2zKGnAS8TTLbPEATqvdGMi5n9ATgRuIAwmG0iBIS/I/XAOKPLcMrVXcDhwFsIySY2xXPeCLwvkZMUtxD8ptcSlJKSs0sW4vkOJcyyPyppEyHD0BGpamfFtv9SIfPa3YTAUgid38+BVQoufe+r8JbOJyiDtxAG0muBC+l2dz2a8Py0EjrpewkKIoTn4HFJmwnWmevj9+B0M5yyuIwgM3sS/OZfAx4myOdtJeo/QUgEcXOUr0sJs7MJIgwm1kT5+h/gcxZiqSYQrFsvxGO/AZxuZmsH0uYUFxHk5Uex3cvpHmR8gaBcNRPcBV8mZeU1s9cJLjZLoqz/Z4l7XUtwa/wIYbBzO3A18M1BttcZWT5Ed7Kc9OvvCQPFQ/o7QZw4Wi3p76Iy/0+EuJoXCVbR2+lObnJy6tArgbMkvS1OxiZW3f8tdR1Jc+Jk1KQ4gfs24EsE5d4Z2+Rdzm6N9/d5SRPjMWcRshuXJE6izYgTXvsR3NcXm9lTsfxwSX+lEGs2IU7+nt5POwaGjYEsKP7yl7+y9yIkifjcaLfDX/7yl7+G+0VRZjVKZBcjWCeXESYIvlvmPL8DvlfqnCXqvo3gMrtHmfK6MvvPJbiTvk6Y4DowVdZImGg6PHWNPxMmCDYBTxAU//rR/s7H42s8yxlBUWwtusZfEyZEX4/X+lRR+S+AK1PbHyUkRWojTLReRMyKHcuT7LabCZOC9wEnVfM3TNLmOo7jVIxC7N5ThE7ultFuj+M4Th5RWJz1GwRr5W2EweVOwPEEC+4JFqy5jjNoXM6qhytWjuMMCEmHEmL57gBOMzPPJuk4jjNMKCyvch4h+c6uhBn/3wH/ZWb3j2bbnPzgclYdXLFyHMdxHMdxHMcZIp68wnEcx3Ecx3EcZ4i4YuU4juM4juPkGklzJd0r6en43mtNz7hkyDqFxc9XSLoiVXa9pOdTZZ8f2TtwskDdaDdgMMyYMcNmzZo12s1whoGHHnpovZk19F8zG7is5heXVScruKw6WWGYZfVK4Aozu1HSaYRFzY8pUe8GMzu/zDm+ZmaXV3pBl9V80pecZlKxmjVrFsuXLx/tZjjDgKRy63NlEpfV/OKy6mQFl1UnKwyXrEqaSViT79i46ybgckkNFhawHxZcVvNJX3LqroCO4ziO4wyKCt2r3ijpdkmPSHoiWguSsrKuV45TRfYAXjCzToD4/mLcX8wpUVbvjFlw05wn6VFJt0l6c6kLSVooabmk5c3Nw6azOWMUV6wcx3EcxxksiXvVXOAKgntVMZcBy83sAOAI4BJJ6QHtDWZ2UHz98/A32XHKciWwV5TVRcDtkqbHss8D+5jZW4BbgTsk1RafwMyuNrN5ZjavoSE3HrhOhbhi5TiO4zjOgEm5V90Ud90EHCypeDR5IGHdO6Lb1QrgAyPVTschLHi7W6IIxfdd4/4CZvZSsjajmd0Vy/eP2y+YWVf8fAMwDdh9xO7AyQSZjLEqpqmljTOXPMia5s3s3TCVxQvm0zh9ymg3y3H6xWXXcZwM08u9SlLiXpX2gXqI4F61HJgFvB1Ymyo/RdJxwEvAF83s3uILSVoILARobGys/p1UiaH06ZUc6/8Zg8PM1klaAZwK3BjfHy6Or5K0m5m9ED8fRJDXp0qUvRPoBF4YsZsYwwyX7CbHrF7XSm2t6OwyZjdMq/j8wIg/L5lcIHjevHmWDgY8ctHdPNvSBkCNYHbDNO4678jRap4zBCQ9ZGbzRrsd1aJYVos59rJ7WLWuFcNlN2uMN1l1sstwyaqktxLc+PZL7fs/4DQz+1NqXwPwTeAtQBPQRlDIzpP0RqDFzNolHQv8AHizmbWUu+5IyGpfg8CkbNW6VmprREeXUVcjusyQwuAvzZyZ0/jy+/fnC7c/VnLQt2pdKzU1vY8DqI3n3X3HydTWiLVxrJOmvlZ0dBp1ceDZuHNo53OvvM7eDVML104Gp+m6xYPUSu67kkHuYBnOflXSm4AlwE7ABuAMM3tK0lLgIjNbLmkJ8FaC0rSNoOgvjcf/CngD0AVsAi4ws/v6umZe+9ViOWnv7OLZlrY+xzLp8U5CXY3oTMl3U0sbNfGZqi3zTEB8LlJ1kuewmBpB8e7kmHLPTVNLW7/y3Zec5kKx2vvCn/f44molVn/1+FFomTNUxttgdfaFS+lMPYMuu9lhvMmqk12GUbGaCTwNTI/WqlqgBZjTV6a1OJC91cyuLdVW4Dwzu6fc8YOV1fRgcI+dJwM9lY/P3voIz7a0UVcj2otGYzUCM6irFe2d1Rk3KZ5ztEkGn3VlBqfJIFYlBqkJdXGwmgyU37DdRDoNml/bWjhvTWpAW27Q6v3q2KGUIp0oH6UU/DS1Eneff1SP46v13IwGc2b2lNW+5DQXMVbJDw2hg9i7YeootsZxKictq3LZdRwnQ5jZOkK81KlxVzn3qumS6uLnYwiWqx/G7d1S9Xq4XlWbM5c8yKrmVjrNWNvSxtqWNjrNWN3cymmL72dtnHEvVqogKBQGVR0cjgWlCrqVpVJKFUBnl2GUV6qSY5PvrsvgL5u2su61rYV9Fs8D4TvsMljV3MqZSx6s5q04A2Dly69x+Nd/w+wLl3LsZffQFJWlppY2jr50GUcsupuV61rpovs3S56b/njDDhP54DX39Tg+ywxEVnMRY/XNkw/iH777R4DCDIjjZIHFC+ZzxKK7AWjcaYrLruM4WeMcYImki4juVVCwSl1kZsuBtwHfltQJrAfea2bJ6OyS6FKYuF6dbmYvDUdD1zRvLqnMdBl0VUnLEdW1auUZs/CbOCNHU0sbH/7eAzyzfnMPl7zVza2ccd39GBRCa4bCixu3DPkcxSSWzsTtr5JHtlrP40BkNReK1d4zpgGw/aQ6j09xMsVuO00ufP7v097qQciO42QKM3sSOKTE/uNTn38B9FrfKpYtGL7W9WTP6VNYs37gA/n62vIDueI4jfTk7plLHmTlutay500GfZ2d1iOmozgmaqBxU325axW3dzCD1KS9Qx2suodRdRhIUogzrru/pFwk1qihUKPgNtqXXNQoeJnV19aUlO8kvqmSOMByMYN9xTMWH9NXjFX6PgYiq7lQrCbWB4/GrR1do9wSxxkY21Iy297p8us4jjNcvO+gXfnWr1YCMGt638pHKSVpoEkb7jrvyF6D3lKDvlLnqGSSuL86A8nUVnxvpZS7gQxwyw2UyymhzuBJEqAYwfJ05pIHe8lGU0tbWaWqEur7UfATGVvd3HsioQaqmuykcfqUfmW/VPlADS/lsgz2Ry4Uqwm1QbHa1tmFxaw8jpMFtnZ0Fj67YuU4jlM9igdGNTVhbPDtU/+a9x24KxAyla1ubqXL+s7MOlhvmFKDwJHyrKlkANpXnaEc64wca5q73fq6ilzWmlra+OC19/H8htd7HVeJm1xx0oZSpGWg0ucpCwxWvnORvKKmRtTXCrPsB8g544u0lXWbK1aO4zhVI3HF6zRj5bpWnnrpNWoEb37jdoU6ixfMZ3bDNGolt6A4mWTGdhN6bO/dMJWmljbecVlIQFFKqQLYZ+Y0fn3eUZSyRcyZOY3fXnA0d5135ICsS/485cRiBTCxrpb2zg62dnQyoS4X+qIzDtjSnrZY+aSA4zhOtSgVbN5l8Ikf/KkwE+1WFyfLmBnTJtbzMlsL+7558oF85PoHWF0m2UKxJWmfhmlVW0/Tn6ccKVYT6mpga8+YFccZ66QtVu0uu47jOFVjzxlTSipXnonOyTJNLW0s+N4DrF2/uZB8pLZG7LfL9jzywqusXNfap4wXW5IWL5g/qFgipzS5Uawm1nkCCyd7bG335BWO4zjDwSUnvIVTrrmvxz7PROdknZOvvpe/vBrSmSdrj3V1GX95Nbj83XT/cyWPKxcv5Vam6uKKleOMIH9YtZ5P3fQwG9q2MbthGp9+R3cGYo+xchzHqR5TJtYCYUAJ+Iy8k2maWto46ao/8vKmrb3KDGjZvA2AB9a+AoAUElRUIxOfUzm5UaySuCp3Bcw/kuYCS4DpQAtwhpmtLKpzHHAJ8BbgO2Z2fqrsI8C5QBdQC1xjZt+OZTcAB6ROdQBwgpn9VNLFwCeAF2PZH8zsnwfS9gtu+XOh81vd3MolS58olHmMleM4TvXY2NYOwBu2n8SNH+u11JbjZIqTrvwjL7/WW6mC7tioZ19p6zEOznJWvqySmywPE+vCzFQ6fbWTW64ErjCzucAVwFUl6qwBPgYsKlH2E+BAMzsIeDvwGUkHAJjZGWZ2UCxbAGwAfpk69oakfKBKFcBLm7pXI+8yCuZ8cFdApxtJcyXdK+np+N5rcVVJtZKukLRa0ipJHytRZ19JbZIuHZmWO87YYUNbmMTaYUr9KLfEcQZPU0sbh1zyq5JKVX2tCkrV4gXze4wjzDyecDRwi5WTKSTNBA4Gjo27bgIul9RgZs1JPTNbFeufUHwOM9uU2pwC1AOlzEVnAj8ws9JTRINgtx0n81xMfVqjMJOaKFcuu06KZPLgRkmnESYPjimq8yFgH2AOwXr7sKRfmdlaCIpXPO62EWu144whXn09WKx2csXKyTAnX31vL/e/ctn7ZjdMZfW6zYUMfx5POPLkyGLlMVbjhD2AF8ysEyC+vxj3V4yk90l6HHgWWGRmjxaVTwA+CFxXdOgpkh6RdKekQwfa+H9//36Fz7MbpvHRw2YVtt1i5UCPyYOb4q6bgIMlNRRVPZngxtoVJxVuA05KlX8W+Bnw9DA32XHGJIkr4I6TJ/RT0zonl5EAACAASURBVHHGJn9+bmMPz5aEcmtEXbfgbewzc3yvIzXa5MZi1a1YuSug0z9m9lPgp5IagdskLTWzp1JVTgCazGxFat+VwFfMrF3SscDtkt5sZi3pc0taCCwEaGxs7HHdvWeEIOrGnUMWnh890FQo8+QVTqTX5IGkZPKgOVWvkTAxkNAU6yDpQOCdwNHAF8pdqC9ZdZysk7gC7ugWKydjNLW0ccZ197O2pa3H/v7WmfIMf6NPbixW7go4bngO2C26OSXuTrvG/QPGzJqAB4D3FBV9lCJrlZm9ZGbt8fNd8Zr7lzjn1WY2z8zmNTT0NDJMnhBiAV+PCwP3WCC4w5NXOENHUj1wNXBOopyVoy9ZdZys82pisZriFqvxToVxqxdLWidpRXxdkSqbIunmGM/6pKTiMUNVOXPJgz2UqvpauRUqI+TIYpUkr3DFKs+Y2TpJK4BTgRvj+8Pp+Kr+iFamJ+LnGYRZ/VtT5bsDh8dzp4/bzcxeiJ8PAmYBaStXv0yqD3K6ZVsY7/ZYINgtVk6gMHkQrVXlJg+agD2BB+N2YsHaBZgNLJUEsCMgSdub2cKRuAHHGQsULFaT3WLlVBS3CiFB1fkl9p8PbDKzfaJS9jtJ+5hZ63A0tjjpRFcXrP7q8cNxKafK5MZi5TFW44pzgE9Kehr4ZNxG0lJJ8+LnwyQ9D5wHnC3peUnvjMcvlPR4VNB+DVxuZnemzr8A+H9mtqHoupdIekzSn4FrgNPN7KWBNHxyfU+LlStWTjFmtg5IJg+g/OTBLcBZkmpi/NUJwP+YWZOZzTCzWWY2C/gWIRbLlSpnXLHx9cRi5YrVeGYAcat9cTIxA3Fc3mU58O5qtjNNOumEPAlFpqjIYlXhukG1wLeBdxEyrH3NzK6NZRdTZv0fSVOA7wFvBTqA883sZwO9kQmuWI0bzOxJoNeiJGZ2fOrz74Hdyxx/bj/n/0qZ/QsG1tLe1NeK2hrR0WW0d3b1iAn0GCsnxTnAEkkXEVL+nwFh8gC4yMyWA98nPAdJX/wlM3tmNBrrOGMRdwV0IpXGrUJIUHUc8BLwRTO7N+4vG9NaTDViV7/7oYM59pu/BconqnDGJpW6Ag459S/DbF4tuAK2e/IKZ+wiicn1tbRu7WBLeydb2t1i5fSmwsmDTuDjFZzr4qo2znHGKE0tbZy55EHWNG9m74aprG8NKardYuVUSEUJqvrDzK4mxLkyb968QQVP19UGY8HuO03mV56MIlP06wpYxdS/5aiKebWQvMIHp84YZ1LKHTBtsfLkFY7jZIkKEwK8UdLtcZmKJ+LkbFLW7yLXA2HB9x5g5bpWOs1Y3dzKpi0dgMdYOZUlveonQVUS05rQWHx8NXkhrne5246Th+sSzjBRSYxVpesG9WcmLbf+T8Xm1b4oxFi1u2LljG0mTwiyumVbVw95dYuV4zgZI/FmmQtcQZwkLeIyYLmZHQAcQYhVTf7j054uhwIXS5o12MY829Id8N8V56m2m1hXmP13xieVxq1K2i31uThB1S3A2bFsDjAfuGO42vzCxpAR0BWr7DFSvc2VwF6xY11EMK9OH8gJJC2UtFzS8ubm3gngJtZ7jJWTDSbVpS1W3fLq1lbHcbLCALxZDiQOQONAdgXwgVg2WE+XkjRsNzHVvvC+g7sBOoF+k17Rd4KqRcCOklYRFl5faGavDVdjX9gYFgXebSdXrLJGJYpVpesGlTWTVsO82t96KxNqfR0rJxuk17Lq4QroipXjONmhUm+WhwgeK5K0F/B2uv/zB5QQoK/JVYAFh84qfE5m+nfyxBUOIW7VzA4xs7nx/am4//iYDAgzW2Bm+5vZgWY238yWpo7fbGYnmdk+Zravmd0+nO11V8Ds0q9iNdTUvzAy5tWJ9ck6Vp68whnbFGKsthUnr/AYK8dxcsdngDcQxhHfJixx0THQk1SymHXaOrXwiL0BT1zhZIOmljaOveweZl+4lGMvu4fVzcEYtqsrVpmj0qyAQ039e4mktwKdwDZ6m1evj+bVTgZpXp3oFisnIyRrWW1xi5XjONmlooWs4yRsOmHFUuD/4ma5Ra4HRUdqcmpF00YAdvDEFU4GOHPJg6xa14oBq5tbqYm+rO4KmD0qUqyGmvq3r/V/zGwzQ/CpTvAYKycr9FSsUjFWLruO42QEM1sXF1k/FbiR8gkBpgOvmlmHpGOAtwAnxuLE0+VWwjItJwCHD7ZNHV0pxer5oFi5K6CTBdY0B6UKQuKVLgtbu+7gilXWyE2qnEJWQHcFdMY4PWKsPCug4zjZpZKEAG8DnpD0JPAl4L1m1hbLvg+sIXi63McQF7nuSPWha5pDhkB3BXSywB47Tyl8jnlXmD51QmG84GSHSl0BxzyFdax81t8Z46TXsdrSwxXQY6wcx8kOFXqz/IKQTr3U8RUtcl0paYtVwo5usXIywJfevx9nXBc8YifU1bC1o8vdADNKjixWSfIKV6ycsc3kVPIKt1g5juNUh85SipXHWDkZYOep3UsFJONYdwPMJrlRrCbUeYyVkw0mxXjAXjFWrlg5juMMmo4Sfai7AjpZ4PX23mEsbrHKJrlRrCa6K6CTESbX+zpWjuM41cZdAZ2s8vq23oqVp1rPJjlSrHwdKycbFJJXbOvq6QrY4TFWjuM4g6W0YuUWK2fsk1isatW979rfraGppa3MEc5YJTeKlSevcLJCd/KKjh7uf+4K6DiOM3g6SiQA8hgrJwtsiYpVMpYFeGnTFs5c8mC5Q5wxSm4Uq4keY+VkhMQV8NXX23vsb3fZdRzHGTSdXaEPfeP2kwr7fIFgJwskroBbUl4sZt3LBjjZwRUrxxlhElfAjW1BsaqPtn+3WDmO4wye9ugKuHsq6P/d//U7d6dyxjyJK+D2k+upie6ANYK9G6aOYqucwZAbxcpdAccPkuZKulfS0/G91xopko6TtFzSVkmXFpV9RNIjklZIelTSp1JlF0taF8tWSLoiVTZF0s2SVkl6UtJ7BtP+xGKVKFbbTQozqp68wnEcZ/B0RlfAVetaC/tWN7e6O5Uz5kkUq79/yy7MbphGrcTshmksXjB/lFvmDJTcLBDsySvGFVcCV5jZjZJOA64Cjimqswb4GHAiMKmo7CfA9WZmkrYDHpO0zMweieU3mNn5Ja57PrDJzPaJytzvJO1jZq0l6pZlUkGx2gYERUuCLgvrsNTWqK/DHcdxnBIkySte3dLtZt3l7lROBtgSXQFnbj+Ru847cpRb4wyF3FisEneq9k6jq0RmICcfSJoJHAzcFHfdBBwsqSFdz8xWmdkKoKP4HGa2ycwSIZkC1AOVCM3JBCUOM1sJLAfePdB7KLgCxhirSfU1TKgNj6JbrRzHcQZHR4yxmrndRHencjLFluhtlXi0ONklN4qVpO61rHxwmmf2AF4ws06A+P5i3F8xkt4n6XHgWWCRmT2aKj4lugreKenQ1P7GWD+haaDXhe4FgtviDNXEutqCYuWy6ziOMzgSi9XZR852dyqnF5WEEaTq7iupLR1KIOl6Sc+nQgU+X622JckrkolXJ7vkxhUQQgKLrR1hbaBJrvU7fWBmPwV+KqkRuE3SUjN7iuBm+BUza5d0LHC7pDebWUul55a0EFgI0NjY2Ku8eEZqUn0N9XU1sNUzAzqO4wyWjjgxtcv2k9ydyilFJWEESKqNZbeVOMfXzOzyajcsibHysWv2yY3FCmBCEmfV6XFWOeY5YLfY8SUd4K5x/4AxsybgAeA9cfslM2uPn++K590/Vm8C9kwd3ljqumZ2tZnNM7N5DQ0NxcW9FKuJdbU9XFkdp8IELbWSrpC0OiZU+Viq7AuSHo+W14ckvXNk78BxRp7OaLHyOFWnmErDCCKfBX4GPD1CzSsoVu4KmH1ypVgVUq63+6x/XjGzdcAK4NS461TgYTNrrvQckt6c+jwDOBp4NG7vlio7CJgFPBV33QKcHcvmAPOBOwZ6D5OKTP0T62uo9xgrpyfJzOpc4ApibF8RHwL2AeYAhwIXS5oVyx4A5pvZAcBHgZslTS5xDsfJDYkrYNKfOk6KisIIJB0IvBP4ZpnznBezCd+WHksMlSR5hStW2SdXvY+vZTVuOAf4pKSngU/GbSQtlTQvfj5M0vPAecDZ0S86mbVfGGfzVwC/Bi43sztj2SWSHpP0Z+Aa4HQzeymWLQJ2lLSKMJu10MxeG2jje1usajzGyikwgJnVk4FrzKwrTizcBpwEYGa/NLNk8Z5HAAHTh73xjjOKdHS6xcoZPJLqgauBcxIFrIjPA/uY2VuAW4E7Eu+ZovMsjMu9LG9urmzOt2Cx8hirzJOrGCtfy2p8YGZPAoeU2H986vPvgd3LHH9uH+de0EfZZuLAdSjU19ZQV6PC7Oqk+lq3WDlpes2sSkpmVtP/0pUmUzkDWG1mzxcX9BcP6DhZIskKWOeKldObQhhB7FNLhRHsAswGlkoC2BGQpO3NbKGZvZBUNLMbJH2TMM5I98OY2dUEBY158+ZV5N/vMVb5IV8Wq3pfy8rJBmmr1cS6GurrYoxVh8dYOdVD0pHAl+l2ne1Bf/GAjpMlEotVnbsCOkVUEkZgZk1mNsPMZpnZLOBbBK+AhdArVOCdQCdQULaGQpIVMMka7GSXXP2CE2vdYuVkg3ScVUhe4a6AToFKE7T0mUwlLhVwI3BCzHjpOFWnwkQrMyX9PCZTeULSdyXVxbKLJa1LpbC+YrBt6fDkFU7f9BtG0A9LYnzVn4F/A95nZr3WyhwMWzx5RW7IlSvgxHqPsXKyQS+LlbsCOhEzWxfj/04lKEblErTcApwl6VZC/NQJwOEAkuYDNwMnmtmfRqzxznikkhTWnwOeMLO/j3Esvwf+EfhxLL/BzM4fakM6C8krXLFyelNJGEHR/ouLtt8xPC2DLTHpmsdYZZ98Waw8eYWTEdLm/kn13QsEu2LlRCqZWf0+sAZYCdwHfMnMnoll3wUmA1elLAFvGdE7cHLPABKtGLCdpBpgIjCBKrlQpUn6T7dYOVnD063nh1xZrDx5hZMVelusknWsXHadihO0dAIfL3P8/OFrneMUqDTRypeBnwB/AaYSMrH+IVV+iqTjgJeAL5rZvcUXqiTRSmKxqqvJ1ZyxMw7w5BX5IVe9z8Q6T17hZIN055lex2qbJ69wHCd/nERI+78LsBtwhKQTY9mVwF5xzbVFwO2Sei0NUEmilSTGqs5dAZ0M0dllbOvoQur2vHKyS65+wQmevMLJCJOLk1fUuSug4ziZo9JEK58EfhDXXHsVuJ2wMDtm9pKZtcfPd8Vj9x9MYzzdupNF0okrYpp3J8PkSrHy5BVOVki7Ak6qr/EYK8dxMkclKawjzwDvApA0AXgH8FjcTqewPgiYBf+/vXsPr6uu8z3+/iZNrwGRNGXkUmpv6hGRwXYcRhR0KBzRQZ4ZHGAUOlIoOOfgUQaeZ9AROTBe5oDoM0MdLoIUcBgGdcDRKhcHis5waYHSggptCgSKTEMolDZtmux8zx/rt3ZWdvbeWUl2mr1WPq/nyZO912Xnt7JWVtbv9v0yoiiWBYVblwzS/Kp8ydUcq/7gFRoKKPVt4ByrRs2xEpGsOo8oDPUlwDaihNSY2SrgEndfC3weuMbMNgCNwP3A9WH/r5nZ+4hyAu0BznD3V0ZSkJ7iHCu1+kt29OewUsUqD3JVsVLwCsmKgXmsknOsdO2KSHakDLTSBiypsP/SWpWloDxWkkG7e5QcOE9ydRb7g1fo4VTq27RKwSsKCl4hIjIScY9/k6ICSoYoh1W+pLr7pMys3mhmK8yszcw2mdnZZbZ5h5l1mdmViWU3mdlLiVwrXxrpwUxWHivJiAFzrCY1Fq9dDQUUERmZYo+VogJKhmiOVb6kHQqYJrP6p4D5wAKgBXjCzO5z9+ehGC3oWuDOMp//DXe/egTlH2CKhgJKRiS7/KMeqzDHSteuiMiI9GqOlWSQcljly5A9VsPIrH4qcH0Ip9pBVIH6ZGL93wA/AZ4ddakrUB4ryYqpg4JXqMdKRGQ0egsKty7ZEwevUI9VPqQZCjgoszoQZ1ZPmg28kHjfHm9jZu8FTgC+VeFnXGBmG8zsTjN7V7kNzGy5ma01s7UdHaWRXCPxcKrXdu7hj7/5AHMv/ilLrlpNe2dXisMU2XumVQpeoTlWIiLD1tfnhA4rBa+QTCnmsdIcq1wY8xmeZtYEXAecF1fOSnwJmO/u7wF+BPw8TjaYlCbrejwU8D83ddLWsZM+h00dO1i2ck2tDkekJgbmsWpUHisRkVEoeP8wQCVZlSzRHKt8STPHqphZ3d0LVTKrtwOHAnEtJu7BehswD1gVbnb7AWZm+7r7cnffEn+Au99sZt8CDmZg71cqcY/Vju7e4jJ32Nyxc7gfJTKmBuaxalAeKxGRUegtKNS6ZJPyWOXLkD1Ww8isfgdwjpk1hPlXJwM/cPd2d5/p7nPcfQ7wbaK5WMthUNb1E4iSBG5hBOIeq8mJrOsGzG2dMZKPkzqVMkrl8WHoaHcyCmVY9xkzWx+iUG4ws88l1n3ZzJ4O6x8L12S8rmYRLAfmsWqkSVEBRURGrLdP86skmxS8Il/SRgVMk1n9FqIkgRvDPpe5+3MpPnulmR0A9AHbgZPcvXeIfcqKg1ckH04P2HcqNyxdPJKPk/qVJkrlZuBs4BRgasm6HwI3ubub2T7AU2b2gLuvBx4FvunuXWFu4Goze5u77wr71iSCZcU8Vr2aYyUiMlxxj9WkRuWwkmzZraGAuZKqYpUys3oB+GyKz7q05P1xacqQRjwUMPlo+tfHL2R2y/Ra/QgZZ4kolUvCotuAq82sNdmL6u6bwvYnl36Gu29PvJ0ONBEuG3e/O7FuPVGnZwvwUg0PY9BQQM2xEhEZOYVal2rMbCGwkuj/eSdwprtvrLDtO4AngO+4+4Vh2XTge8D7gF7gQnf/SS3K1h+8Qo0CeZCrsxgPBUzarbxAeZM2SmVVZnaSmT1NNJfvCnffUGazM4E2d09WqmoSwfL1rj3F18d/60He2NUDqGIlIjIScXLgSUoOLOXFI10WAiuIRroMUiXn6oXAdnefD/wJ8F0za65FwRS8Il9yVbFKJl2N7d6jnFYymLv/2N3fDSwEzggtVEVmdgxwOf1zC6GGESy/8uOni6/bOnZwzeo2QBUrEZGR6CnmsMrVY43UwDDysULlnKunEipjoadrLfDRWpRv157o2tUcq3zI1R1ocuPgizJuCZDcKEaphGLrUrkolam4ezvRvKqPx8vM7CjgVuBkd38mse0Wd+8Lr28GmokiWA7/IF7bVXzd5/Df23cDymMlIjIScY+VogJKGalGugyRc7VirtZSaUatJCmPVb7kqmI1pVyPlSpWuTKMKJUVJYfwmdlM4MPAhvB+MXA7cIq7P16yX80iWM5tnUH877/B4G1vieJr9GjoqojIsBWjAmoooIxAipyrqaUZtZKkoYD5kquK1eQy0YDUY5VL5wHnm9mzwPnhPWa2yswWhddHm9lLwAXAuSFMehw6fXkIqb4O+AVwtbvfE9Z9B5gGXJsIq/6esG5lmF/1JPC3jCKC5Q1LFzN/VjONZsxrbebiE6O6noYCiogMn4JXSBVpRrokc64+D3yeKIXQdWF9nKs1NpsRjpQpFeexUsUqH9KGW8+EZI/VrH2msPXNbvVY5VDKKJW/osIwPXf/QpXPrhibv5YRLGe3TOfeC44pvl/34uuAKlYiIiNRDLeuOVZSwt23hobU04mG+Q8a6RKmBcyM35vZpUBzHBWQKFfrucDakDtzMQPnYI9Y3AEwRRWrXMjVHeiVN3YXX+/cE3Uk7O7Rg6rUv6YwfEVzrARSJ8FuNLMVZtZmZpvM7Ow060TyqFdRAaW6IUe6DOEKYD8z20QU3GK5u7850sK0d3ax5KrVzLt4Fb9+OcoAox6rfMhVj9W5tzxWfN3VHbUA7FJUQMkA5bGSEmmSYH8KmA8sIMrN8oSZ3efuzw+xTqQm0uQGChHZvkc00b8JuB/4nLv3hiFZ/wD8T6Jcgt9w9++OpCyFMMdKwSuknDQjXUqWX1ryfifwyVqV54wbH+GFzi4ACqFBVcEr8iFXPVabO3YWX8ft/ppjJVnQpIqVBMMIDXwqcL2794UhLXfS/4+/2jqRWkmTG+iLwG/c/XDgcKIEq38a1iUbAI4CLjWzOSMpSE94OG3SUEDJgPbXugYtU49VPuTqDjS3dQZxY1XcZqWKlWRBU0huraiAQvok2NXC/6YKDTzcsMAisWE0ADiwj5k1AFOAyfRHU61ZA4DCrUuWvHVa06BlqljlQ64qVjcsXcy81ijS2sFvnQZAtypWkgH9c6xUsZK9Z7hhgUUS0jYAXE6UiP13wCvA3e7+n2FdzXIDaY6VZMkJ7/69QcumTs7VI/mElauzGEdaa/v6iXx3aRTcTT1WkgXxHKs96rGS9Emwq4X/HbPQwCLD9ElgPVE464OAD5nZKcP9kKEaAXpDo5TCrUsWlEYAbLDyKYMke3J7FuMuVVWsJAv651gpKuBEN4wk2HcQ5VlpCMOvTgZ+kGKdSC2kbQA4H/h+GO73BnAXUVJ2qGEDQG9xKGBuH2skR7pLGlGnNTVipkaBPMjtHWhqyGmlcOuSBcngFe2dXRx31QPMu3gVS65aTXvn4EmukntpQgPfAmwGNgIPA5e5+3Mp1omM2jAaAJ4jivqHmU0GjgOeCutq1gAQ57Fq0lBAyYDS0SlTNb8qN3IVbj1paghbuVvh1iUD4oeB3j7n1Ose4nchJ1tbxw6WrVwzIJmw5F/KJNgF4LMV9q+4TqSGzgNWmtklwDbgTIgaAIBL3H0t8HngGjPbADQShVu/Pux/C9F1HodoH3EDQK/CrUuGlM6nVsUqP3JbsdJQQMkSM6Op0egp+IBE130+MI2AiEi9SNkA0AYsqbB/zRoA4qiATZqnIhlQGlhNOazyI7d3oKbGBhobjN4+V24gyYT4gSAZ1arBojQCIiJSWTwUUD1WkgVxj9XkSdH1umnrDg39z4ncVqygv9dqt3qtJANKA1gYMK+1mRtChEsRESmvGG5dFSvJgO4w/78xEbAiHvov2ZbboYAQjVnd0d3Lrp4C+0wdnIxNpJ6UDmE5esFMblk2aJSNiIiUKIQ5VspjJVkQ91jtTgSx0ND/fMh3j1VIttatyICSAZNLHgje3N07TiUREcmWuKd/ksKtSwbEUQEP3m8acaeVhv7nQ67vQFMnKYCFZEfTpIF/jtt394xTSUREsqWgoYCSId290XPpZSe/m/mtzTSaaeh/TuR6KGAcZWWXQq5LBpQOBVSPlYhIOj1xuHUNBZQMiHus5rQ0K51KzuS7x0oh1yVDSitW23epx0pEJI1CQT1Wkh3dvXFUwFw/hk9IuT6jUxUVMJfMbKGZPWRmz4bvC8psc7yZrTWzbjO7smTdZ8xsvZmtM7MNZva5xLpGM1thZm1mtsnMzk6zrhbiOVZNjUZjg9Hd21ccLiAiIpX1RwXM9WONjFDK54ZqzwaXmtnWsG6dma0YTXniHqvJyruWO/keCtgUXbCqWOXONcAKd7/VzD4NXAt8pGSbzcDZwCnA1JJ1PwRucnc3s32Ap8zsAXdfD3wKmA8sAFqAJ8zsPnd/foh1oxb3WM1rbea/t+9mW1cPb+7uZUqzEgeKiFTTG0cFVI+VlJfmuaHaswHAze5+YS0KE1espjSpYpU3uT6j0zQUMHfMbBZwJHBbWHQbcKSZtSa3c/dN7r4OGDRRyd23u7uHt9OBJiB+fypwvbv3uXsHcCfwyRTrRqW9s4unX34DgC3bdhXnB2qelYjI0Io9VuoBkBLDeG6o9mxQU93qscqtXJ/R/qGACreeI4cAW9y9ABC+vxyWp2ZmJ5nZ08ALwBXuviGsmh2WxdoTn11tXfKzl4dhiGs7OjpSlWfZyjXsCtfpju5eOnfsATTPSkQkjV7NsZLKUj83VHk2ADgtDBW8x8yOqvTDhnoGcPdiHqspmmOVO7k+o8XgFYoKKCXc/cfu/m5gIXCGmb2jhp99nbsvcvdFra2tQ+/AwKSATn9rlnqsRESGFodbb1TFSkahyrPBNcDb3f1w4ArgLjNrqfAZVZ8Bkr1VZrpe8ybXFatiuHUNBcyTF4GDzKwRooASwIFh+bC5ezvwKPDxsKgdODSxyezEZ1dbNypzW2fQkEgSOGNKdO0ql5WIyNDiOVZNCrcugw37uaH02cDdX3H3nvD63rDvYSMpTNxbpYiA+ZTqrKaMpjJkxDQze4eZdSWjtJnZdDO7PezzWzP7eOl+IxUnCO5WxSo33H0rsA44PSw6HXgizHlKxczelXg9E/gwEHf33wGcY2YNYfz1ycAPUqwblRuWLmZeIknghxZErVxvqmIlIjKkeChgo6ICSom0zw3Vng3M7KDEuiOAOcAzIylPMXCFKla5lDYqYJpoKlUjpoUWgmuJJvwnXQhsd/f5ocL2SzOb7+47RnRECdMmRxeteqxy5zxgpZldAmwDzgQws1XAJe6+1syOBv4F2DdaZacBy9z9bmC5mR0P9AAGXO3u94TPvgV4P7AxvL/M3Z9LsW5UZrdMH5Ak8PKf/BqA7bs0FFBEZCj94dbVYyVlDfncQPVng6+Z2fuAArAHOMPdXxlJQZTDKt+GrFgloqksCYtuA642s9aS2n4xYhrQYWZxxLQrwvq/AX4CNIev5H5LAdx9o5mtBT5K1DswKooKmE/u/luiCk7p8hMTr38FHFxh/y9U+ewC8Nnhrqu1faZGf5rqsRIRGVpvGF41SUMBpYyUzw3Vng2W1qos6rHKtzRnNW00lYoR08zsvcAJwLfKfP6YRVqboqiAklH7Tm0CYLuCV4iIDKlXwSskI7p7o8Z+9Vjl05ifVTNrAq4DzosrZyMxkkhr6rGSrIp7rBS8QkTqWco52Deb2brEV5+ZnRTWXWpmWxPrVoykHHFUwCblBZI6t0dDAXMtnQv1FwAAIABJREFUzRyrYjQVdy9UiaYSR0xbE97HPVFvA+YBq0JYyf2I5rzs6+7LE/t1JPa7f+SH1C+uWO1WuHXJmH2nhR4rzbESkfo25Bxsdz8zfh1GsPwHcHdik5vd/cLRFKKnoB4ryYb+oYCN41wSGQtDVpeHEYWtbMQ0d29395nuPsfd5wDfJpqLtTyx37kAoaVrMfDzUR4XkEgQ3KuKlWSL5liJSL1LzMG+LSy6DTgyPANUsgz4vrt317IshRBuXcErpN4l81hJ/qQ9q+cB55vZs8D54T1mtsrMFoVtbgE2E0VMe5j0EdOuAPYzs01EwS2Wu/ubwziGiopRAdVjJRmjOVYT03DST5jZOWG7NjO72swawvJPmNljZvaUmT1tZn+9945AJpi0c7ABMLPJwF8AN5asOs3M1pvZPWZ21EgKUowKqIdVqXMaCphvqcKtp4ymkipimrtfWvJ+J1H0wJqbWpxjpeAVki3FitUu9VhNMKnST5jZ24GvAL8PdAI/Az4N3Ay8AvyJu79sZm8BHjOzR939l3v1SEQGOxlod/d1iWXXAF919x4zWwLcZWbvcvfO5I5mthxYDjB79uxBHxznsVKPldS7bkUFzLVcn9XiUEAFr5CM2XeahgJOUKcSzVHB3TcCcfqJUqcAd7p7R0hxcX3YF3d/xN1fDq/fAH5DNI9VpNaKc7ChmK+y3Bzs2FmU9Fa5+yvu3hNe3xv2Pax0x6ECWBWUx0oyQlEB8y3XZ3WaKlaSUc1TQsWqu5e+8MAgE0Kq9BNptzOzdwJ/SBQsYJCRpLEQiQ1jDjZmdjDwQeD7JcsPSrw+ApgDPDPcsvT0KY+VZIOCV+TbhKhYKdy6ZM2kxgZmTG7EHXbu0TyrvDCzx83s1QpfNf0va2ZvA+4C/iruwSo1kjQWIiXSzMEGWAr8u7tvK9n/a2E+4JNEPa9nuPsrwy1EoZjHKtePNZID3ZpjlWup5lhl1bTJoWKl4BWSQftMbWLnngLbd/eyT5hzJdnm7kdWW29madNPxNuR2K44/CpEa7sP+H/ufsdoyixSTZo52OH9Vyvsv7QW5dAcK8mKPZpjlWu5PqvxRdvd26fhVJI5mmc1IaVNP/FD4GQzaw3RAM8B/jXs1wLcC1zt7jfslVKLjLNeDQWUjNhTUMUqz3J9Vs2MqU39lSuRLNlnqpIET0AV00+Y2WVmdh6Au28GLidKbbGRKNXFreEz/gZYCJxrZuvC12f28nGI7FXFcOsaCih1rrtHQwHzLNdDASGaZ7W7p49dPYXi0ECRLNhXSYInnGrpJ9z9kpL31xIiCJYsvwi4aEwKKFKnNBRQsmJPIZqeoh6rfMr9WVXIdcmqfafFSYJVsRIRqaY/eIUqVlLf1GOVb7k/q4oMKFm1T7HHSkMBRUSqiedYNTXm/rFGMi6eYzVZ12ou5f6sxj1WigwoWbNvcY6VeqxERKqJhwKqx0rKMbOFZvaQmT0bvi8os81nzGx9mJe6wcw+l1jXaGYrzKzNzDaZ2dkjLUsxKmCTpqfkUe7nWMXBK154bSdfuH0dmzt2Mrd1BjcsXczslunjXDqRyuLgFeqxEhGpLg5e0aSogFLeNcAKd7/VzD5NND/1IyXb/BC4yd3dzPYBnjKzB9x9PfApYD6wAGgBnjCz+9z9+eEWpJjHSj1WuZT7sxoHrPi7n/yGTVt3UHCnrWMHy1auGeeSyUilbHk63szWmlm3mV1Zsu7LZvZ0aJl6zMxOSKy7LxFJ7SkzczM7PKy7ycxeSqz/0lgeZzy05boHN7PkqtW0d3aN5Y8TEcms3jC8Sj1WUirk9TsSuC0sug040swGZEV39+3uHufmmQ40AfH7U4Hr3b3P3TuAO6kQaGgo/T1WuX8En5Byf1bjOVa/e2N38a+jz2Fzx87xK5SMVtzytBBYQZnIaEThp88mCl9d6lFgsbsfDpwF3G5m0wDc/Th3P8LdjwD+Fng6tFbFvhGvr5Twsla+/3A7EN3V1RggIlKZwq1LFYcAW9y9ABC+vxyWD2BmJ5nZ08ALwBXuviGsmh2WxdrL7Z9Gd280NUU9VvmU+7Nabgxrg8Hc1hnjUBoZrWG0PG1y93XAoHF07n63u8fdP+sBI+raL3UWcGOtyj5cW9/cXXytxgARkcriqIBKECyj4e4/dvd3E+UCPMPM3jHczzCz5WHEzNqOjo5B64tDARUVMJdyfVbbO7t48NnBF/W81mZuWLp4HEokNZC65SmlM4E2d38pudDMfg84DrilZPsLwqTWO83sXeU+cKibalrJyr+pMUBEpCx3T/RYqWIlg7wIHGRmjRAFogAODMvLcvd2otEtHw+L2oFDE5vMrrS/u1/n7ovcfVFra+ug9cWhgJMUvCKPcl2xWrZyzaCJ/2aw6v98UIErBDM7BrgcOL3M6jOBn4ex1LEvAfPd/T3Aj4CfxzfqpKFuqmnduPQPiiHXW6ZPVmOAiEgZyRxWZqpYyUDuvhVYR///+tOBJ0r+v5NsLDWzmcCHgXgo4B3AOWbWEEbInAz8YCTlUY9VvuX6rJYbOuUOr7yxu8zWkhHDbnkqx8yOAm4FTnb3Z8ps8hlKhgG6+xZ37wuvbwaagYOHfQQpzW6Zzt//2eEAvD30Vi25ajXzLl6lYBYiIkGvkgPL0M4DzjezZ4Hzw3vMbJWZLQrbLA+BrdYBvwCudvd7wrpbiOZubwQeBi5z9+dGUpD+HqtcP4JPWLkOtz63dQZtHTvo82he1eRJDezu6eOlbbs4ZH/1WGWRu28NN73TiSpGZVueqjGzxcDtwCnu/niZ9X8EvAX4Wcnyg9x9S3h9AlAAtoz0WNL44IKZNDUaj72wjb/83qM89+rOAcEs7r3gmLH88RNae2cXy1auUYoGkTqnYYAyFHf/LfD+MstPTLz+QpX9C8Bna1GWOHiFKlb5lOuzesPSxcxrbabRjHmtzXxg3kwAXn591ziXTEZpyJYnMzvazF4CLgDODWHS47Dq3wGmAdcmQqe/J/H5nwFujudxJawM86ueJIoYeJK7j2mSqX2mNvHeQ/aLgleEShUomMXesGzlmmKKhk2KyihStwoFVawkO/YUNBQwz3LdYzW7ZfqAFv2///lv+cVvt7JFFatMS9ny9CsqDNNz96qTldz9nArLjxteSWvjhTJD/gwFsxit0h6pyz9xGF++66ni+7aOHcWKrKsiK1K3ekLOv0kKXy0ZoOAV+ZbrilWpA/ebBsCWbapYSXZ07ugetGzfaU0KZjFKn7npUTZ39A+tPOPGR+gtePF9gxl9IVekUjSI1K+ChgJKhih4Rb5NqLN6cKhYvfyGKlaSHfNam4kDXcWPDYe2TNd8n1EqHVrZEypV8ft43oaZUjSIlGNmC83sITN7NnxfUGabmxNDrteZWZ+ZnRTWNZrZCjNrM7NNZnb2SMrRE4ZWqWIlWbBHFatcm1BnVT1WkkU3LF3M/DBXMO41+c3vtrO7p3QKmAzH9MlDD8OY1GDc+4UPce8Fx6giKzLYNcAKd18IrACuLd3A3c909yPc/QhgKbANuDus/hQwH1gAHAVcamZzhluIYrh1JQeWDOhWVMBcm1Bn9aC3horV67tw9yG2FqkP8VzBtq+fyC/++lgWHtBMT8H5ze+2j3fRMqvQ55DiFlDocz5766DAkSITnpnNAo4EbguLbgOODDl+KlkGfN/d4/HNpwLXu3tfiOx6J/DJ4ZYl7l1uaphQjzSSQYU+p9DnmKmHNa8m1F2oecok3jKtie7ePjp37hnv4oiMyHsP3g+AdS++Ps4lyY72zi6OveJ+5l78U5ZctZp7f/3f7NxT4NCW6TRWSSjqKGiFSAWHAFvi6Knh+8th+SBmNhn4CwbmB5wNvJB4315p/2p6C8pjJdmQzGGlZNb5NKEqVqDhgJJ9R8yOKlZPqmKV2rKVa3i+s4s+h01bd/Clf9sAwAfmz2Ru6wzi57EGg6ZGG/BeQStEauJkoN3d141kZzNbbmZrzWxtR8fAtIW9ISqgKlZS7+IcVpMVwTK3JtyZPShUrJ588XWOu+oB5l28iiVXraa9TEhrkXoU91g9+dIb41yS7Gjr2FF87VDssT56/sxB+e5uOev9A94raIVIWS8CB5lZI0SBKIADw/JyzmJgbxVEPVSHJt7PrrS/u1/n7ovcfVFr68DRhvEcqyY9rEqd6w9coVDreTWhwq0DHBzmWX37vmd5rasHiB66lq1cMyDnlUi9mja5EQOee3Un8764CndnbusMblz6BwqwELR3dnHGjY/w0mtdzG1tZmpTI117Bgb7MIOj5rbw1hmTB/3t614gUp27bzWzdcDpwK3h+xNhrtQAZnYw8MGwTdIdwDlm9iOghahX64PDLUuPhgJKRihwRf6lOrMpQ6pWDJtqZp8xs/Uh1OoGM/tcYt2lZrY1EYp1RW0OrbwD95sKUKxUQRRaWfMoJCvOu+WxYtyFQp/T59C2dSfLVq4Z13LVk0/d8DAvdHZRCEP/SitVEA3FeHN37ziUrjIzm25mt4d76G/N7ONVtj0nbNdmZlebWUPJ+qlm9rSZrR37kssEdR5wvpk9C5wf3mNmq8xsUWK7pcC/u/u2kv1vATYDG4GHgcvc/bnhFqK/x0oVK6lvqljlX9oeqzik6q1m9mmikKofKdkmGTa1BXjCzO5z9+eBHwI3ubub2T7AU2b2gLuvD/ve7O4XjvZg0qiU6XrOTLX0SzaUawSYyEEW2ju7OGtllOw3Hrr34mv9cyjjSmjzlEm0NE/mhTDsd09vXz32VF8IbHf3+aEB65dmNt/ddyQ3MrO3A18Bfh/oBH4GfBq4ObHZV4keVt+7V0ouE467/xZ4f5nlJ5a8/2qF/QvAZ0dbjt6C5lhJNiiHVf4NeWaHEVK1YthUd9/u/fHNpwNNpAp2XHvf/eXmsss3d+zUXCvJhGSwhaQD3zp17xdmHLV3dvHH33yAD11xP5u27qTPYePWHZx+/UNlt9+5p7dYqYK6rYyeSsgF5O4bgbXAR8tsdwpwp7t3uHsfcH3YFwAz+yBRI9ctY15ikXEWh1ufpHDrUufi4BXqscqvNGc2bUjVqmFTzewkM3s6bHOFu29IbHtaGCp4j5kdNYLjSO3l13eXXe70z7USqWdxsIUGoqEvcR3rqLkttHd28ZFv5jsoS3tnFx+5MqpQtZWpGG0Jf+Ollc+4aafOI/6lDT9dcTszmwF8mxQ9AdUirYlkRTwUcJKGAkqdU49V/u214BXu/mPgx2Y2G7jTzFa5+zNEwwy/6u49ZrYEuMvM3uXuncn9zWw5sBxg9uzZIy7H3NYZtHXsoM+jB6u+RL+Z5lpJFsQJg2OPt2/jT7/zXzzwTAe/2vRqsfEgb0FZ2ju7WPq9R3nu1fR/o02NVpyH1mAwe//pNDU2sLljJ3NbZ+z1iH9m9jhRpaicA2r0Y64gGrq9pdx82CR3vw64DmDRokXKmi6Z1BOGAirhqtS7/jlWigqYV2kqVsWQqu5eqBJSNQ6bGnf5lLaoAuDu7Wb2KPBx4Bl3fyWx7l4zexE4DFhdsl9NHgBuWLqYZSvXFB+segp9vPBaV7E1+5D9p9He2TVgmxuWLla0Nalbv3/Ifhz4lqm8/MbA3ti0DQX1fr3HEf5eGGbvW58DBWferOa6OTZ3P7LaejOL76Nx99Fs4P4ym1YLU300cKKZXQJMBd5qZuvd/fDRlF2kXhU0FFAyQj1W+TdkxWoYIVUrhk0NPVC/Ca9nAh8GfhTeH+TuW8LrI4A5wDOjP7TySlv744fKjVujueHPd3bx4W8+ULxRt3Xs4MwbH8HMeP7VnUwKLeDxJPl6egCVicnM2N0zOOodpBvqlrz+67GX67TrH6o4hDe2YFZzsdEk2SM9r7W5ro4lhTuAc4G1obdpMYNDVEMUEOhBM/u/RMErzgH+GSBZgTKzY4Er3X1Rmc8QyYWe8P+6UUMBpQozWwisJHpG7QTODHNZk9t8GTgNKAA9wBfd/e6w7ibgOODVsPkdlQKzVLIn9K4qQXB+pR0KeB6wMrSAbgPOhCikKnCJu68lmiT9fqKwqTAwbOpyMzue6CI14Gp3vyes+5qZvY/oIt4DnJHsxRprcUXr2Cvu5/nQIl5IjA/sc4rLoT9fRj0+gMrE9fqunkHLGhuMS096N0uuWk3b1h00VmgUSCbP3VvDYUt7yS7/xGF8+a6nBvUsdbzZXbVSFVeo4mMp7ZHOYHLfK4CbzGwT0T1xubu/CWBmlwEvu/s17r7ZzC4nivoHcA9Rw5fIhFPo01BASSVNhOtHgW+6e5eZvRdYbWZvc/c41Ow33P3qkRagGLyiSRWrvEpVsUoTUrVa2FR3/0KVz16apgxjLRmeOckoH75Q87GknsxrbR7QU9NgRm+fc9EPnixWTPpCo8CmrQMbBfad1sTribxueyOgw6e++zAvbov+5to6dnDGjY8UGy02bt3Bh664n6ZGKy4rVVqhipX2SGeNu+8kRFMts+6SkvfXEiIIVvm8BwD1Vkmu9RY0FFCqS0S4XhIW3QZcbWatyRFYce9UsJ7oMbAFeKkW5SgOBVSPVW7pzAbJENZGfz6MalGGCu65jbxWz1ImrD4+RDvrNrMrS9Z9OSROXW9mj5nZCYl1N5nZS4mE1V9KrDsgRK581syeNLNBjQ3jJY4U2GjGvNZmPnb424DyUTCdqPIy7+JVHHfV6kHrr/zk2E7FcfdipQqiRopyFajksqYGo9GMBbOaefCiD3PvBcdoGK6IAMlw6+qxkorSRrhOOhNoc/dkpeoCM9tgZnea2bvK7VQt2moxeIV6rHJLZzZIPpjOn9XM3Z//IDObJxcf7syiCldpZvdNCtE+HuLu/IXACsq32m8GziYaWlXqUWBxmItyFnC7mU1LrP+Gux8RvpLjp78OPBh+7v8CbjWzuvhPHvfUtH39RO694BjWtb8+5D4Fd9q27uD1rh4O2X8ax74jSk335EtvFLdp7+xiyVWraxq+ffWzww/r3ecUj00VKhFJ6lW4dakxMzsGuJyBc1y/BMx39/cQxQn4eQjoNoC7X+fui9x9UWvrwJSv/T1WigqYV3st3Hq9SzOEaP6saCL8vItXUQhhBD0kJZ178U8HzF1p7+zirJWPsrljpwJd1NAwuvM3he1PLv2MUXT1/zlRcBXc/Vdm1k00zKruatYvbRs8tDUZejwWv9yxu5d3H7gvDzzTwSV3Pc3lP/l1ca5hvH3aeYXx/KnSeV3xPKo4UEbzlEns6O4d8ljqNN+UiNSJXoVbl6GljXBNyKd6K/CJkBYIgDjQWnh9s5l9CziYMhGwK+lWVMDc05mtYtvO/nknnphTlRw2GOvzgb1Xf/m9R9m0dWe0PMxpGYvW/wloJN351aTq6jezFsDc/dXEdmWTt9ZD0tXkNdpg0ZykjV89kc1f/xgLZjVT+vjx+q4erntwc/F9TyGqgI0kz9vS7z3Kxq076Et8zsatOzjt+oeLlSqAA/adwr5T+9t2DJjTMp0Fs/qTH8eR/TIYhEJE9pK4EahRc6ykAnffCsQRrqFChGszWwzcDpzi7o+XrDso8foEogBDWxiG/jxWulbzSj1WVZQmE45bzZORx+KeK+jvvVrwxVXF8K/QP6fl2CvvLz6oxhP0K03CL1XvuYayKNHVvySx+EvA79y9z8zOJOrqnzucz62HpKvVouPF65KVHK8wz6nUIftPY8lVq8tG8ztk/2n0FPrYMkRo9Njzr3bhDPw7efG1XbR9/cTKO4mIlIiHApYO1RcpkSbC9XeAacC1iZH+Z7j7hrDvAUAfsB04yd2HHnaRoDxW+aeKVRWVHk6TwwaXXLW6WPmKJStVSeUWJyOgJUNhAwN+dndvH+2vRT1cm0JurabGholY0UrdnV/NcLv63f0FM8PMZiZ6rZJJWetKtaGt8brktdtgUcCW0qGCcSCX+MElmXogjubXW4iqR88Powc22VBRrvFCRCSteChgo4YCShUpI1xXHB7h7seNtgzFcOuqWOWWKlZVpJl3Va71fyRKQ01PSjzMllbc3Ac/4C5buWZQRbBSbqC0RtJLliY/EcCnbniYLdt2DXv+2TASVlc0VFd/ImF1aVf/HUQtXn9nZkcTtWo9lvbn1ptK10u5nFcf+4df8mbJfKg+7w/hXkmlkOmVGhA05E9Ehqs/eIUeVqW+7dFQwNwz93EZqTQqixYt8rVr1453MQYo13NV2gtgRFGL0gy5GitzQgWmvbOLxkajt+DFSlxDKGtjg9HnjjG4l60p3ifxvdDnHLL/NHDjhdeGN28snkMTV2DN7DF3r5p3x8zeSZQ9/a2E7nx3fybZnR8qPv8C7Ev0q38DWObud5vZGqIgFMmx0We4+wYzuw9IdvVf5O4Ph5/7e0SVuUOBXcB57v5f1cpaj9fqSMy9+Kdle1wrSZ7XvA5jTXOtZklerlUZLM/XantnF59Y8Su2dfWw/4zJ3PlXH8jF/WWiyvu1+vF//CXbd/cya58p/OC8P9K1mlHVrlP1WNVI3PpfKRJaaYt8LXq5RiLZ0xX3NsRDFwsl38s9R8eVwtLvL3SWT7A8lJEkWk7Znf8romg95fYfUVe/u78CjHooQBbNa21mU8cOqrXDxJX2F1/bVXHorIhILS1buaaY4Hzbzj2pIpeKjIdlK9ewfXc08qPjzW5dqzmlilWNVHt4LLc82ZIfV8aSPVnVercarPx8rSzSvJpsKB02WNo722jGAxd9ePwKKCIT0uaOncVGQGf4DXUie0vy2tS1ml8a5DmO4srY5m98jI1fPZEHL/owC2b1Jyn+xQXHRqGnE2Gz57RMLyYyXjCrubjPWKSpLZcQuZaf22imUNoZUZqAeF7rwOtSlWORicnMFprZQ2b2bPi+oMJ2fx7SWDwVvh8Qll9qZlvNbF34WjGcnz+3dUbx/5/pXiR1TNfqxKCKVR0pfXid3TKdG5YuLlak5rU2c/NZ7y+7zfxEZetfzvnDYgWt9P2clunMaZlezBNkFb43GMXKXVx5q7RPXOGb0zI9VRniz00eg2RL6XWpyrHIhHUNsMLdFwIrgGtLNzCzRcClwBJ3Pww4mmjea+xmdz8ifP2v4fzw5P+/+boXSR3TtToxKHiF1JU8T1yVfNG1KlkxVteqmc0CngVaEukvOoEFyUitZvZ94BfufmOZz7gUaHb3C9P+XF2r+aX7qmRBtetUPVYiIiIyEocAW9y9ABC+vxyWJ/0PYK6ZPWhmj5vZ35oNGMB+mpmtN7N7Qo5BEZFMUsVKRERExlIjcDiwBDgG+ChwRlh3DfB2dz8cuAK4y8xaSj/AzJab2VozW9vRkTptoYjIXqWKlYiIiIzEi8BBYQgg4fuBYXlSO/ADd+929zeBu4A/gCiNhbv3hNf3hn0PK/1B7n6duy9y90Wtra1jdkAiIqOhipWIiIgMm7tvBdYBp4dFpwNPJOdXBf8MHG+RJuCPgScBzOygeCMzO4IoefszY1x0EZExkcngFWbWAbxQZtVM4NW9XJzRUHkHO9Tdc9McqWt13OhaHaYcXatp5PGYoPJxjdm1ambvBFYCbwW2AWe6+zNmtgq4xN3XmlkDcCXREMA+4G7gQnfvM7OVwPuAArAH+Iq7rxriZ5a7VrN2TlXe8ibCfVXnfmyN6///TFasKjGztVmKJqPyTlxZ+12qvBNXHn+XeTwmyO9xpZG1Y1d5J66s/S5V3uHRUEAREREREZFRUsVKRERERERklPJWsbpuvAswTCrvxJW136XKO3Hl8XeZx2OC/B5XGlk7dpV34sra71LlHYZczbESEREREREZD3nrsRIREREREdnrclGxMrOFZvaQmT0bvi8Y7zIlmVmLma0ys2fMbIOZ/cjMWsO6PzSzJ0PZ7zGzWeNd3piZfcXM3MwOC+/rtqxZoWt1bOhaHTkzm25mt5vZJjP7rZl9vMq254Tt2szs6hBGGzM71sy6zGxd+Hpk7x3BgPIN+fdlZo1mtiIcwyYzOzvNuvFUg+O61My2Js7Pir17BGOrnu+rWb2ngu6rY0HX6tioq2vV3TP/BfwH8Onw+tPAf4x3mUrKtz9wbOL9FcANRBXbTcDRYfnfAjeOd3lDWY4EfgY8DxxWz2XN0peu1TEps67V0f3+LgGuD68XAK8AzWW2ezvwEtAafsd3E+UsAjgWWFsHxzLk3xdwZih7QziWl4A5Q63L+HFdClw53scxnr+fcSxb5u6poTy6r47N71XXau3LXVfX6rj/QmrwC50FvA40hveN4X3reJetSpn/DLgPWAw8lVg+E9hRB+WbAjwEzElcqHVZ1ix96Vodk/LpWh397/BpYFHi/U+AT5bZ7iLg6sT7U4CfhtfHMs4Vq7R/X8BPgVMS768GLhpqXcaP61JyWrHK2n213u+poSy6r47N71XXau3LWHfXah6GAh4CbHH3AkD4/nJYXnfC0JnPAj8GZpPIyO3urwINZrb/OBUvdhlwq7s/n1hWr2XNEl2rtadrdfQG/L6Adspfk0Ntt9DMHjezR8xsae2LOaS0f1/VjiPt72JvqsVxAZxmZuvDsJijxrLAe1lm7qsZuaeC7qtjRddq7dXdtZqHilXW/COwg6g1se6Ef7iLgO+Md1lk3OlazYFQ2Xm1wldjjX7M48Ah7n4kcBpwiZkdV6PPltG7Bni7ux9ONLznLjNrGecyTUR1fU8F3VelSNfqCOWhYvUicFD8gBC+HxiW1xUzu5JoDsOp7t5H1KJ4aGL9TKDP3V8bpyICHAO8C3jOzJ4HDiYatz+f+itr1uharS1dqym4+5HuPrPCV4GSc0vU2lfumqy4nbtvd/c3wuvngDuBD4zF8VSR9u+r2vGm/V3sTaM+Lnd/xd17wut7w/LDxrjce0sm7qsZuaeC7qtjSddqbdXltZr5ipW7bwXWAaeHRacDT7h7x/iVajAz+xrwPuBkd+8Oix8DppnZ0eH9ecAd41G+mLt/w90PdPc57j6/ZeQBAAABeklEQVSHaAL0CUStnHVV1qzRtVpbulZr5g7gXIAQoWox8PMy2/0QONnMWsMwkXOAfw37vc3MLLzeHzie6Frfa4bx93UHcI6ZNYSIVycDP0ixblzU4rjM7KB4IzM7gmg+wjNjXPS9Igv31azcU0H31bGka7W26vZa3VuTucbyC3gn8AjwbPj+jvEuU0n53g040T+ydeHr38K6PwI2ABuBe4EDxru8JWV/HjgsC2XNwpeu1TEtu67Vkf3eZhD909kUzvsnEusuA85LvD8XaAtf/0T/JOz/TRQEYx3wFOMU8KHS3xewihCgg2jC+D8ljmN5Yv+K68b5HI32uFaG8/IksAY4cbyPaW/8furhK8v31FBG3Vdr+/vUtTp25a+La9VCAURERERERGSEMj8UUEREREREZLypYiUiIiIiIjJKqliJiIiIiIiMkipWIiIiIiIio6SKlYiIiIiIyCipYiUiIiIiIjJKqliJiIiIiIiMkipWIiIiIiIio/T/AQXU/HyE3WNkAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 864x432 with 10 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"HXFQcoG0kWE7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594619516231,"user_tz":-540,"elapsed":46927517,"user":{"displayName":"노수철","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJOIZCchrOEMg4QcU2w6H3DmKa3eEnmQMEQl1V=s64","userId":"08629297047198293656"}}},"source":["import shutil\n","new_weight = '/content/drive/My Drive/Colab Notebooks/yolov5weights/' + name_input\n","if os.path.exists(new_weight):\n","  shutil.rmtree(new_weight)\n","os.mkdir(new_weight)\n","\n","weight_last = '/content/yolov5/weights/last_' + name_input + '.pt'\n","weight_best = '/content/yolov5/weights/best_' + name_input + '.pt'\n","\n","!cp '{weight_last}' '{new_weight}'\n","!cp '{weight_best}' '{new_weight}'\n","!cp 'results.png' '{new_weight}'\n","!cp 'labels.png' '{new_weight}'\n","!cp 'test_batch0_gt.jpg' '{new_weight}'\n","!cp 'test_batch0_pred.jpg' '{new_weight}'"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtigXSkIl15i","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}